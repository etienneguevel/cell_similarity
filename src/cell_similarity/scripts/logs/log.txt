I20240512 12:43:58 1248064 dinov2 config.py:59] git:
  sha: e1277af2ba9496fbadf7aec6eba56e8d882d1e35, status: has uncommitted changes, branch: main

I20240512 12:43:58 1248064 dinov2 config.py:60] config_file: config_test2.yaml
eval: 
eval_only: False
no_resume: False
opts: ['train.output_dir=/home/guevel/OT4D/cell_similarity/src/cell_similarity/scripts']
output_dir: /home/guevel/OT4D/cell_similarity/src/cell_similarity/scripts
I20240512 12:43:58 1248064 dinov2 config.py:26] sqrt scaling learning rate; base: 0.004, new: 0.001
I20240512 12:43:58 1248064 dinov2 config.py:33] MODEL:
  WEIGHTS: ''
compute_precision:
  grad_scaler: true
  teacher:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
  student:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
dino:
  loss_weight: 1.0
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
  koleo_loss_weight: 0.1
ibot:
  loss_weight: 1.0
  mask_sample_probability: 0.5
  mask_ratio_min_max:
  - 0.1
  - 0.5
  separate_head: false
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
train:
  batch_size_per_gpu: 64
  dataset_path: /home/manon/classification/data/Single_cells/medhi
  output_dir: /home/guevel/OT4D/cell_similarity/src/cell_similarity/scripts
  saveckp_freq: 20
  seed: 0
  num_workers: 10
  OFFICIAL_EPOCH_LENGTH: 20
  cache_dataset: true
  centering: centering
student:
  arch: vit_small
  patch_size: 16
  drop_path_rate: 0.3
  layerscale: 1.0e-05
  drop_path_uniform: true
  pretrained_weights: ''
  ffn_layer: mlp
  block_chunks: 4
  qkv_bias: true
  proj_bias: true
  ffn_bias: true
  num_register_tokens: 0
  interpolate_antialias: false
  interpolate_offset: 0.1
teacher:
  momentum_teacher: 0.992
  final_momentum_teacher: 1
  warmup_teacher_temp: 0.04
  teacher_temp: 0.07
  warmup_teacher_temp_epochs: 30
optim:
  epochs: 100
  weight_decay: 0.04
  weight_decay_end: 0.4
  base_lr: 0.004
  lr: 0.001
  warmup_epochs: 10
  min_lr: 1.0e-06
  clip_grad: 3.0
  freeze_last_layer_epochs: 1
  scaling_rule: sqrt_wrt_1024
  patch_embed_lr_mult: 0.2
  layerwise_decay: 0.9
  adamw_beta1: 0.9
  adamw_beta2: 0.999
crops:
  global_crops_scale:
  - 0.32
  - 1.0
  local_crops_number: 8
  local_crops_scale:
  - 0.05
  - 0.32
  global_crops_size: 224
  local_crops_size: 96
evaluation:
  eval_period_iterations: 12500

I20240512 12:43:59 1248064 dinov2 vision_transformer.py:122] using MLP layer as FFN
I20240512 12:44:00 1248064 dinov2 vision_transformer.py:122] using MLP layer as FFN
I20240512 12:44:00 1248064 dinov2 ssl_meta_arch.py:43] OPTIONS -- architecture : embed_dim: 384
I20240512 12:44:00 1248064 dinov2 ssl_meta_arch.py:58] OPTIONS -- DINO
I20240512 12:44:00 1248064 dinov2 ssl_meta_arch.py:60] OPTIONS -- DINO -- loss_weight: 1.0
I20240512 12:44:00 1248064 dinov2 ssl_meta_arch.py:61] OPTIONS -- DINO -- head_n_prototypes: 65536
I20240512 12:44:00 1248064 dinov2 ssl_meta_arch.py:62] OPTIONS -- DINO -- head_bottleneck_dim: 256
I20240512 12:44:00 1248064 dinov2 ssl_meta_arch.py:63] OPTIONS -- DINO -- head_hidden_dim: 2048
I20240512 12:44:00 1248064 dinov2 ssl_meta_arch.py:75] OPTIONS -- DINO -- applying KOLEO regularization
I20240512 12:44:01 1248064 dinov2 ssl_meta_arch.py:85] OPTIONS -- IBOT
I20240512 12:44:01 1248064 dinov2 ssl_meta_arch.py:86] OPTIONS -- IBOT -- loss_weight: 1.0
I20240512 12:44:01 1248064 dinov2 ssl_meta_arch.py:87] OPTIONS -- IBOT masking -- ibot_mask_ratio_tuple: [0.1, 0.5]
I20240512 12:44:01 1248064 dinov2 ssl_meta_arch.py:88] OPTIONS -- IBOT masking -- ibot_mask_sample_probability: 0.5
I20240512 12:44:01 1248064 dinov2 ssl_meta_arch.py:111] OPTIONS -- IBOT -- head shared with DINO
I20240512 12:44:01 1248064 dinov2 ssl_meta_arch.py:121] Student and Teacher are built: they are both vit_small network.
I20240512 12:44:01 1248064 dinov2 ssl_meta_arch.py:391] DISTRIBUTED FSDP -- preparing model for distributed training
W20240512 12:44:01 1248064 py.warnings warnings.py:109] /home/guevel/.conda/envs/dinov2/lib/python3.9/site-packages/torch/distributed/fsdp/_init_utils.py:295: UserWarning: FSDP is switching to use `NO_SHARD` instead of ShardingStrategy.SHARD_GRAD_OP since the world size is 1.
  warnings.warn(

I20240512 12:44:02 1248064 dinov2 memory_test2.py:17] Model:
SSLMetaArch(
  (dino_loss): DINOLoss()
  (koleo_loss): KoLeoLoss(
    (pdist): PairwiseDistance()
  )
  (ibot_patch_loss): iBOTPatchLoss()
  (student): ModuleDict(
    (backbone): FullyShardedDataParallel(
      (_fsdp_wrapped_module): DinoVisionTransformer(
        (patch_embed): PatchEmbed(
          (proj): Conv2d(3, 384, kernel_size=(16, 16), stride=(16, 16))
          (norm): Identity()
        )
        (blocks): ModuleList(
          (0): FullyShardedDataParallel(
            (_fsdp_wrapped_module): BlockChunk(
              (0-2): 3 x NestedTensorBlock(
                (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
                (attn): MemEffAttention(
                  (qkv): Linear(in_features=384, out_features=1152, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=384, out_features=384, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                )
                (ls1): LayerScale()
                (drop_path1): DropPath()
                (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=384, out_features=1536, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=1536, out_features=384, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
                (ls2): LayerScale()
                (drop_path2): DropPath()
              )
            )
          )
          (1): FullyShardedDataParallel(
            (_fsdp_wrapped_module): BlockChunk(
              (0-2): 3 x Identity()
              (3-5): 3 x NestedTensorBlock(
                (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
                (attn): MemEffAttention(
                  (qkv): Linear(in_features=384, out_features=1152, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=384, out_features=384, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                )
                (ls1): LayerScale()
                (drop_path1): DropPath()
                (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=384, out_features=1536, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=1536, out_features=384, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
                (ls2): LayerScale()
                (drop_path2): DropPath()
              )
            )
          )
          (2): FullyShardedDataParallel(
            (_fsdp_wrapped_module): BlockChunk(
              (0-5): 6 x Identity()
              (6-8): 3 x NestedTensorBlock(
                (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
                (attn): MemEffAttention(
                  (qkv): Linear(in_features=384, out_features=1152, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=384, out_features=384, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                )
                (ls1): LayerScale()
                (drop_path1): DropPath()
                (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=384, out_features=1536, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=1536, out_features=384, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
                (ls2): LayerScale()
                (drop_path2): DropPath()
              )
            )
          )
          (3): FullyShardedDataParallel(
            (_fsdp_wrapped_module): BlockChunk(
              (0-8): 9 x Identity()
              (9-11): 3 x NestedTensorBlock(
                (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
                (attn): MemEffAttention(
                  (qkv): Linear(in_features=384, out_features=1152, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=384, out_features=384, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                )
                (ls1): LayerScale()
                (drop_path1): DropPath()
                (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=384, out_features=1536, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=1536, out_features=384, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
                (ls2): LayerScale()
                (drop_path2): DropPath()
              )
            )
          )
        )
        (norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (head): Identity()
      )
    )
    (dino_head): FullyShardedDataParallel(
      (_fsdp_wrapped_module): DINOHead(
        (mlp): Sequential(
          (0): Linear(in_features=384, out_features=2048, bias=True)
          (1): GELU(approximate='none')
          (2): Linear(in_features=2048, out_features=2048, bias=True)
          (3): GELU(approximate='none')
          (4): Linear(in_features=2048, out_features=256, bias=True)
        )
        (last_layer): Linear(in_features=256, out_features=65536, bias=False)
      )
    )
  )
  (teacher): ModuleDict(
    (backbone): FullyShardedDataParallel(
      (_fsdp_wrapped_module): DinoVisionTransformer(
        (patch_embed): PatchEmbed(
          (proj): Conv2d(3, 384, kernel_size=(16, 16), stride=(16, 16))
          (norm): Identity()
        )
        (blocks): ModuleList(
          (0): FullyShardedDataParallel(
            (_fsdp_wrapped_module): BlockChunk(
              (0-2): 3 x NestedTensorBlock(
                (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
                (attn): MemEffAttention(
                  (qkv): Linear(in_features=384, out_features=1152, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=384, out_features=384, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                )
                (ls1): LayerScale()
                (drop_path1): Identity()
                (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=384, out_features=1536, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=1536, out_features=384, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
                (ls2): LayerScale()
                (drop_path2): Identity()
              )
            )
          )
          (1): FullyShardedDataParallel(
            (_fsdp_wrapped_module): BlockChunk(
              (0-2): 3 x Identity()
              (3-5): 3 x NestedTensorBlock(
                (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
                (attn): MemEffAttention(
                  (qkv): Linear(in_features=384, out_features=1152, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=384, out_features=384, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                )
                (ls1): LayerScale()
                (drop_path1): Identity()
                (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=384, out_features=1536, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=1536, out_features=384, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
                (ls2): LayerScale()
                (drop_path2): Identity()
              )
            )
          )
          (2): FullyShardedDataParallel(
            (_fsdp_wrapped_module): BlockChunk(
              (0-5): 6 x Identity()
              (6-8): 3 x NestedTensorBlock(
                (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
                (attn): MemEffAttention(
                  (qkv): Linear(in_features=384, out_features=1152, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=384, out_features=384, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                )
                (ls1): LayerScale()
                (drop_path1): Identity()
                (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=384, out_features=1536, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=1536, out_features=384, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
                (ls2): LayerScale()
                (drop_path2): Identity()
              )
            )
          )
          (3): FullyShardedDataParallel(
            (_fsdp_wrapped_module): BlockChunk(
              (0-8): 9 x Identity()
              (9-11): 3 x NestedTensorBlock(
                (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
                (attn): MemEffAttention(
                  (qkv): Linear(in_features=384, out_features=1152, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=384, out_features=384, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                )
                (ls1): LayerScale()
                (drop_path1): Identity()
                (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=384, out_features=1536, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=1536, out_features=384, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
                (ls2): LayerScale()
                (drop_path2): Identity()
              )
            )
          )
        )
        (norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (head): Identity()
      )
    )
    (dino_head): FullyShardedDataParallel(
      (_fsdp_wrapped_module): DINOHead(
        (mlp): Sequential(
          (0): Linear(in_features=384, out_features=2048, bias=True)
          (1): GELU(approximate='none')
          (2): Linear(in_features=2048, out_features=2048, bias=True)
          (3): GELU(approximate='none')
          (4): Linear(in_features=2048, out_features=256, bias=True)
        )
        (last_layer): Linear(in_features=256, out_features=65536, bias=False)
      )
    )
  )
)
I20240512 12:44:02 1248064 dinov2 param_groups.py:54] chunked fsdp
I20240512 12:44:02 1248064 dinov2 param_groups.py:87] cls_token: lr_multiplier: 0.2541865828329001, wd_multiplier: 1.0
I20240512 12:44:02 1248064 dinov2 param_groups.py:87] pos_embed: lr_multiplier: 0.2541865828329001, wd_multiplier: 1.0
I20240512 12:44:02 1248064 dinov2 param_groups.py:87] mask_token: lr_multiplier: 0.2541865828329001, wd_multiplier: 1.0
I20240512 12:44:02 1248064 dinov2 param_groups.py:87] patch_embed.proj.weight: lr_multiplier: 0.05083731656658002, wd_multiplier: 1.0
I20240512 12:44:02 1248064 dinov2 param_groups.py:87] patch_embed.proj.bias: lr_multiplier: 0.05083731656658002, wd_multiplier: 0.0
I20240512 12:44:02 1248064 dinov2 param_groups.py:87] blocks.0.0.norm1.weight: lr_multiplier: 0.2824295364810001, wd_multiplier: 0.0
I20240512 12:44:02 1248064 dinov2 param_groups.py:87] blocks.0.0.norm1.bias: lr_multiplier: 0.2824295364810001, wd_multiplier: 0.0
I20240512 12:44:02 1248064 dinov2 param_groups.py:87] blocks.0.0.attn.qkv.weight: lr_multiplier: 0.2824295364810001, wd_multiplier: 1.0
I20240512 12:44:02 1248064 dinov2 param_groups.py:87] blocks.0.0.attn.qkv.bias: lr_multiplier: 0.2824295364810001, wd_multiplier: 0.0
I20240512 12:44:02 1248064 dinov2 param_groups.py:87] blocks.0.0.attn.proj.weight: lr_multiplier: 0.2824295364810001, wd_multiplier: 1.0
I20240512 12:44:02 1248064 dinov2 param_groups.py:87] blocks.0.0.attn.proj.bias: lr_multiplier: 0.2824295364810001, wd_multiplier: 0.0
I20240512 12:44:02 1248064 dinov2 param_groups.py:87] blocks.0.0.ls1.gamma: lr_multiplier: 0.2824295364810001, wd_multiplier: 0.0
I20240512 12:44:02 1248064 dinov2 param_groups.py:87] blocks.0.0.norm2.weight: lr_multiplier: 0.2824295364810001, wd_multiplier: 0.0
I20240512 12:44:02 1248064 dinov2 param_groups.py:87] blocks.0.0.norm2.bias: lr_multiplier: 0.2824295364810001, wd_multiplier: 0.0
I20240512 12:44:02 1248064 dinov2 param_groups.py:87] blocks.0.0.mlp.fc1.weight: lr_multiplier: 0.2824295364810001, wd_multiplier: 1.0
I20240512 12:44:02 1248064 dinov2 param_groups.py:87] blocks.0.0.mlp.fc1.bias: lr_multiplier: 0.2824295364810001, wd_multiplier: 0.0
I20240512 12:44:02 1248064 dinov2 param_groups.py:87] blocks.0.0.mlp.fc2.weight: lr_multiplier: 0.2824295364810001, wd_multiplier: 1.0
I20240512 12:44:02 1248064 dinov2 param_groups.py:87] blocks.0.0.mlp.fc2.bias: lr_multiplier: 0.2824295364810001, wd_multiplier: 0.0
I20240512 12:44:02 1248064 dinov2 param_groups.py:87] blocks.0.0.ls2.gamma: lr_multiplier: 0.2824295364810001, wd_multiplier: 0.0
I20240512 12:44:02 1248064 dinov2 param_groups.py:87] blocks.0.1.norm1.weight: lr_multiplier: 0.31381059609000006, wd_multiplier: 0.0
I20240512 12:44:02 1248064 dinov2 param_groups.py:87] blocks.0.1.norm1.bias: lr_multiplier: 0.31381059609000006, wd_multiplier: 0.0
I20240512 12:44:02 1248064 dinov2 param_groups.py:87] blocks.0.1.attn.qkv.weight: lr_multiplier: 0.31381059609000006, wd_multiplier: 1.0
I20240512 12:44:02 1248064 dinov2 param_groups.py:87] blocks.0.1.attn.qkv.bias: lr_multiplier: 0.31381059609000006, wd_multiplier: 0.0
I20240512 12:44:02 1248064 dinov2 param_groups.py:87] blocks.0.1.attn.proj.weight: lr_multiplier: 0.31381059609000006, wd_multiplier: 1.0
I20240512 12:44:02 1248064 dinov2 param_groups.py:87] blocks.0.1.attn.proj.bias: lr_multiplier: 0.31381059609000006, wd_multiplier: 0.0
I20240512 12:44:02 1248064 dinov2 param_groups.py:87] blocks.0.1.ls1.gamma: lr_multiplier: 0.31381059609000006, wd_multiplier: 0.0
I20240512 12:44:02 1248064 dinov2 param_groups.py:87] blocks.0.1.norm2.weight: lr_multiplier: 0.31381059609000006, wd_multiplier: 0.0
I20240512 12:44:02 1248064 dinov2 param_groups.py:87] blocks.0.1.norm2.bias: lr_multiplier: 0.31381059609000006, wd_multiplier: 0.0
I20240512 12:44:02 1248064 dinov2 param_groups.py:87] blocks.0.1.mlp.fc1.weight: lr_multiplier: 0.31381059609000006, wd_multiplier: 1.0
I20240512 12:44:02 1248064 dinov2 param_groups.py:87] blocks.0.1.mlp.fc1.bias: lr_multiplier: 0.31381059609000006, wd_multiplier: 0.0
I20240512 12:44:02 1248064 dinov2 param_groups.py:87] blocks.0.1.mlp.fc2.weight: lr_multiplier: 0.31381059609000006, wd_multiplier: 1.0
I20240512 12:44:02 1248064 dinov2 param_groups.py:87] blocks.0.1.mlp.fc2.bias: lr_multiplier: 0.31381059609000006, wd_multiplier: 0.0
I20240512 12:44:02 1248064 dinov2 param_groups.py:87] blocks.0.1.ls2.gamma: lr_multiplier: 0.31381059609000006, wd_multiplier: 0.0
I20240512 12:44:02 1248064 dinov2 param_groups.py:87] blocks.0.2.norm1.weight: lr_multiplier: 0.3486784401000001, wd_multiplier: 0.0
I20240512 12:44:02 1248064 dinov2 param_groups.py:87] blocks.0.2.norm1.bias: lr_multiplier: 0.3486784401000001, wd_multiplier: 0.0
I20240512 12:44:02 1248064 dinov2 param_groups.py:87] blocks.0.2.attn.qkv.weight: lr_multiplier: 0.3486784401000001, wd_multiplier: 1.0
I20240512 12:44:02 1248064 dinov2 param_groups.py:87] blocks.0.2.attn.qkv.bias: lr_multiplier: 0.3486784401000001, wd_multiplier: 0.0
I20240512 12:44:02 1248064 dinov2 param_groups.py:87] blocks.0.2.attn.proj.weight: lr_multiplier: 0.3486784401000001, wd_multiplier: 1.0
I20240512 12:44:02 1248064 dinov2 param_groups.py:87] blocks.0.2.attn.proj.bias: lr_multiplier: 0.3486784401000001, wd_multiplier: 0.0
I20240512 12:44:02 1248064 dinov2 param_groups.py:87] blocks.0.2.ls1.gamma: lr_multiplier: 0.3486784401000001, wd_multiplier: 0.0
I20240512 12:44:02 1248064 dinov2 param_groups.py:87] blocks.0.2.norm2.weight: lr_multiplier: 0.3486784401000001, wd_multiplier: 0.0
I20240512 12:44:02 1248064 dinov2 param_groups.py:87] blocks.0.2.norm2.bias: lr_multiplier: 0.3486784401000001, wd_multiplier: 0.0
I20240512 12:44:02 1248064 dinov2 param_groups.py:87] blocks.0.2.mlp.fc1.weight: lr_multiplier: 0.3486784401000001, wd_multiplier: 1.0
I20240512 12:44:02 1248064 dinov2 param_groups.py:87] blocks.0.2.mlp.fc1.bias: lr_multiplier: 0.3486784401000001, wd_multiplier: 0.0
I20240512 12:44:02 1248064 dinov2 param_groups.py:87] blocks.0.2.mlp.fc2.weight: lr_multiplier: 0.3486784401000001, wd_multiplier: 1.0
I20240512 12:44:02 1248064 dinov2 param_groups.py:87] blocks.0.2.mlp.fc2.bias: lr_multiplier: 0.3486784401000001, wd_multiplier: 0.0
I20240512 12:44:02 1248064 dinov2 param_groups.py:87] blocks.0.2.ls2.gamma: lr_multiplier: 0.3486784401000001, wd_multiplier: 0.0
I20240512 12:44:02 1248064 dinov2 param_groups.py:87] blocks.1.3.norm1.weight: lr_multiplier: 0.3874204890000001, wd_multiplier: 0.0
I20240512 12:44:02 1248064 dinov2 param_groups.py:87] blocks.1.3.norm1.bias: lr_multiplier: 0.3874204890000001, wd_multiplier: 0.0
I20240512 12:44:02 1248064 dinov2 param_groups.py:87] blocks.1.3.attn.qkv.weight: lr_multiplier: 0.3874204890000001, wd_multiplier: 1.0
I20240512 12:44:02 1248064 dinov2 param_groups.py:87] blocks.1.3.attn.qkv.bias: lr_multiplier: 0.3874204890000001, wd_multiplier: 0.0
I20240512 12:44:02 1248064 dinov2 param_groups.py:87] blocks.1.3.attn.proj.weight: lr_multiplier: 0.3874204890000001, wd_multiplier: 1.0
I20240512 12:44:02 1248064 dinov2 param_groups.py:87] blocks.1.3.attn.proj.bias: lr_multiplier: 0.3874204890000001, wd_multiplier: 0.0
I20240512 12:44:02 1248064 dinov2 param_groups.py:87] blocks.1.3.ls1.gamma: lr_multiplier: 0.3874204890000001, wd_multiplier: 0.0
I20240512 12:44:02 1248064 dinov2 param_groups.py:87] blocks.1.3.norm2.weight: lr_multiplier: 0.3874204890000001, wd_multiplier: 0.0
I20240512 12:44:02 1248064 dinov2 param_groups.py:87] blocks.1.3.norm2.bias: lr_multiplier: 0.3874204890000001, wd_multiplier: 0.0
I20240512 12:44:02 1248064 dinov2 param_groups.py:87] blocks.1.3.mlp.fc1.weight: lr_multiplier: 0.3874204890000001, wd_multiplier: 1.0
I20240512 12:44:02 1248064 dinov2 param_groups.py:87] blocks.1.3.mlp.fc1.bias: lr_multiplier: 0.3874204890000001, wd_multiplier: 0.0
I20240512 12:44:02 1248064 dinov2 param_groups.py:87] blocks.1.3.mlp.fc2.weight: lr_multiplier: 0.3874204890000001, wd_multiplier: 1.0
I20240512 12:44:02 1248064 dinov2 param_groups.py:87] blocks.1.3.mlp.fc2.bias: lr_multiplier: 0.3874204890000001, wd_multiplier: 0.0
I20240512 12:44:02 1248064 dinov2 param_groups.py:87] blocks.1.3.ls2.gamma: lr_multiplier: 0.3874204890000001, wd_multiplier: 0.0
I20240512 12:44:02 1248064 dinov2 param_groups.py:87] blocks.1.4.norm1.weight: lr_multiplier: 0.4304672100000001, wd_multiplier: 0.0
I20240512 12:44:02 1248064 dinov2 param_groups.py:87] blocks.1.4.norm1.bias: lr_multiplier: 0.4304672100000001, wd_multiplier: 0.0
I20240512 12:44:02 1248064 dinov2 param_groups.py:87] blocks.1.4.attn.qkv.weight: lr_multiplier: 0.4304672100000001, wd_multiplier: 1.0
I20240512 12:44:02 1248064 dinov2 param_groups.py:87] blocks.1.4.attn.qkv.bias: lr_multiplier: 0.4304672100000001, wd_multiplier: 0.0
I20240512 12:44:02 1248064 dinov2 param_groups.py:87] blocks.1.4.attn.proj.weight: lr_multiplier: 0.4304672100000001, wd_multiplier: 1.0
I20240512 12:44:02 1248064 dinov2 param_groups.py:87] blocks.1.4.attn.proj.bias: lr_multiplier: 0.4304672100000001, wd_multiplier: 0.0
I20240512 12:44:02 1248064 dinov2 param_groups.py:87] blocks.1.4.ls1.gamma: lr_multiplier: 0.4304672100000001, wd_multiplier: 0.0
I20240512 12:44:02 1248064 dinov2 param_groups.py:87] blocks.1.4.norm2.weight: lr_multiplier: 0.4304672100000001, wd_multiplier: 0.0
I20240512 12:44:02 1248064 dinov2 param_groups.py:87] blocks.1.4.norm2.bias: lr_multiplier: 0.4304672100000001, wd_multiplier: 0.0
I20240512 12:44:02 1248064 dinov2 param_groups.py:87] blocks.1.4.mlp.fc1.weight: lr_multiplier: 0.4304672100000001, wd_multiplier: 1.0
I20240512 12:44:02 1248064 dinov2 param_groups.py:87] blocks.1.4.mlp.fc1.bias: lr_multiplier: 0.4304672100000001, wd_multiplier: 0.0
I20240512 12:44:02 1248064 dinov2 param_groups.py:87] blocks.1.4.mlp.fc2.weight: lr_multiplier: 0.4304672100000001, wd_multiplier: 1.0
I20240512 12:44:02 1248064 dinov2 param_groups.py:87] blocks.1.4.mlp.fc2.bias: lr_multiplier: 0.4304672100000001, wd_multiplier: 0.0
I20240512 12:44:02 1248064 dinov2 param_groups.py:87] blocks.1.4.ls2.gamma: lr_multiplier: 0.4304672100000001, wd_multiplier: 0.0
I20240512 12:44:02 1248064 dinov2 param_groups.py:87] blocks.1.5.norm1.weight: lr_multiplier: 0.4782969000000001, wd_multiplier: 0.0
I20240512 12:44:02 1248064 dinov2 param_groups.py:87] blocks.1.5.norm1.bias: lr_multiplier: 0.4782969000000001, wd_multiplier: 0.0
I20240512 12:44:02 1248064 dinov2 param_groups.py:87] blocks.1.5.attn.qkv.weight: lr_multiplier: 0.4782969000000001, wd_multiplier: 1.0
I20240512 12:44:02 1248064 dinov2 param_groups.py:87] blocks.1.5.attn.qkv.bias: lr_multiplier: 0.4782969000000001, wd_multiplier: 0.0
I20240512 12:44:02 1248064 dinov2 param_groups.py:87] blocks.1.5.attn.proj.weight: lr_multiplier: 0.4782969000000001, wd_multiplier: 1.0
I20240512 12:44:02 1248064 dinov2 param_groups.py:87] blocks.1.5.attn.proj.bias: lr_multiplier: 0.4782969000000001, wd_multiplier: 0.0
I20240512 12:44:02 1248064 dinov2 param_groups.py:87] blocks.1.5.ls1.gamma: lr_multiplier: 0.4782969000000001, wd_multiplier: 0.0
I20240512 12:44:02 1248064 dinov2 param_groups.py:87] blocks.1.5.norm2.weight: lr_multiplier: 0.4782969000000001, wd_multiplier: 0.0
I20240512 12:44:02 1248064 dinov2 param_groups.py:87] blocks.1.5.norm2.bias: lr_multiplier: 0.4782969000000001, wd_multiplier: 0.0
I20240512 12:44:02 1248064 dinov2 param_groups.py:87] blocks.1.5.mlp.fc1.weight: lr_multiplier: 0.4782969000000001, wd_multiplier: 1.0
I20240512 12:44:02 1248064 dinov2 param_groups.py:87] blocks.1.5.mlp.fc1.bias: lr_multiplier: 0.4782969000000001, wd_multiplier: 0.0
I20240512 12:44:02 1248064 dinov2 param_groups.py:87] blocks.1.5.mlp.fc2.weight: lr_multiplier: 0.4782969000000001, wd_multiplier: 1.0
I20240512 12:44:02 1248064 dinov2 param_groups.py:87] blocks.1.5.mlp.fc2.bias: lr_multiplier: 0.4782969000000001, wd_multiplier: 0.0
I20240512 12:44:02 1248064 dinov2 param_groups.py:87] blocks.1.5.ls2.gamma: lr_multiplier: 0.4782969000000001, wd_multiplier: 0.0
I20240512 12:44:02 1248064 dinov2 param_groups.py:87] blocks.2.6.norm1.weight: lr_multiplier: 0.531441, wd_multiplier: 0.0
I20240512 12:44:02 1248064 dinov2 param_groups.py:87] blocks.2.6.norm1.bias: lr_multiplier: 0.531441, wd_multiplier: 0.0
I20240512 12:44:02 1248064 dinov2 param_groups.py:87] blocks.2.6.attn.qkv.weight: lr_multiplier: 0.531441, wd_multiplier: 1.0
I20240512 12:44:02 1248064 dinov2 param_groups.py:87] blocks.2.6.attn.qkv.bias: lr_multiplier: 0.531441, wd_multiplier: 0.0
I20240512 12:44:02 1248064 dinov2 param_groups.py:87] blocks.2.6.attn.proj.weight: lr_multiplier: 0.531441, wd_multiplier: 1.0
I20240512 12:44:02 1248064 dinov2 param_groups.py:87] blocks.2.6.attn.proj.bias: lr_multiplier: 0.531441, wd_multiplier: 0.0
I20240512 12:44:02 1248064 dinov2 param_groups.py:87] blocks.2.6.ls1.gamma: lr_multiplier: 0.531441, wd_multiplier: 0.0
I20240512 12:44:02 1248064 dinov2 param_groups.py:87] blocks.2.6.norm2.weight: lr_multiplier: 0.531441, wd_multiplier: 0.0
I20240512 12:44:02 1248064 dinov2 param_groups.py:87] blocks.2.6.norm2.bias: lr_multiplier: 0.531441, wd_multiplier: 0.0
I20240512 12:44:02 1248064 dinov2 param_groups.py:87] blocks.2.6.mlp.fc1.weight: lr_multiplier: 0.531441, wd_multiplier: 1.0
I20240512 12:44:02 1248064 dinov2 param_groups.py:87] blocks.2.6.mlp.fc1.bias: lr_multiplier: 0.531441, wd_multiplier: 0.0
I20240512 12:44:02 1248064 dinov2 param_groups.py:87] blocks.2.6.mlp.fc2.weight: lr_multiplier: 0.531441, wd_multiplier: 1.0
I20240512 12:44:02 1248064 dinov2 param_groups.py:87] blocks.2.6.mlp.fc2.bias: lr_multiplier: 0.531441, wd_multiplier: 0.0
I20240512 12:44:02 1248064 dinov2 param_groups.py:87] blocks.2.6.ls2.gamma: lr_multiplier: 0.531441, wd_multiplier: 0.0
I20240512 12:44:02 1248064 dinov2 param_groups.py:87] blocks.2.7.norm1.weight: lr_multiplier: 0.5904900000000001, wd_multiplier: 0.0
I20240512 12:44:02 1248064 dinov2 param_groups.py:87] blocks.2.7.norm1.bias: lr_multiplier: 0.5904900000000001, wd_multiplier: 0.0
I20240512 12:44:02 1248064 dinov2 param_groups.py:87] blocks.2.7.attn.qkv.weight: lr_multiplier: 0.5904900000000001, wd_multiplier: 1.0
I20240512 12:44:02 1248064 dinov2 param_groups.py:87] blocks.2.7.attn.qkv.bias: lr_multiplier: 0.5904900000000001, wd_multiplier: 0.0
I20240512 12:44:02 1248064 dinov2 param_groups.py:87] blocks.2.7.attn.proj.weight: lr_multiplier: 0.5904900000000001, wd_multiplier: 1.0
I20240512 12:44:02 1248064 dinov2 param_groups.py:87] blocks.2.7.attn.proj.bias: lr_multiplier: 0.5904900000000001, wd_multiplier: 0.0
I20240512 12:44:02 1248064 dinov2 param_groups.py:87] blocks.2.7.ls1.gamma: lr_multiplier: 0.5904900000000001, wd_multiplier: 0.0
I20240512 12:44:02 1248064 dinov2 param_groups.py:87] blocks.2.7.norm2.weight: lr_multiplier: 0.5904900000000001, wd_multiplier: 0.0
I20240512 12:44:02 1248064 dinov2 param_groups.py:87] blocks.2.7.norm2.bias: lr_multiplier: 0.5904900000000001, wd_multiplier: 0.0
I20240512 12:44:02 1248064 dinov2 param_groups.py:87] blocks.2.7.mlp.fc1.weight: lr_multiplier: 0.5904900000000001, wd_multiplier: 1.0
I20240512 12:44:02 1248064 dinov2 param_groups.py:87] blocks.2.7.mlp.fc1.bias: lr_multiplier: 0.5904900000000001, wd_multiplier: 0.0
I20240512 12:44:02 1248064 dinov2 param_groups.py:87] blocks.2.7.mlp.fc2.weight: lr_multiplier: 0.5904900000000001, wd_multiplier: 1.0
I20240512 12:44:02 1248064 dinov2 param_groups.py:87] blocks.2.7.mlp.fc2.bias: lr_multiplier: 0.5904900000000001, wd_multiplier: 0.0
I20240512 12:44:02 1248064 dinov2 param_groups.py:87] blocks.2.7.ls2.gamma: lr_multiplier: 0.5904900000000001, wd_multiplier: 0.0
I20240512 12:44:02 1248064 dinov2 param_groups.py:87] blocks.2.8.norm1.weight: lr_multiplier: 0.6561, wd_multiplier: 0.0
I20240512 12:44:02 1248064 dinov2 param_groups.py:87] blocks.2.8.norm1.bias: lr_multiplier: 0.6561, wd_multiplier: 0.0
I20240512 12:44:02 1248064 dinov2 param_groups.py:87] blocks.2.8.attn.qkv.weight: lr_multiplier: 0.6561, wd_multiplier: 1.0
I20240512 12:44:02 1248064 dinov2 param_groups.py:87] blocks.2.8.attn.qkv.bias: lr_multiplier: 0.6561, wd_multiplier: 0.0
I20240512 12:44:02 1248064 dinov2 param_groups.py:87] blocks.2.8.attn.proj.weight: lr_multiplier: 0.6561, wd_multiplier: 1.0
I20240512 12:44:02 1248064 dinov2 param_groups.py:87] blocks.2.8.attn.proj.bias: lr_multiplier: 0.6561, wd_multiplier: 0.0
I20240512 12:44:02 1248064 dinov2 param_groups.py:87] blocks.2.8.ls1.gamma: lr_multiplier: 0.6561, wd_multiplier: 0.0
I20240512 12:44:02 1248064 dinov2 param_groups.py:87] blocks.2.8.norm2.weight: lr_multiplier: 0.6561, wd_multiplier: 0.0
I20240512 12:44:02 1248064 dinov2 param_groups.py:87] blocks.2.8.norm2.bias: lr_multiplier: 0.6561, wd_multiplier: 0.0
I20240512 12:44:02 1248064 dinov2 param_groups.py:87] blocks.2.8.mlp.fc1.weight: lr_multiplier: 0.6561, wd_multiplier: 1.0
I20240512 12:44:02 1248064 dinov2 param_groups.py:87] blocks.2.8.mlp.fc1.bias: lr_multiplier: 0.6561, wd_multiplier: 0.0
I20240512 12:44:02 1248064 dinov2 param_groups.py:87] blocks.2.8.mlp.fc2.weight: lr_multiplier: 0.6561, wd_multiplier: 1.0
I20240512 12:44:02 1248064 dinov2 param_groups.py:87] blocks.2.8.mlp.fc2.bias: lr_multiplier: 0.6561, wd_multiplier: 0.0
I20240512 12:44:02 1248064 dinov2 param_groups.py:87] blocks.2.8.ls2.gamma: lr_multiplier: 0.6561, wd_multiplier: 0.0
I20240512 12:44:02 1248064 dinov2 param_groups.py:87] blocks.3.9.norm1.weight: lr_multiplier: 0.7290000000000001, wd_multiplier: 0.0
I20240512 12:44:02 1248064 dinov2 param_groups.py:87] blocks.3.9.norm1.bias: lr_multiplier: 0.7290000000000001, wd_multiplier: 0.0
I20240512 12:44:02 1248064 dinov2 param_groups.py:87] blocks.3.9.attn.qkv.weight: lr_multiplier: 0.7290000000000001, wd_multiplier: 1.0
I20240512 12:44:02 1248064 dinov2 param_groups.py:87] blocks.3.9.attn.qkv.bias: lr_multiplier: 0.7290000000000001, wd_multiplier: 0.0
I20240512 12:44:02 1248064 dinov2 param_groups.py:87] blocks.3.9.attn.proj.weight: lr_multiplier: 0.7290000000000001, wd_multiplier: 1.0
I20240512 12:44:02 1248064 dinov2 param_groups.py:87] blocks.3.9.attn.proj.bias: lr_multiplier: 0.7290000000000001, wd_multiplier: 0.0
I20240512 12:44:02 1248064 dinov2 param_groups.py:87] blocks.3.9.ls1.gamma: lr_multiplier: 0.7290000000000001, wd_multiplier: 0.0
I20240512 12:44:02 1248064 dinov2 param_groups.py:87] blocks.3.9.norm2.weight: lr_multiplier: 0.7290000000000001, wd_multiplier: 0.0
I20240512 12:44:02 1248064 dinov2 param_groups.py:87] blocks.3.9.norm2.bias: lr_multiplier: 0.7290000000000001, wd_multiplier: 0.0
I20240512 12:44:02 1248064 dinov2 param_groups.py:87] blocks.3.9.mlp.fc1.weight: lr_multiplier: 0.7290000000000001, wd_multiplier: 1.0
I20240512 12:44:02 1248064 dinov2 param_groups.py:87] blocks.3.9.mlp.fc1.bias: lr_multiplier: 0.7290000000000001, wd_multiplier: 0.0
I20240512 12:44:02 1248064 dinov2 param_groups.py:87] blocks.3.9.mlp.fc2.weight: lr_multiplier: 0.7290000000000001, wd_multiplier: 1.0
I20240512 12:44:02 1248064 dinov2 param_groups.py:87] blocks.3.9.mlp.fc2.bias: lr_multiplier: 0.7290000000000001, wd_multiplier: 0.0
I20240512 12:44:02 1248064 dinov2 param_groups.py:87] blocks.3.9.ls2.gamma: lr_multiplier: 0.7290000000000001, wd_multiplier: 0.0
I20240512 12:44:02 1248064 dinov2 param_groups.py:87] blocks.3.10.norm1.weight: lr_multiplier: 0.81, wd_multiplier: 0.0
I20240512 12:44:02 1248064 dinov2 param_groups.py:87] blocks.3.10.norm1.bias: lr_multiplier: 0.81, wd_multiplier: 0.0
I20240512 12:44:02 1248064 dinov2 param_groups.py:87] blocks.3.10.attn.qkv.weight: lr_multiplier: 0.81, wd_multiplier: 1.0
I20240512 12:44:02 1248064 dinov2 param_groups.py:87] blocks.3.10.attn.qkv.bias: lr_multiplier: 0.81, wd_multiplier: 0.0
I20240512 12:44:02 1248064 dinov2 param_groups.py:87] blocks.3.10.attn.proj.weight: lr_multiplier: 0.81, wd_multiplier: 1.0
I20240512 12:44:02 1248064 dinov2 param_groups.py:87] blocks.3.10.attn.proj.bias: lr_multiplier: 0.81, wd_multiplier: 0.0
I20240512 12:44:02 1248064 dinov2 param_groups.py:87] blocks.3.10.ls1.gamma: lr_multiplier: 0.81, wd_multiplier: 0.0
I20240512 12:44:02 1248064 dinov2 param_groups.py:87] blocks.3.10.norm2.weight: lr_multiplier: 0.81, wd_multiplier: 0.0
I20240512 12:44:02 1248064 dinov2 param_groups.py:87] blocks.3.10.norm2.bias: lr_multiplier: 0.81, wd_multiplier: 0.0
I20240512 12:44:02 1248064 dinov2 param_groups.py:87] blocks.3.10.mlp.fc1.weight: lr_multiplier: 0.81, wd_multiplier: 1.0
I20240512 12:44:02 1248064 dinov2 param_groups.py:87] blocks.3.10.mlp.fc1.bias: lr_multiplier: 0.81, wd_multiplier: 0.0
I20240512 12:44:02 1248064 dinov2 param_groups.py:87] blocks.3.10.mlp.fc2.weight: lr_multiplier: 0.81, wd_multiplier: 1.0
I20240512 12:44:02 1248064 dinov2 param_groups.py:87] blocks.3.10.mlp.fc2.bias: lr_multiplier: 0.81, wd_multiplier: 0.0
I20240512 12:44:02 1248064 dinov2 param_groups.py:87] blocks.3.10.ls2.gamma: lr_multiplier: 0.81, wd_multiplier: 0.0
I20240512 12:44:02 1248064 dinov2 param_groups.py:87] blocks.3.11.norm1.weight: lr_multiplier: 0.9, wd_multiplier: 0.0
I20240512 12:44:02 1248064 dinov2 param_groups.py:87] blocks.3.11.norm1.bias: lr_multiplier: 0.9, wd_multiplier: 0.0
I20240512 12:44:02 1248064 dinov2 param_groups.py:87] blocks.3.11.attn.qkv.weight: lr_multiplier: 0.9, wd_multiplier: 1.0
I20240512 12:44:02 1248064 dinov2 param_groups.py:87] blocks.3.11.attn.qkv.bias: lr_multiplier: 0.9, wd_multiplier: 0.0
I20240512 12:44:02 1248064 dinov2 param_groups.py:87] blocks.3.11.attn.proj.weight: lr_multiplier: 0.9, wd_multiplier: 1.0
I20240512 12:44:02 1248064 dinov2 param_groups.py:87] blocks.3.11.attn.proj.bias: lr_multiplier: 0.9, wd_multiplier: 0.0
I20240512 12:44:02 1248064 dinov2 param_groups.py:87] blocks.3.11.ls1.gamma: lr_multiplier: 0.9, wd_multiplier: 0.0
I20240512 12:44:02 1248064 dinov2 param_groups.py:87] blocks.3.11.norm2.weight: lr_multiplier: 0.9, wd_multiplier: 0.0
I20240512 12:44:02 1248064 dinov2 param_groups.py:87] blocks.3.11.norm2.bias: lr_multiplier: 0.9, wd_multiplier: 0.0
I20240512 12:44:02 1248064 dinov2 param_groups.py:87] blocks.3.11.mlp.fc1.weight: lr_multiplier: 0.9, wd_multiplier: 1.0
I20240512 12:44:02 1248064 dinov2 param_groups.py:87] blocks.3.11.mlp.fc1.bias: lr_multiplier: 0.9, wd_multiplier: 0.0
I20240512 12:44:02 1248064 dinov2 param_groups.py:87] blocks.3.11.mlp.fc2.weight: lr_multiplier: 0.9, wd_multiplier: 1.0
I20240512 12:44:02 1248064 dinov2 param_groups.py:87] blocks.3.11.mlp.fc2.bias: lr_multiplier: 0.9, wd_multiplier: 0.0
I20240512 12:44:02 1248064 dinov2 param_groups.py:87] blocks.3.11.ls2.gamma: lr_multiplier: 0.9, wd_multiplier: 0.0
I20240512 12:44:02 1248064 dinov2 param_groups.py:87] norm.weight: lr_multiplier: 1.0, wd_multiplier: 0.0
I20240512 12:44:02 1248064 dinov2 param_groups.py:87] norm.bias: lr_multiplier: 1.0, wd_multiplier: 0.0
I20240512 12:44:02 1248064 dinov2 ssl_meta_arch.py:378] fusing param groups
I20240512 12:44:02 1248064 dinov2 param_groups.py:64] else code branch
I20240512 12:44:02 1248064 dinov2 param_groups.py:87] mlp.0.weight: lr_multiplier: 1.0, wd_multiplier: 1.0
I20240512 12:44:02 1248064 dinov2 param_groups.py:87] mlp.0.bias: lr_multiplier: 1.0, wd_multiplier: 0.0
I20240512 12:44:02 1248064 dinov2 param_groups.py:87] mlp.2.weight: lr_multiplier: 1.0, wd_multiplier: 1.0
I20240512 12:44:02 1248064 dinov2 param_groups.py:87] mlp.2.bias: lr_multiplier: 1.0, wd_multiplier: 0.0
I20240512 12:44:02 1248064 dinov2 param_groups.py:87] mlp.4.weight: lr_multiplier: 1.0, wd_multiplier: 1.0
I20240512 12:44:02 1248064 dinov2 param_groups.py:87] mlp.4.bias: lr_multiplier: 1.0, wd_multiplier: 0.0
I20240512 12:44:02 1248064 dinov2 param_groups.py:87] last_layer.weight_g: lr_multiplier: 1.0, wd_multiplier: 1.0
I20240512 12:44:02 1248064 dinov2 param_groups.py:87] last_layer.weight_v: lr_multiplier: 1.0, wd_multiplier: 1.0
I20240512 12:44:02 1248064 dinov2 ssl_meta_arch.py:378] fusing param groups
I20240512 12:44:02 1248064 dinov2 train.py:102] Schedulers ready.
I20240512 12:44:02 1248064 fvcore.common.checkpoint checkpoint.py:148] No checkpoint found. Initializing model from scratch
I20240512 12:44:02 1248064 dinov2 augmentations.py:34] ###################################
I20240512 12:44:02 1248064 dinov2 augmentations.py:35] Using data augmentation parameters:
I20240512 12:44:02 1248064 dinov2 augmentations.py:36] global_crops_scale: [0.32, 1.0]
I20240512 12:44:02 1248064 dinov2 augmentations.py:37] local_crops_scale: [0.05, 0.32]
I20240512 12:44:02 1248064 dinov2 augmentations.py:38] local_crops_number: 8
I20240512 12:44:02 1248064 dinov2 augmentations.py:39] global_crops_size: 224
I20240512 12:44:02 1248064 dinov2 augmentations.py:40] local_crops_size: 96
I20240512 12:44:02 1248064 dinov2 augmentations.py:41] ###################################
I20240512 13:01:03 1248064 dinov2 loaders.py:122] sampler: sharded infinite
I20240512 13:01:03 1248064 dinov2 loaders.py:206] using PyTorch data loader
I20240512 13:01:03 1248064 dinov2 loaders.py:221] infinite data loader
I20240512 15:21:13 3636382 dinov2 config.py:59] git:
  sha: e1277af2ba9496fbadf7aec6eba56e8d882d1e35, status: has uncommitted changes, branch: main

I20240512 15:21:13 3636382 dinov2 config.py:60] config_file: config_test2.yaml
eval: 
eval_only: False
no_resume: False
opts: ['train.output_dir=/home/guevel/OT4D/cell_similarity/src/cell_similarity/scripts']
output_dir: /home/guevel/OT4D/cell_similarity/src/cell_similarity/scripts
I20240512 15:21:13 3636382 dinov2 config.py:26] sqrt scaling learning rate; base: 0.004, new: 0.0007071067811865476
I20240512 15:21:13 3636382 dinov2 config.py:33] MODEL:
  WEIGHTS: ''
compute_precision:
  grad_scaler: true
  teacher:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
  student:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
dino:
  loss_weight: 1.0
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
  koleo_loss_weight: 0.1
ibot:
  loss_weight: 1.0
  mask_sample_probability: 0.5
  mask_ratio_min_max:
  - 0.1
  - 0.5
  separate_head: false
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
train:
  batch_size_per_gpu: 32
  dataset_path: /home/manon/classification/data/Single_cells/medhi
  output_dir: /home/guevel/OT4D/cell_similarity/src/cell_similarity/scripts
  saveckp_freq: 20
  seed: 0
  num_workers: 10
  OFFICIAL_EPOCH_LENGTH: 20
  cache_dataset: true
  centering: centering
student:
  arch: vit_large
  patch_size: 16
  drop_path_rate: 0.3
  layerscale: 1.0e-05
  drop_path_uniform: true
  pretrained_weights: ''
  ffn_layer: mlp
  block_chunks: 4
  qkv_bias: true
  proj_bias: true
  ffn_bias: true
  num_register_tokens: 0
  interpolate_antialias: false
  interpolate_offset: 0.1
teacher:
  momentum_teacher: 0.992
  final_momentum_teacher: 1
  warmup_teacher_temp: 0.04
  teacher_temp: 0.07
  warmup_teacher_temp_epochs: 30
optim:
  epochs: 100
  weight_decay: 0.04
  weight_decay_end: 0.4
  base_lr: 0.004
  lr: 0.0007071067811865476
  warmup_epochs: 10
  min_lr: 1.0e-06
  clip_grad: 3.0
  freeze_last_layer_epochs: 1
  scaling_rule: sqrt_wrt_1024
  patch_embed_lr_mult: 0.2
  layerwise_decay: 0.9
  adamw_beta1: 0.9
  adamw_beta2: 0.999
crops:
  global_crops_scale:
  - 0.32
  - 1.0
  local_crops_number: 8
  local_crops_scale:
  - 0.05
  - 0.32
  global_crops_size: 224
  local_crops_size: 96
evaluation:
  eval_period_iterations: 12500

I20240512 15:21:13 3636382 dinov2 vision_transformer.py:122] using MLP layer as FFN
I20240512 15:21:16 3636382 dinov2 vision_transformer.py:122] using MLP layer as FFN
I20240512 15:21:20 3636382 dinov2 ssl_meta_arch.py:43] OPTIONS -- architecture : embed_dim: 1024
I20240512 15:21:20 3636382 dinov2 ssl_meta_arch.py:58] OPTIONS -- DINO
I20240512 15:21:20 3636382 dinov2 ssl_meta_arch.py:60] OPTIONS -- DINO -- loss_weight: 1.0
I20240512 15:21:20 3636382 dinov2 ssl_meta_arch.py:61] OPTIONS -- DINO -- head_n_prototypes: 65536
I20240512 15:21:20 3636382 dinov2 ssl_meta_arch.py:62] OPTIONS -- DINO -- head_bottleneck_dim: 256
I20240512 15:21:20 3636382 dinov2 ssl_meta_arch.py:63] OPTIONS -- DINO -- head_hidden_dim: 2048
I20240512 15:21:20 3636382 dinov2 ssl_meta_arch.py:75] OPTIONS -- DINO -- applying KOLEO regularization
I20240512 15:21:20 3636382 dinov2 ssl_meta_arch.py:85] OPTIONS -- IBOT
I20240512 15:21:20 3636382 dinov2 ssl_meta_arch.py:86] OPTIONS -- IBOT -- loss_weight: 1.0
I20240512 15:21:20 3636382 dinov2 ssl_meta_arch.py:87] OPTIONS -- IBOT masking -- ibot_mask_ratio_tuple: [0.1, 0.5]
I20240512 15:21:20 3636382 dinov2 ssl_meta_arch.py:88] OPTIONS -- IBOT masking -- ibot_mask_sample_probability: 0.5
I20240512 15:21:20 3636382 dinov2 ssl_meta_arch.py:111] OPTIONS -- IBOT -- head shared with DINO
I20240512 15:21:20 3636382 dinov2 ssl_meta_arch.py:121] Student and Teacher are built: they are both vit_large network.
I20240512 15:21:21 3636382 dinov2 ssl_meta_arch.py:391] DISTRIBUTED FSDP -- preparing model for distributed training
W20240512 15:21:21 3636382 py.warnings warnings.py:109] /home/guevel/.conda/envs/dinov2/lib/python3.9/site-packages/torch/distributed/fsdp/_init_utils.py:295: UserWarning: FSDP is switching to use `NO_SHARD` instead of ShardingStrategy.SHARD_GRAD_OP since the world size is 1.
  warnings.warn(

I20240512 15:21:21 3636382 dinov2 memory_test2.py:17] Model:
SSLMetaArch(
  (dino_loss): DINOLoss()
  (koleo_loss): KoLeoLoss(
    (pdist): PairwiseDistance()
  )
  (ibot_patch_loss): iBOTPatchLoss()
  (student): ModuleDict(
    (backbone): FullyShardedDataParallel(
      (_fsdp_wrapped_module): DinoVisionTransformer(
        (patch_embed): PatchEmbed(
          (proj): Conv2d(3, 1024, kernel_size=(16, 16), stride=(16, 16))
          (norm): Identity()
        )
        (blocks): ModuleList(
          (0): FullyShardedDataParallel(
            (_fsdp_wrapped_module): BlockChunk(
              (0-5): 6 x NestedTensorBlock(
                (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
                (attn): MemEffAttention(
                  (qkv): Linear(in_features=1024, out_features=3072, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=1024, out_features=1024, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                )
                (ls1): LayerScale()
                (drop_path1): DropPath()
                (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=1024, out_features=4096, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=4096, out_features=1024, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
                (ls2): LayerScale()
                (drop_path2): DropPath()
              )
            )
          )
          (1): FullyShardedDataParallel(
            (_fsdp_wrapped_module): BlockChunk(
              (0-5): 6 x Identity()
              (6-11): 6 x NestedTensorBlock(
                (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
                (attn): MemEffAttention(
                  (qkv): Linear(in_features=1024, out_features=3072, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=1024, out_features=1024, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                )
                (ls1): LayerScale()
                (drop_path1): DropPath()
                (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=1024, out_features=4096, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=4096, out_features=1024, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
                (ls2): LayerScale()
                (drop_path2): DropPath()
              )
            )
          )
          (2): FullyShardedDataParallel(
            (_fsdp_wrapped_module): BlockChunk(
              (0-11): 12 x Identity()
              (12-17): 6 x NestedTensorBlock(
                (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
                (attn): MemEffAttention(
                  (qkv): Linear(in_features=1024, out_features=3072, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=1024, out_features=1024, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                )
                (ls1): LayerScale()
                (drop_path1): DropPath()
                (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=1024, out_features=4096, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=4096, out_features=1024, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
                (ls2): LayerScale()
                (drop_path2): DropPath()
              )
            )
          )
          (3): FullyShardedDataParallel(
            (_fsdp_wrapped_module): BlockChunk(
              (0-17): 18 x Identity()
              (18-23): 6 x NestedTensorBlock(
                (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
                (attn): MemEffAttention(
                  (qkv): Linear(in_features=1024, out_features=3072, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=1024, out_features=1024, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                )
                (ls1): LayerScale()
                (drop_path1): DropPath()
                (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=1024, out_features=4096, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=4096, out_features=1024, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
                (ls2): LayerScale()
                (drop_path2): DropPath()
              )
            )
          )
        )
        (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (head): Identity()
      )
    )
    (dino_head): FullyShardedDataParallel(
      (_fsdp_wrapped_module): DINOHead(
        (mlp): Sequential(
          (0): Linear(in_features=1024, out_features=2048, bias=True)
          (1): GELU(approximate='none')
          (2): Linear(in_features=2048, out_features=2048, bias=True)
          (3): GELU(approximate='none')
          (4): Linear(in_features=2048, out_features=256, bias=True)
        )
        (last_layer): Linear(in_features=256, out_features=65536, bias=False)
      )
    )
  )
  (teacher): ModuleDict(
    (backbone): FullyShardedDataParallel(
      (_fsdp_wrapped_module): DinoVisionTransformer(
        (patch_embed): PatchEmbed(
          (proj): Conv2d(3, 1024, kernel_size=(16, 16), stride=(16, 16))
          (norm): Identity()
        )
        (blocks): ModuleList(
          (0): FullyShardedDataParallel(
            (_fsdp_wrapped_module): BlockChunk(
              (0-5): 6 x NestedTensorBlock(
                (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
                (attn): MemEffAttention(
                  (qkv): Linear(in_features=1024, out_features=3072, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=1024, out_features=1024, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                )
                (ls1): LayerScale()
                (drop_path1): Identity()
                (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=1024, out_features=4096, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=4096, out_features=1024, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
                (ls2): LayerScale()
                (drop_path2): Identity()
              )
            )
          )
          (1): FullyShardedDataParallel(
            (_fsdp_wrapped_module): BlockChunk(
              (0-5): 6 x Identity()
              (6-11): 6 x NestedTensorBlock(
                (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
                (attn): MemEffAttention(
                  (qkv): Linear(in_features=1024, out_features=3072, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=1024, out_features=1024, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                )
                (ls1): LayerScale()
                (drop_path1): Identity()
                (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=1024, out_features=4096, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=4096, out_features=1024, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
                (ls2): LayerScale()
                (drop_path2): Identity()
              )
            )
          )
          (2): FullyShardedDataParallel(
            (_fsdp_wrapped_module): BlockChunk(
              (0-11): 12 x Identity()
              (12-17): 6 x NestedTensorBlock(
                (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
                (attn): MemEffAttention(
                  (qkv): Linear(in_features=1024, out_features=3072, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=1024, out_features=1024, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                )
                (ls1): LayerScale()
                (drop_path1): Identity()
                (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=1024, out_features=4096, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=4096, out_features=1024, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
                (ls2): LayerScale()
                (drop_path2): Identity()
              )
            )
          )
          (3): FullyShardedDataParallel(
            (_fsdp_wrapped_module): BlockChunk(
              (0-17): 18 x Identity()
              (18-23): 6 x NestedTensorBlock(
                (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
                (attn): MemEffAttention(
                  (qkv): Linear(in_features=1024, out_features=3072, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=1024, out_features=1024, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                )
                (ls1): LayerScale()
                (drop_path1): Identity()
                (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=1024, out_features=4096, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=4096, out_features=1024, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
                (ls2): LayerScale()
                (drop_path2): Identity()
              )
            )
          )
        )
        (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (head): Identity()
      )
    )
    (dino_head): FullyShardedDataParallel(
      (_fsdp_wrapped_module): DINOHead(
        (mlp): Sequential(
          (0): Linear(in_features=1024, out_features=2048, bias=True)
          (1): GELU(approximate='none')
          (2): Linear(in_features=2048, out_features=2048, bias=True)
          (3): GELU(approximate='none')
          (4): Linear(in_features=2048, out_features=256, bias=True)
        )
        (last_layer): Linear(in_features=256, out_features=65536, bias=False)
      )
    )
  )
)
I20240512 15:21:21 3636382 dinov2 param_groups.py:54] chunked fsdp
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] cls_token: lr_multiplier: 0.0717897987691853, wd_multiplier: 1.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] pos_embed: lr_multiplier: 0.0717897987691853, wd_multiplier: 1.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] mask_token: lr_multiplier: 0.0717897987691853, wd_multiplier: 1.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] patch_embed.proj.weight: lr_multiplier: 0.01435795975383706, wd_multiplier: 1.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] patch_embed.proj.bias: lr_multiplier: 0.01435795975383706, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.0.0.norm1.weight: lr_multiplier: 0.07976644307687256, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.0.0.norm1.bias: lr_multiplier: 0.07976644307687256, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.0.0.attn.qkv.weight: lr_multiplier: 0.07976644307687256, wd_multiplier: 1.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.0.0.attn.qkv.bias: lr_multiplier: 0.07976644307687256, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.0.0.attn.proj.weight: lr_multiplier: 0.07976644307687256, wd_multiplier: 1.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.0.0.attn.proj.bias: lr_multiplier: 0.07976644307687256, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.0.0.ls1.gamma: lr_multiplier: 0.07976644307687256, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.0.0.norm2.weight: lr_multiplier: 0.07976644307687256, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.0.0.norm2.bias: lr_multiplier: 0.07976644307687256, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.0.0.mlp.fc1.weight: lr_multiplier: 0.07976644307687256, wd_multiplier: 1.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.0.0.mlp.fc1.bias: lr_multiplier: 0.07976644307687256, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.0.0.mlp.fc2.weight: lr_multiplier: 0.07976644307687256, wd_multiplier: 1.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.0.0.mlp.fc2.bias: lr_multiplier: 0.07976644307687256, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.0.0.ls2.gamma: lr_multiplier: 0.07976644307687256, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.0.1.norm1.weight: lr_multiplier: 0.08862938119652507, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.0.1.norm1.bias: lr_multiplier: 0.08862938119652507, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.0.1.attn.qkv.weight: lr_multiplier: 0.08862938119652507, wd_multiplier: 1.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.0.1.attn.qkv.bias: lr_multiplier: 0.08862938119652507, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.0.1.attn.proj.weight: lr_multiplier: 0.08862938119652507, wd_multiplier: 1.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.0.1.attn.proj.bias: lr_multiplier: 0.08862938119652507, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.0.1.ls1.gamma: lr_multiplier: 0.08862938119652507, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.0.1.norm2.weight: lr_multiplier: 0.08862938119652507, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.0.1.norm2.bias: lr_multiplier: 0.08862938119652507, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.0.1.mlp.fc1.weight: lr_multiplier: 0.08862938119652507, wd_multiplier: 1.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.0.1.mlp.fc1.bias: lr_multiplier: 0.08862938119652507, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.0.1.mlp.fc2.weight: lr_multiplier: 0.08862938119652507, wd_multiplier: 1.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.0.1.mlp.fc2.bias: lr_multiplier: 0.08862938119652507, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.0.1.ls2.gamma: lr_multiplier: 0.08862938119652507, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.0.2.norm1.weight: lr_multiplier: 0.09847709021836118, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.0.2.norm1.bias: lr_multiplier: 0.09847709021836118, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.0.2.attn.qkv.weight: lr_multiplier: 0.09847709021836118, wd_multiplier: 1.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.0.2.attn.qkv.bias: lr_multiplier: 0.09847709021836118, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.0.2.attn.proj.weight: lr_multiplier: 0.09847709021836118, wd_multiplier: 1.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.0.2.attn.proj.bias: lr_multiplier: 0.09847709021836118, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.0.2.ls1.gamma: lr_multiplier: 0.09847709021836118, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.0.2.norm2.weight: lr_multiplier: 0.09847709021836118, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.0.2.norm2.bias: lr_multiplier: 0.09847709021836118, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.0.2.mlp.fc1.weight: lr_multiplier: 0.09847709021836118, wd_multiplier: 1.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.0.2.mlp.fc1.bias: lr_multiplier: 0.09847709021836118, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.0.2.mlp.fc2.weight: lr_multiplier: 0.09847709021836118, wd_multiplier: 1.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.0.2.mlp.fc2.bias: lr_multiplier: 0.09847709021836118, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.0.2.ls2.gamma: lr_multiplier: 0.09847709021836118, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.0.3.norm1.weight: lr_multiplier: 0.10941898913151242, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.0.3.norm1.bias: lr_multiplier: 0.10941898913151242, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.0.3.attn.qkv.weight: lr_multiplier: 0.10941898913151242, wd_multiplier: 1.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.0.3.attn.qkv.bias: lr_multiplier: 0.10941898913151242, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.0.3.attn.proj.weight: lr_multiplier: 0.10941898913151242, wd_multiplier: 1.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.0.3.attn.proj.bias: lr_multiplier: 0.10941898913151242, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.0.3.ls1.gamma: lr_multiplier: 0.10941898913151242, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.0.3.norm2.weight: lr_multiplier: 0.10941898913151242, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.0.3.norm2.bias: lr_multiplier: 0.10941898913151242, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.0.3.mlp.fc1.weight: lr_multiplier: 0.10941898913151242, wd_multiplier: 1.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.0.3.mlp.fc1.bias: lr_multiplier: 0.10941898913151242, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.0.3.mlp.fc2.weight: lr_multiplier: 0.10941898913151242, wd_multiplier: 1.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.0.3.mlp.fc2.bias: lr_multiplier: 0.10941898913151242, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.0.3.ls2.gamma: lr_multiplier: 0.10941898913151242, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.0.4.norm1.weight: lr_multiplier: 0.12157665459056935, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.0.4.norm1.bias: lr_multiplier: 0.12157665459056935, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.0.4.attn.qkv.weight: lr_multiplier: 0.12157665459056935, wd_multiplier: 1.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.0.4.attn.qkv.bias: lr_multiplier: 0.12157665459056935, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.0.4.attn.proj.weight: lr_multiplier: 0.12157665459056935, wd_multiplier: 1.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.0.4.attn.proj.bias: lr_multiplier: 0.12157665459056935, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.0.4.ls1.gamma: lr_multiplier: 0.12157665459056935, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.0.4.norm2.weight: lr_multiplier: 0.12157665459056935, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.0.4.norm2.bias: lr_multiplier: 0.12157665459056935, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.0.4.mlp.fc1.weight: lr_multiplier: 0.12157665459056935, wd_multiplier: 1.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.0.4.mlp.fc1.bias: lr_multiplier: 0.12157665459056935, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.0.4.mlp.fc2.weight: lr_multiplier: 0.12157665459056935, wd_multiplier: 1.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.0.4.mlp.fc2.bias: lr_multiplier: 0.12157665459056935, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.0.4.ls2.gamma: lr_multiplier: 0.12157665459056935, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.0.5.norm1.weight: lr_multiplier: 0.13508517176729928, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.0.5.norm1.bias: lr_multiplier: 0.13508517176729928, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.0.5.attn.qkv.weight: lr_multiplier: 0.13508517176729928, wd_multiplier: 1.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.0.5.attn.qkv.bias: lr_multiplier: 0.13508517176729928, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.0.5.attn.proj.weight: lr_multiplier: 0.13508517176729928, wd_multiplier: 1.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.0.5.attn.proj.bias: lr_multiplier: 0.13508517176729928, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.0.5.ls1.gamma: lr_multiplier: 0.13508517176729928, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.0.5.norm2.weight: lr_multiplier: 0.13508517176729928, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.0.5.norm2.bias: lr_multiplier: 0.13508517176729928, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.0.5.mlp.fc1.weight: lr_multiplier: 0.13508517176729928, wd_multiplier: 1.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.0.5.mlp.fc1.bias: lr_multiplier: 0.13508517176729928, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.0.5.mlp.fc2.weight: lr_multiplier: 0.13508517176729928, wd_multiplier: 1.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.0.5.mlp.fc2.bias: lr_multiplier: 0.13508517176729928, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.0.5.ls2.gamma: lr_multiplier: 0.13508517176729928, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.1.6.norm1.weight: lr_multiplier: 0.15009463529699918, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.1.6.norm1.bias: lr_multiplier: 0.15009463529699918, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.1.6.attn.qkv.weight: lr_multiplier: 0.15009463529699918, wd_multiplier: 1.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.1.6.attn.qkv.bias: lr_multiplier: 0.15009463529699918, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.1.6.attn.proj.weight: lr_multiplier: 0.15009463529699918, wd_multiplier: 1.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.1.6.attn.proj.bias: lr_multiplier: 0.15009463529699918, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.1.6.ls1.gamma: lr_multiplier: 0.15009463529699918, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.1.6.norm2.weight: lr_multiplier: 0.15009463529699918, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.1.6.norm2.bias: lr_multiplier: 0.15009463529699918, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.1.6.mlp.fc1.weight: lr_multiplier: 0.15009463529699918, wd_multiplier: 1.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.1.6.mlp.fc1.bias: lr_multiplier: 0.15009463529699918, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.1.6.mlp.fc2.weight: lr_multiplier: 0.15009463529699918, wd_multiplier: 1.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.1.6.mlp.fc2.bias: lr_multiplier: 0.15009463529699918, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.1.6.ls2.gamma: lr_multiplier: 0.15009463529699918, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.1.7.norm1.weight: lr_multiplier: 0.16677181699666577, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.1.7.norm1.bias: lr_multiplier: 0.16677181699666577, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.1.7.attn.qkv.weight: lr_multiplier: 0.16677181699666577, wd_multiplier: 1.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.1.7.attn.qkv.bias: lr_multiplier: 0.16677181699666577, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.1.7.attn.proj.weight: lr_multiplier: 0.16677181699666577, wd_multiplier: 1.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.1.7.attn.proj.bias: lr_multiplier: 0.16677181699666577, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.1.7.ls1.gamma: lr_multiplier: 0.16677181699666577, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.1.7.norm2.weight: lr_multiplier: 0.16677181699666577, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.1.7.norm2.bias: lr_multiplier: 0.16677181699666577, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.1.7.mlp.fc1.weight: lr_multiplier: 0.16677181699666577, wd_multiplier: 1.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.1.7.mlp.fc1.bias: lr_multiplier: 0.16677181699666577, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.1.7.mlp.fc2.weight: lr_multiplier: 0.16677181699666577, wd_multiplier: 1.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.1.7.mlp.fc2.bias: lr_multiplier: 0.16677181699666577, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.1.7.ls2.gamma: lr_multiplier: 0.16677181699666577, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.1.8.norm1.weight: lr_multiplier: 0.18530201888518416, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.1.8.norm1.bias: lr_multiplier: 0.18530201888518416, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.1.8.attn.qkv.weight: lr_multiplier: 0.18530201888518416, wd_multiplier: 1.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.1.8.attn.qkv.bias: lr_multiplier: 0.18530201888518416, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.1.8.attn.proj.weight: lr_multiplier: 0.18530201888518416, wd_multiplier: 1.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.1.8.attn.proj.bias: lr_multiplier: 0.18530201888518416, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.1.8.ls1.gamma: lr_multiplier: 0.18530201888518416, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.1.8.norm2.weight: lr_multiplier: 0.18530201888518416, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.1.8.norm2.bias: lr_multiplier: 0.18530201888518416, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.1.8.mlp.fc1.weight: lr_multiplier: 0.18530201888518416, wd_multiplier: 1.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.1.8.mlp.fc1.bias: lr_multiplier: 0.18530201888518416, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.1.8.mlp.fc2.weight: lr_multiplier: 0.18530201888518416, wd_multiplier: 1.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.1.8.mlp.fc2.bias: lr_multiplier: 0.18530201888518416, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.1.8.ls2.gamma: lr_multiplier: 0.18530201888518416, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.1.9.norm1.weight: lr_multiplier: 0.20589113209464907, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.1.9.norm1.bias: lr_multiplier: 0.20589113209464907, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.1.9.attn.qkv.weight: lr_multiplier: 0.20589113209464907, wd_multiplier: 1.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.1.9.attn.qkv.bias: lr_multiplier: 0.20589113209464907, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.1.9.attn.proj.weight: lr_multiplier: 0.20589113209464907, wd_multiplier: 1.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.1.9.attn.proj.bias: lr_multiplier: 0.20589113209464907, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.1.9.ls1.gamma: lr_multiplier: 0.20589113209464907, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.1.9.norm2.weight: lr_multiplier: 0.20589113209464907, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.1.9.norm2.bias: lr_multiplier: 0.20589113209464907, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.1.9.mlp.fc1.weight: lr_multiplier: 0.20589113209464907, wd_multiplier: 1.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.1.9.mlp.fc1.bias: lr_multiplier: 0.20589113209464907, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.1.9.mlp.fc2.weight: lr_multiplier: 0.20589113209464907, wd_multiplier: 1.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.1.9.mlp.fc2.bias: lr_multiplier: 0.20589113209464907, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.1.9.ls2.gamma: lr_multiplier: 0.20589113209464907, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.1.10.norm1.weight: lr_multiplier: 0.2287679245496101, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.1.10.norm1.bias: lr_multiplier: 0.2287679245496101, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.1.10.attn.qkv.weight: lr_multiplier: 0.2287679245496101, wd_multiplier: 1.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.1.10.attn.qkv.bias: lr_multiplier: 0.2287679245496101, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.1.10.attn.proj.weight: lr_multiplier: 0.2287679245496101, wd_multiplier: 1.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.1.10.attn.proj.bias: lr_multiplier: 0.2287679245496101, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.1.10.ls1.gamma: lr_multiplier: 0.2287679245496101, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.1.10.norm2.weight: lr_multiplier: 0.2287679245496101, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.1.10.norm2.bias: lr_multiplier: 0.2287679245496101, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.1.10.mlp.fc1.weight: lr_multiplier: 0.2287679245496101, wd_multiplier: 1.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.1.10.mlp.fc1.bias: lr_multiplier: 0.2287679245496101, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.1.10.mlp.fc2.weight: lr_multiplier: 0.2287679245496101, wd_multiplier: 1.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.1.10.mlp.fc2.bias: lr_multiplier: 0.2287679245496101, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.1.10.ls2.gamma: lr_multiplier: 0.2287679245496101, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.1.11.norm1.weight: lr_multiplier: 0.2541865828329001, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.1.11.norm1.bias: lr_multiplier: 0.2541865828329001, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.1.11.attn.qkv.weight: lr_multiplier: 0.2541865828329001, wd_multiplier: 1.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.1.11.attn.qkv.bias: lr_multiplier: 0.2541865828329001, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.1.11.attn.proj.weight: lr_multiplier: 0.2541865828329001, wd_multiplier: 1.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.1.11.attn.proj.bias: lr_multiplier: 0.2541865828329001, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.1.11.ls1.gamma: lr_multiplier: 0.2541865828329001, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.1.11.norm2.weight: lr_multiplier: 0.2541865828329001, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.1.11.norm2.bias: lr_multiplier: 0.2541865828329001, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.1.11.mlp.fc1.weight: lr_multiplier: 0.2541865828329001, wd_multiplier: 1.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.1.11.mlp.fc1.bias: lr_multiplier: 0.2541865828329001, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.1.11.mlp.fc2.weight: lr_multiplier: 0.2541865828329001, wd_multiplier: 1.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.1.11.mlp.fc2.bias: lr_multiplier: 0.2541865828329001, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.1.11.ls2.gamma: lr_multiplier: 0.2541865828329001, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.2.12.norm1.weight: lr_multiplier: 0.2824295364810001, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.2.12.norm1.bias: lr_multiplier: 0.2824295364810001, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.2.12.attn.qkv.weight: lr_multiplier: 0.2824295364810001, wd_multiplier: 1.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.2.12.attn.qkv.bias: lr_multiplier: 0.2824295364810001, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.2.12.attn.proj.weight: lr_multiplier: 0.2824295364810001, wd_multiplier: 1.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.2.12.attn.proj.bias: lr_multiplier: 0.2824295364810001, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.2.12.ls1.gamma: lr_multiplier: 0.2824295364810001, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.2.12.norm2.weight: lr_multiplier: 0.2824295364810001, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.2.12.norm2.bias: lr_multiplier: 0.2824295364810001, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.2.12.mlp.fc1.weight: lr_multiplier: 0.2824295364810001, wd_multiplier: 1.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.2.12.mlp.fc1.bias: lr_multiplier: 0.2824295364810001, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.2.12.mlp.fc2.weight: lr_multiplier: 0.2824295364810001, wd_multiplier: 1.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.2.12.mlp.fc2.bias: lr_multiplier: 0.2824295364810001, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.2.12.ls2.gamma: lr_multiplier: 0.2824295364810001, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.2.13.norm1.weight: lr_multiplier: 0.31381059609000006, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.2.13.norm1.bias: lr_multiplier: 0.31381059609000006, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.2.13.attn.qkv.weight: lr_multiplier: 0.31381059609000006, wd_multiplier: 1.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.2.13.attn.qkv.bias: lr_multiplier: 0.31381059609000006, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.2.13.attn.proj.weight: lr_multiplier: 0.31381059609000006, wd_multiplier: 1.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.2.13.attn.proj.bias: lr_multiplier: 0.31381059609000006, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.2.13.ls1.gamma: lr_multiplier: 0.31381059609000006, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.2.13.norm2.weight: lr_multiplier: 0.31381059609000006, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.2.13.norm2.bias: lr_multiplier: 0.31381059609000006, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.2.13.mlp.fc1.weight: lr_multiplier: 0.31381059609000006, wd_multiplier: 1.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.2.13.mlp.fc1.bias: lr_multiplier: 0.31381059609000006, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.2.13.mlp.fc2.weight: lr_multiplier: 0.31381059609000006, wd_multiplier: 1.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.2.13.mlp.fc2.bias: lr_multiplier: 0.31381059609000006, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.2.13.ls2.gamma: lr_multiplier: 0.31381059609000006, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.2.14.norm1.weight: lr_multiplier: 0.3486784401000001, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.2.14.norm1.bias: lr_multiplier: 0.3486784401000001, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.2.14.attn.qkv.weight: lr_multiplier: 0.3486784401000001, wd_multiplier: 1.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.2.14.attn.qkv.bias: lr_multiplier: 0.3486784401000001, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.2.14.attn.proj.weight: lr_multiplier: 0.3486784401000001, wd_multiplier: 1.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.2.14.attn.proj.bias: lr_multiplier: 0.3486784401000001, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.2.14.ls1.gamma: lr_multiplier: 0.3486784401000001, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.2.14.norm2.weight: lr_multiplier: 0.3486784401000001, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.2.14.norm2.bias: lr_multiplier: 0.3486784401000001, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.2.14.mlp.fc1.weight: lr_multiplier: 0.3486784401000001, wd_multiplier: 1.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.2.14.mlp.fc1.bias: lr_multiplier: 0.3486784401000001, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.2.14.mlp.fc2.weight: lr_multiplier: 0.3486784401000001, wd_multiplier: 1.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.2.14.mlp.fc2.bias: lr_multiplier: 0.3486784401000001, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.2.14.ls2.gamma: lr_multiplier: 0.3486784401000001, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.2.15.norm1.weight: lr_multiplier: 0.3874204890000001, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.2.15.norm1.bias: lr_multiplier: 0.3874204890000001, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.2.15.attn.qkv.weight: lr_multiplier: 0.3874204890000001, wd_multiplier: 1.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.2.15.attn.qkv.bias: lr_multiplier: 0.3874204890000001, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.2.15.attn.proj.weight: lr_multiplier: 0.3874204890000001, wd_multiplier: 1.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.2.15.attn.proj.bias: lr_multiplier: 0.3874204890000001, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.2.15.ls1.gamma: lr_multiplier: 0.3874204890000001, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.2.15.norm2.weight: lr_multiplier: 0.3874204890000001, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.2.15.norm2.bias: lr_multiplier: 0.3874204890000001, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.2.15.mlp.fc1.weight: lr_multiplier: 0.3874204890000001, wd_multiplier: 1.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.2.15.mlp.fc1.bias: lr_multiplier: 0.3874204890000001, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.2.15.mlp.fc2.weight: lr_multiplier: 0.3874204890000001, wd_multiplier: 1.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.2.15.mlp.fc2.bias: lr_multiplier: 0.3874204890000001, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.2.15.ls2.gamma: lr_multiplier: 0.3874204890000001, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.2.16.norm1.weight: lr_multiplier: 0.4304672100000001, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.2.16.norm1.bias: lr_multiplier: 0.4304672100000001, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.2.16.attn.qkv.weight: lr_multiplier: 0.4304672100000001, wd_multiplier: 1.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.2.16.attn.qkv.bias: lr_multiplier: 0.4304672100000001, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.2.16.attn.proj.weight: lr_multiplier: 0.4304672100000001, wd_multiplier: 1.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.2.16.attn.proj.bias: lr_multiplier: 0.4304672100000001, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.2.16.ls1.gamma: lr_multiplier: 0.4304672100000001, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.2.16.norm2.weight: lr_multiplier: 0.4304672100000001, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.2.16.norm2.bias: lr_multiplier: 0.4304672100000001, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.2.16.mlp.fc1.weight: lr_multiplier: 0.4304672100000001, wd_multiplier: 1.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.2.16.mlp.fc1.bias: lr_multiplier: 0.4304672100000001, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.2.16.mlp.fc2.weight: lr_multiplier: 0.4304672100000001, wd_multiplier: 1.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.2.16.mlp.fc2.bias: lr_multiplier: 0.4304672100000001, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.2.16.ls2.gamma: lr_multiplier: 0.4304672100000001, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.2.17.norm1.weight: lr_multiplier: 0.4782969000000001, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.2.17.norm1.bias: lr_multiplier: 0.4782969000000001, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.2.17.attn.qkv.weight: lr_multiplier: 0.4782969000000001, wd_multiplier: 1.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.2.17.attn.qkv.bias: lr_multiplier: 0.4782969000000001, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.2.17.attn.proj.weight: lr_multiplier: 0.4782969000000001, wd_multiplier: 1.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.2.17.attn.proj.bias: lr_multiplier: 0.4782969000000001, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.2.17.ls1.gamma: lr_multiplier: 0.4782969000000001, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.2.17.norm2.weight: lr_multiplier: 0.4782969000000001, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.2.17.norm2.bias: lr_multiplier: 0.4782969000000001, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.2.17.mlp.fc1.weight: lr_multiplier: 0.4782969000000001, wd_multiplier: 1.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.2.17.mlp.fc1.bias: lr_multiplier: 0.4782969000000001, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.2.17.mlp.fc2.weight: lr_multiplier: 0.4782969000000001, wd_multiplier: 1.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.2.17.mlp.fc2.bias: lr_multiplier: 0.4782969000000001, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.2.17.ls2.gamma: lr_multiplier: 0.4782969000000001, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.3.18.norm1.weight: lr_multiplier: 0.531441, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.3.18.norm1.bias: lr_multiplier: 0.531441, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.3.18.attn.qkv.weight: lr_multiplier: 0.531441, wd_multiplier: 1.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.3.18.attn.qkv.bias: lr_multiplier: 0.531441, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.3.18.attn.proj.weight: lr_multiplier: 0.531441, wd_multiplier: 1.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.3.18.attn.proj.bias: lr_multiplier: 0.531441, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.3.18.ls1.gamma: lr_multiplier: 0.531441, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.3.18.norm2.weight: lr_multiplier: 0.531441, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.3.18.norm2.bias: lr_multiplier: 0.531441, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.3.18.mlp.fc1.weight: lr_multiplier: 0.531441, wd_multiplier: 1.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.3.18.mlp.fc1.bias: lr_multiplier: 0.531441, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.3.18.mlp.fc2.weight: lr_multiplier: 0.531441, wd_multiplier: 1.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.3.18.mlp.fc2.bias: lr_multiplier: 0.531441, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.3.18.ls2.gamma: lr_multiplier: 0.531441, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.3.19.norm1.weight: lr_multiplier: 0.5904900000000001, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.3.19.norm1.bias: lr_multiplier: 0.5904900000000001, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.3.19.attn.qkv.weight: lr_multiplier: 0.5904900000000001, wd_multiplier: 1.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.3.19.attn.qkv.bias: lr_multiplier: 0.5904900000000001, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.3.19.attn.proj.weight: lr_multiplier: 0.5904900000000001, wd_multiplier: 1.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.3.19.attn.proj.bias: lr_multiplier: 0.5904900000000001, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.3.19.ls1.gamma: lr_multiplier: 0.5904900000000001, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.3.19.norm2.weight: lr_multiplier: 0.5904900000000001, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.3.19.norm2.bias: lr_multiplier: 0.5904900000000001, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.3.19.mlp.fc1.weight: lr_multiplier: 0.5904900000000001, wd_multiplier: 1.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.3.19.mlp.fc1.bias: lr_multiplier: 0.5904900000000001, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.3.19.mlp.fc2.weight: lr_multiplier: 0.5904900000000001, wd_multiplier: 1.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.3.19.mlp.fc2.bias: lr_multiplier: 0.5904900000000001, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.3.19.ls2.gamma: lr_multiplier: 0.5904900000000001, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.3.20.norm1.weight: lr_multiplier: 0.6561, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.3.20.norm1.bias: lr_multiplier: 0.6561, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.3.20.attn.qkv.weight: lr_multiplier: 0.6561, wd_multiplier: 1.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.3.20.attn.qkv.bias: lr_multiplier: 0.6561, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.3.20.attn.proj.weight: lr_multiplier: 0.6561, wd_multiplier: 1.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.3.20.attn.proj.bias: lr_multiplier: 0.6561, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.3.20.ls1.gamma: lr_multiplier: 0.6561, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.3.20.norm2.weight: lr_multiplier: 0.6561, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.3.20.norm2.bias: lr_multiplier: 0.6561, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.3.20.mlp.fc1.weight: lr_multiplier: 0.6561, wd_multiplier: 1.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.3.20.mlp.fc1.bias: lr_multiplier: 0.6561, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.3.20.mlp.fc2.weight: lr_multiplier: 0.6561, wd_multiplier: 1.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.3.20.mlp.fc2.bias: lr_multiplier: 0.6561, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.3.20.ls2.gamma: lr_multiplier: 0.6561, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.3.21.norm1.weight: lr_multiplier: 0.7290000000000001, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.3.21.norm1.bias: lr_multiplier: 0.7290000000000001, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.3.21.attn.qkv.weight: lr_multiplier: 0.7290000000000001, wd_multiplier: 1.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.3.21.attn.qkv.bias: lr_multiplier: 0.7290000000000001, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.3.21.attn.proj.weight: lr_multiplier: 0.7290000000000001, wd_multiplier: 1.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.3.21.attn.proj.bias: lr_multiplier: 0.7290000000000001, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.3.21.ls1.gamma: lr_multiplier: 0.7290000000000001, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.3.21.norm2.weight: lr_multiplier: 0.7290000000000001, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.3.21.norm2.bias: lr_multiplier: 0.7290000000000001, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.3.21.mlp.fc1.weight: lr_multiplier: 0.7290000000000001, wd_multiplier: 1.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.3.21.mlp.fc1.bias: lr_multiplier: 0.7290000000000001, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.3.21.mlp.fc2.weight: lr_multiplier: 0.7290000000000001, wd_multiplier: 1.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.3.21.mlp.fc2.bias: lr_multiplier: 0.7290000000000001, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.3.21.ls2.gamma: lr_multiplier: 0.7290000000000001, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.3.22.norm1.weight: lr_multiplier: 0.81, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.3.22.norm1.bias: lr_multiplier: 0.81, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.3.22.attn.qkv.weight: lr_multiplier: 0.81, wd_multiplier: 1.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.3.22.attn.qkv.bias: lr_multiplier: 0.81, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.3.22.attn.proj.weight: lr_multiplier: 0.81, wd_multiplier: 1.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.3.22.attn.proj.bias: lr_multiplier: 0.81, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.3.22.ls1.gamma: lr_multiplier: 0.81, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.3.22.norm2.weight: lr_multiplier: 0.81, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.3.22.norm2.bias: lr_multiplier: 0.81, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.3.22.mlp.fc1.weight: lr_multiplier: 0.81, wd_multiplier: 1.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.3.22.mlp.fc1.bias: lr_multiplier: 0.81, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.3.22.mlp.fc2.weight: lr_multiplier: 0.81, wd_multiplier: 1.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.3.22.mlp.fc2.bias: lr_multiplier: 0.81, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.3.22.ls2.gamma: lr_multiplier: 0.81, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.3.23.norm1.weight: lr_multiplier: 0.9, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.3.23.norm1.bias: lr_multiplier: 0.9, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.3.23.attn.qkv.weight: lr_multiplier: 0.9, wd_multiplier: 1.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.3.23.attn.qkv.bias: lr_multiplier: 0.9, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.3.23.attn.proj.weight: lr_multiplier: 0.9, wd_multiplier: 1.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.3.23.attn.proj.bias: lr_multiplier: 0.9, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.3.23.ls1.gamma: lr_multiplier: 0.9, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.3.23.norm2.weight: lr_multiplier: 0.9, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.3.23.norm2.bias: lr_multiplier: 0.9, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.3.23.mlp.fc1.weight: lr_multiplier: 0.9, wd_multiplier: 1.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.3.23.mlp.fc1.bias: lr_multiplier: 0.9, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.3.23.mlp.fc2.weight: lr_multiplier: 0.9, wd_multiplier: 1.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.3.23.mlp.fc2.bias: lr_multiplier: 0.9, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] blocks.3.23.ls2.gamma: lr_multiplier: 0.9, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] norm.weight: lr_multiplier: 1.0, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] norm.bias: lr_multiplier: 1.0, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 ssl_meta_arch.py:378] fusing param groups
I20240512 15:21:21 3636382 dinov2 param_groups.py:64] else code branch
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] mlp.0.weight: lr_multiplier: 1.0, wd_multiplier: 1.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] mlp.0.bias: lr_multiplier: 1.0, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] mlp.2.weight: lr_multiplier: 1.0, wd_multiplier: 1.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] mlp.2.bias: lr_multiplier: 1.0, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] mlp.4.weight: lr_multiplier: 1.0, wd_multiplier: 1.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] mlp.4.bias: lr_multiplier: 1.0, wd_multiplier: 0.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] last_layer.weight_g: lr_multiplier: 1.0, wd_multiplier: 1.0
I20240512 15:21:21 3636382 dinov2 param_groups.py:87] last_layer.weight_v: lr_multiplier: 1.0, wd_multiplier: 1.0
I20240512 15:21:21 3636382 dinov2 ssl_meta_arch.py:378] fusing param groups
I20240512 15:21:21 3636382 dinov2 train.py:102] Schedulers ready.
I20240512 15:21:21 3636382 fvcore.common.checkpoint checkpoint.py:148] No checkpoint found. Initializing model from scratch
I20240512 15:21:21 3636382 dinov2 augmentations.py:34] ###################################
I20240512 15:21:21 3636382 dinov2 augmentations.py:35] Using data augmentation parameters:
I20240512 15:21:21 3636382 dinov2 augmentations.py:36] global_crops_scale: [0.32, 1.0]
I20240512 15:21:21 3636382 dinov2 augmentations.py:37] local_crops_scale: [0.05, 0.32]
I20240512 15:21:21 3636382 dinov2 augmentations.py:38] local_crops_number: 8
I20240512 15:21:21 3636382 dinov2 augmentations.py:39] global_crops_size: 224
I20240512 15:21:21 3636382 dinov2 augmentations.py:40] local_crops_size: 96
I20240512 15:21:21 3636382 dinov2 augmentations.py:41] ###################################
I20240512 15:33:22 3637928 dinov2 config.py:59] git:
  sha: e1277af2ba9496fbadf7aec6eba56e8d882d1e35, status: has uncommitted changes, branch: main

I20240512 15:33:22 3637928 dinov2 config.py:60] config_file: config_test2.yaml
eval: 
eval_only: False
no_resume: False
opts: ['train.output_dir=/home/guevel/OT4D/cell_similarity/src/cell_similarity/scripts']
output_dir: /home/guevel/OT4D/cell_similarity/src/cell_similarity/scripts
I20240512 15:33:22 3637928 dinov2 config.py:26] sqrt scaling learning rate; base: 0.004, new: 0.0007071067811865476
I20240512 15:33:22 3637928 dinov2 config.py:33] MODEL:
  WEIGHTS: ''
compute_precision:
  grad_scaler: true
  teacher:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
  student:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
dino:
  loss_weight: 1.0
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
  koleo_loss_weight: 0.1
ibot:
  loss_weight: 1.0
  mask_sample_probability: 0.5
  mask_ratio_min_max:
  - 0.1
  - 0.5
  separate_head: false
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
train:
  batch_size_per_gpu: 32
  dataset_path: /home/manon/classification/data/Single_cells/medhi
  output_dir: /home/guevel/OT4D/cell_similarity/src/cell_similarity/scripts
  saveckp_freq: 20
  seed: 0
  num_workers: 10
  OFFICIAL_EPOCH_LENGTH: 20
  cache_dataset: true
  centering: centering
student:
  arch: vit_large
  patch_size: 16
  drop_path_rate: 0.3
  layerscale: 1.0e-05
  drop_path_uniform: true
  pretrained_weights: ''
  ffn_layer: mlp
  block_chunks: 4
  qkv_bias: true
  proj_bias: true
  ffn_bias: true
  num_register_tokens: 0
  interpolate_antialias: false
  interpolate_offset: 0.1
teacher:
  momentum_teacher: 0.992
  final_momentum_teacher: 1
  warmup_teacher_temp: 0.04
  teacher_temp: 0.07
  warmup_teacher_temp_epochs: 30
optim:
  epochs: 100
  weight_decay: 0.04
  weight_decay_end: 0.4
  base_lr: 0.004
  lr: 0.0007071067811865476
  warmup_epochs: 10
  min_lr: 1.0e-06
  clip_grad: 3.0
  freeze_last_layer_epochs: 1
  scaling_rule: sqrt_wrt_1024
  patch_embed_lr_mult: 0.2
  layerwise_decay: 0.9
  adamw_beta1: 0.9
  adamw_beta2: 0.999
crops:
  global_crops_scale:
  - 0.32
  - 1.0
  local_crops_number: 8
  local_crops_scale:
  - 0.05
  - 0.32
  global_crops_size: 224
  local_crops_size: 96
evaluation:
  eval_period_iterations: 12500

I20240512 15:33:23 3637928 dinov2 vision_transformer.py:122] using MLP layer as FFN
I20240512 15:33:26 3637928 dinov2 vision_transformer.py:122] using MLP layer as FFN
I20240512 15:33:29 3637928 dinov2 ssl_meta_arch.py:43] OPTIONS -- architecture : embed_dim: 1024
I20240512 15:33:32 3637928 dinov2 ssl_meta_arch.py:58] OPTIONS -- DINO
I20240512 15:33:32 3637928 dinov2 ssl_meta_arch.py:60] OPTIONS -- DINO -- loss_weight: 1.0
I20240512 15:33:32 3637928 dinov2 ssl_meta_arch.py:61] OPTIONS -- DINO -- head_n_prototypes: 65536
I20240512 15:33:32 3637928 dinov2 ssl_meta_arch.py:62] OPTIONS -- DINO -- head_bottleneck_dim: 256
I20240512 15:33:32 3637928 dinov2 ssl_meta_arch.py:63] OPTIONS -- DINO -- head_hidden_dim: 2048
I20240512 15:33:32 3637928 dinov2 ssl_meta_arch.py:75] OPTIONS -- DINO -- applying KOLEO regularization
I20240512 15:33:32 3637928 dinov2 ssl_meta_arch.py:85] OPTIONS -- IBOT
I20240512 15:33:32 3637928 dinov2 ssl_meta_arch.py:86] OPTIONS -- IBOT -- loss_weight: 1.0
I20240512 15:33:32 3637928 dinov2 ssl_meta_arch.py:87] OPTIONS -- IBOT masking -- ibot_mask_ratio_tuple: [0.1, 0.5]
I20240512 15:33:32 3637928 dinov2 ssl_meta_arch.py:88] OPTIONS -- IBOT masking -- ibot_mask_sample_probability: 0.5
I20240512 15:33:32 3637928 dinov2 ssl_meta_arch.py:111] OPTIONS -- IBOT -- head shared with DINO
I20240512 15:33:32 3637928 dinov2 ssl_meta_arch.py:121] Student and Teacher are built: they are both vit_large network.
I20240512 15:33:33 3637928 dinov2 ssl_meta_arch.py:391] DISTRIBUTED FSDP -- preparing model for distributed training
W20240512 15:33:33 3637928 py.warnings warnings.py:109] /home/guevel/.conda/envs/dinov2/lib/python3.9/site-packages/torch/distributed/fsdp/_init_utils.py:295: UserWarning: FSDP is switching to use `NO_SHARD` instead of ShardingStrategy.SHARD_GRAD_OP since the world size is 1.
  warnings.warn(

I20240512 15:33:33 3637928 dinov2 memory_test2.py:17] Model:
SSLMetaArch(
  (dino_loss): DINOLoss()
  (koleo_loss): KoLeoLoss(
    (pdist): PairwiseDistance()
  )
  (ibot_patch_loss): iBOTPatchLoss()
  (student): ModuleDict(
    (backbone): FullyShardedDataParallel(
      (_fsdp_wrapped_module): DinoVisionTransformer(
        (patch_embed): PatchEmbed(
          (proj): Conv2d(3, 1024, kernel_size=(16, 16), stride=(16, 16))
          (norm): Identity()
        )
        (blocks): ModuleList(
          (0): FullyShardedDataParallel(
            (_fsdp_wrapped_module): BlockChunk(
              (0-5): 6 x NestedTensorBlock(
                (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
                (attn): MemEffAttention(
                  (qkv): Linear(in_features=1024, out_features=3072, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=1024, out_features=1024, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                )
                (ls1): LayerScale()
                (drop_path1): DropPath()
                (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=1024, out_features=4096, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=4096, out_features=1024, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
                (ls2): LayerScale()
                (drop_path2): DropPath()
              )
            )
          )
          (1): FullyShardedDataParallel(
            (_fsdp_wrapped_module): BlockChunk(
              (0-5): 6 x Identity()
              (6-11): 6 x NestedTensorBlock(
                (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
                (attn): MemEffAttention(
                  (qkv): Linear(in_features=1024, out_features=3072, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=1024, out_features=1024, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                )
                (ls1): LayerScale()
                (drop_path1): DropPath()
                (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=1024, out_features=4096, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=4096, out_features=1024, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
                (ls2): LayerScale()
                (drop_path2): DropPath()
              )
            )
          )
          (2): FullyShardedDataParallel(
            (_fsdp_wrapped_module): BlockChunk(
              (0-11): 12 x Identity()
              (12-17): 6 x NestedTensorBlock(
                (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
                (attn): MemEffAttention(
                  (qkv): Linear(in_features=1024, out_features=3072, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=1024, out_features=1024, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                )
                (ls1): LayerScale()
                (drop_path1): DropPath()
                (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=1024, out_features=4096, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=4096, out_features=1024, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
                (ls2): LayerScale()
                (drop_path2): DropPath()
              )
            )
          )
          (3): FullyShardedDataParallel(
            (_fsdp_wrapped_module): BlockChunk(
              (0-17): 18 x Identity()
              (18-23): 6 x NestedTensorBlock(
                (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
                (attn): MemEffAttention(
                  (qkv): Linear(in_features=1024, out_features=3072, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=1024, out_features=1024, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                )
                (ls1): LayerScale()
                (drop_path1): DropPath()
                (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=1024, out_features=4096, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=4096, out_features=1024, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
                (ls2): LayerScale()
                (drop_path2): DropPath()
              )
            )
          )
        )
        (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (head): Identity()
      )
    )
    (dino_head): FullyShardedDataParallel(
      (_fsdp_wrapped_module): DINOHead(
        (mlp): Sequential(
          (0): Linear(in_features=1024, out_features=2048, bias=True)
          (1): GELU(approximate='none')
          (2): Linear(in_features=2048, out_features=2048, bias=True)
          (3): GELU(approximate='none')
          (4): Linear(in_features=2048, out_features=256, bias=True)
        )
        (last_layer): Linear(in_features=256, out_features=65536, bias=False)
      )
    )
  )
  (teacher): ModuleDict(
    (backbone): FullyShardedDataParallel(
      (_fsdp_wrapped_module): DinoVisionTransformer(
        (patch_embed): PatchEmbed(
          (proj): Conv2d(3, 1024, kernel_size=(16, 16), stride=(16, 16))
          (norm): Identity()
        )
        (blocks): ModuleList(
          (0): FullyShardedDataParallel(
            (_fsdp_wrapped_module): BlockChunk(
              (0-5): 6 x NestedTensorBlock(
                (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
                (attn): MemEffAttention(
                  (qkv): Linear(in_features=1024, out_features=3072, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=1024, out_features=1024, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                )
                (ls1): LayerScale()
                (drop_path1): Identity()
                (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=1024, out_features=4096, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=4096, out_features=1024, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
                (ls2): LayerScale()
                (drop_path2): Identity()
              )
            )
          )
          (1): FullyShardedDataParallel(
            (_fsdp_wrapped_module): BlockChunk(
              (0-5): 6 x Identity()
              (6-11): 6 x NestedTensorBlock(
                (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
                (attn): MemEffAttention(
                  (qkv): Linear(in_features=1024, out_features=3072, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=1024, out_features=1024, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                )
                (ls1): LayerScale()
                (drop_path1): Identity()
                (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=1024, out_features=4096, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=4096, out_features=1024, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
                (ls2): LayerScale()
                (drop_path2): Identity()
              )
            )
          )
          (2): FullyShardedDataParallel(
            (_fsdp_wrapped_module): BlockChunk(
              (0-11): 12 x Identity()
              (12-17): 6 x NestedTensorBlock(
                (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
                (attn): MemEffAttention(
                  (qkv): Linear(in_features=1024, out_features=3072, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=1024, out_features=1024, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                )
                (ls1): LayerScale()
                (drop_path1): Identity()
                (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=1024, out_features=4096, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=4096, out_features=1024, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
                (ls2): LayerScale()
                (drop_path2): Identity()
              )
            )
          )
          (3): FullyShardedDataParallel(
            (_fsdp_wrapped_module): BlockChunk(
              (0-17): 18 x Identity()
              (18-23): 6 x NestedTensorBlock(
                (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
                (attn): MemEffAttention(
                  (qkv): Linear(in_features=1024, out_features=3072, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=1024, out_features=1024, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                )
                (ls1): LayerScale()
                (drop_path1): Identity()
                (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=1024, out_features=4096, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=4096, out_features=1024, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
                (ls2): LayerScale()
                (drop_path2): Identity()
              )
            )
          )
        )
        (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (head): Identity()
      )
    )
    (dino_head): FullyShardedDataParallel(
      (_fsdp_wrapped_module): DINOHead(
        (mlp): Sequential(
          (0): Linear(in_features=1024, out_features=2048, bias=True)
          (1): GELU(approximate='none')
          (2): Linear(in_features=2048, out_features=2048, bias=True)
          (3): GELU(approximate='none')
          (4): Linear(in_features=2048, out_features=256, bias=True)
        )
        (last_layer): Linear(in_features=256, out_features=65536, bias=False)
      )
    )
  )
)
I20240512 15:33:33 3637928 dinov2 param_groups.py:54] chunked fsdp
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] cls_token: lr_multiplier: 0.0717897987691853, wd_multiplier: 1.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] pos_embed: lr_multiplier: 0.0717897987691853, wd_multiplier: 1.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] mask_token: lr_multiplier: 0.0717897987691853, wd_multiplier: 1.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] patch_embed.proj.weight: lr_multiplier: 0.01435795975383706, wd_multiplier: 1.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] patch_embed.proj.bias: lr_multiplier: 0.01435795975383706, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.0.0.norm1.weight: lr_multiplier: 0.07976644307687256, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.0.0.norm1.bias: lr_multiplier: 0.07976644307687256, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.0.0.attn.qkv.weight: lr_multiplier: 0.07976644307687256, wd_multiplier: 1.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.0.0.attn.qkv.bias: lr_multiplier: 0.07976644307687256, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.0.0.attn.proj.weight: lr_multiplier: 0.07976644307687256, wd_multiplier: 1.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.0.0.attn.proj.bias: lr_multiplier: 0.07976644307687256, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.0.0.ls1.gamma: lr_multiplier: 0.07976644307687256, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.0.0.norm2.weight: lr_multiplier: 0.07976644307687256, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.0.0.norm2.bias: lr_multiplier: 0.07976644307687256, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.0.0.mlp.fc1.weight: lr_multiplier: 0.07976644307687256, wd_multiplier: 1.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.0.0.mlp.fc1.bias: lr_multiplier: 0.07976644307687256, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.0.0.mlp.fc2.weight: lr_multiplier: 0.07976644307687256, wd_multiplier: 1.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.0.0.mlp.fc2.bias: lr_multiplier: 0.07976644307687256, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.0.0.ls2.gamma: lr_multiplier: 0.07976644307687256, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.0.1.norm1.weight: lr_multiplier: 0.08862938119652507, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.0.1.norm1.bias: lr_multiplier: 0.08862938119652507, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.0.1.attn.qkv.weight: lr_multiplier: 0.08862938119652507, wd_multiplier: 1.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.0.1.attn.qkv.bias: lr_multiplier: 0.08862938119652507, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.0.1.attn.proj.weight: lr_multiplier: 0.08862938119652507, wd_multiplier: 1.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.0.1.attn.proj.bias: lr_multiplier: 0.08862938119652507, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.0.1.ls1.gamma: lr_multiplier: 0.08862938119652507, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.0.1.norm2.weight: lr_multiplier: 0.08862938119652507, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.0.1.norm2.bias: lr_multiplier: 0.08862938119652507, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.0.1.mlp.fc1.weight: lr_multiplier: 0.08862938119652507, wd_multiplier: 1.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.0.1.mlp.fc1.bias: lr_multiplier: 0.08862938119652507, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.0.1.mlp.fc2.weight: lr_multiplier: 0.08862938119652507, wd_multiplier: 1.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.0.1.mlp.fc2.bias: lr_multiplier: 0.08862938119652507, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.0.1.ls2.gamma: lr_multiplier: 0.08862938119652507, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.0.2.norm1.weight: lr_multiplier: 0.09847709021836118, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.0.2.norm1.bias: lr_multiplier: 0.09847709021836118, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.0.2.attn.qkv.weight: lr_multiplier: 0.09847709021836118, wd_multiplier: 1.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.0.2.attn.qkv.bias: lr_multiplier: 0.09847709021836118, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.0.2.attn.proj.weight: lr_multiplier: 0.09847709021836118, wd_multiplier: 1.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.0.2.attn.proj.bias: lr_multiplier: 0.09847709021836118, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.0.2.ls1.gamma: lr_multiplier: 0.09847709021836118, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.0.2.norm2.weight: lr_multiplier: 0.09847709021836118, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.0.2.norm2.bias: lr_multiplier: 0.09847709021836118, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.0.2.mlp.fc1.weight: lr_multiplier: 0.09847709021836118, wd_multiplier: 1.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.0.2.mlp.fc1.bias: lr_multiplier: 0.09847709021836118, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.0.2.mlp.fc2.weight: lr_multiplier: 0.09847709021836118, wd_multiplier: 1.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.0.2.mlp.fc2.bias: lr_multiplier: 0.09847709021836118, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.0.2.ls2.gamma: lr_multiplier: 0.09847709021836118, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.0.3.norm1.weight: lr_multiplier: 0.10941898913151242, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.0.3.norm1.bias: lr_multiplier: 0.10941898913151242, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.0.3.attn.qkv.weight: lr_multiplier: 0.10941898913151242, wd_multiplier: 1.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.0.3.attn.qkv.bias: lr_multiplier: 0.10941898913151242, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.0.3.attn.proj.weight: lr_multiplier: 0.10941898913151242, wd_multiplier: 1.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.0.3.attn.proj.bias: lr_multiplier: 0.10941898913151242, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.0.3.ls1.gamma: lr_multiplier: 0.10941898913151242, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.0.3.norm2.weight: lr_multiplier: 0.10941898913151242, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.0.3.norm2.bias: lr_multiplier: 0.10941898913151242, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.0.3.mlp.fc1.weight: lr_multiplier: 0.10941898913151242, wd_multiplier: 1.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.0.3.mlp.fc1.bias: lr_multiplier: 0.10941898913151242, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.0.3.mlp.fc2.weight: lr_multiplier: 0.10941898913151242, wd_multiplier: 1.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.0.3.mlp.fc2.bias: lr_multiplier: 0.10941898913151242, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.0.3.ls2.gamma: lr_multiplier: 0.10941898913151242, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.0.4.norm1.weight: lr_multiplier: 0.12157665459056935, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.0.4.norm1.bias: lr_multiplier: 0.12157665459056935, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.0.4.attn.qkv.weight: lr_multiplier: 0.12157665459056935, wd_multiplier: 1.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.0.4.attn.qkv.bias: lr_multiplier: 0.12157665459056935, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.0.4.attn.proj.weight: lr_multiplier: 0.12157665459056935, wd_multiplier: 1.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.0.4.attn.proj.bias: lr_multiplier: 0.12157665459056935, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.0.4.ls1.gamma: lr_multiplier: 0.12157665459056935, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.0.4.norm2.weight: lr_multiplier: 0.12157665459056935, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.0.4.norm2.bias: lr_multiplier: 0.12157665459056935, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.0.4.mlp.fc1.weight: lr_multiplier: 0.12157665459056935, wd_multiplier: 1.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.0.4.mlp.fc1.bias: lr_multiplier: 0.12157665459056935, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.0.4.mlp.fc2.weight: lr_multiplier: 0.12157665459056935, wd_multiplier: 1.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.0.4.mlp.fc2.bias: lr_multiplier: 0.12157665459056935, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.0.4.ls2.gamma: lr_multiplier: 0.12157665459056935, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.0.5.norm1.weight: lr_multiplier: 0.13508517176729928, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.0.5.norm1.bias: lr_multiplier: 0.13508517176729928, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.0.5.attn.qkv.weight: lr_multiplier: 0.13508517176729928, wd_multiplier: 1.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.0.5.attn.qkv.bias: lr_multiplier: 0.13508517176729928, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.0.5.attn.proj.weight: lr_multiplier: 0.13508517176729928, wd_multiplier: 1.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.0.5.attn.proj.bias: lr_multiplier: 0.13508517176729928, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.0.5.ls1.gamma: lr_multiplier: 0.13508517176729928, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.0.5.norm2.weight: lr_multiplier: 0.13508517176729928, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.0.5.norm2.bias: lr_multiplier: 0.13508517176729928, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.0.5.mlp.fc1.weight: lr_multiplier: 0.13508517176729928, wd_multiplier: 1.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.0.5.mlp.fc1.bias: lr_multiplier: 0.13508517176729928, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.0.5.mlp.fc2.weight: lr_multiplier: 0.13508517176729928, wd_multiplier: 1.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.0.5.mlp.fc2.bias: lr_multiplier: 0.13508517176729928, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.0.5.ls2.gamma: lr_multiplier: 0.13508517176729928, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.1.6.norm1.weight: lr_multiplier: 0.15009463529699918, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.1.6.norm1.bias: lr_multiplier: 0.15009463529699918, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.1.6.attn.qkv.weight: lr_multiplier: 0.15009463529699918, wd_multiplier: 1.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.1.6.attn.qkv.bias: lr_multiplier: 0.15009463529699918, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.1.6.attn.proj.weight: lr_multiplier: 0.15009463529699918, wd_multiplier: 1.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.1.6.attn.proj.bias: lr_multiplier: 0.15009463529699918, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.1.6.ls1.gamma: lr_multiplier: 0.15009463529699918, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.1.6.norm2.weight: lr_multiplier: 0.15009463529699918, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.1.6.norm2.bias: lr_multiplier: 0.15009463529699918, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.1.6.mlp.fc1.weight: lr_multiplier: 0.15009463529699918, wd_multiplier: 1.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.1.6.mlp.fc1.bias: lr_multiplier: 0.15009463529699918, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.1.6.mlp.fc2.weight: lr_multiplier: 0.15009463529699918, wd_multiplier: 1.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.1.6.mlp.fc2.bias: lr_multiplier: 0.15009463529699918, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.1.6.ls2.gamma: lr_multiplier: 0.15009463529699918, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.1.7.norm1.weight: lr_multiplier: 0.16677181699666577, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.1.7.norm1.bias: lr_multiplier: 0.16677181699666577, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.1.7.attn.qkv.weight: lr_multiplier: 0.16677181699666577, wd_multiplier: 1.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.1.7.attn.qkv.bias: lr_multiplier: 0.16677181699666577, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.1.7.attn.proj.weight: lr_multiplier: 0.16677181699666577, wd_multiplier: 1.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.1.7.attn.proj.bias: lr_multiplier: 0.16677181699666577, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.1.7.ls1.gamma: lr_multiplier: 0.16677181699666577, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.1.7.norm2.weight: lr_multiplier: 0.16677181699666577, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.1.7.norm2.bias: lr_multiplier: 0.16677181699666577, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.1.7.mlp.fc1.weight: lr_multiplier: 0.16677181699666577, wd_multiplier: 1.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.1.7.mlp.fc1.bias: lr_multiplier: 0.16677181699666577, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.1.7.mlp.fc2.weight: lr_multiplier: 0.16677181699666577, wd_multiplier: 1.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.1.7.mlp.fc2.bias: lr_multiplier: 0.16677181699666577, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.1.7.ls2.gamma: lr_multiplier: 0.16677181699666577, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.1.8.norm1.weight: lr_multiplier: 0.18530201888518416, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.1.8.norm1.bias: lr_multiplier: 0.18530201888518416, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.1.8.attn.qkv.weight: lr_multiplier: 0.18530201888518416, wd_multiplier: 1.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.1.8.attn.qkv.bias: lr_multiplier: 0.18530201888518416, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.1.8.attn.proj.weight: lr_multiplier: 0.18530201888518416, wd_multiplier: 1.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.1.8.attn.proj.bias: lr_multiplier: 0.18530201888518416, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.1.8.ls1.gamma: lr_multiplier: 0.18530201888518416, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.1.8.norm2.weight: lr_multiplier: 0.18530201888518416, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.1.8.norm2.bias: lr_multiplier: 0.18530201888518416, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.1.8.mlp.fc1.weight: lr_multiplier: 0.18530201888518416, wd_multiplier: 1.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.1.8.mlp.fc1.bias: lr_multiplier: 0.18530201888518416, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.1.8.mlp.fc2.weight: lr_multiplier: 0.18530201888518416, wd_multiplier: 1.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.1.8.mlp.fc2.bias: lr_multiplier: 0.18530201888518416, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.1.8.ls2.gamma: lr_multiplier: 0.18530201888518416, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.1.9.norm1.weight: lr_multiplier: 0.20589113209464907, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.1.9.norm1.bias: lr_multiplier: 0.20589113209464907, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.1.9.attn.qkv.weight: lr_multiplier: 0.20589113209464907, wd_multiplier: 1.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.1.9.attn.qkv.bias: lr_multiplier: 0.20589113209464907, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.1.9.attn.proj.weight: lr_multiplier: 0.20589113209464907, wd_multiplier: 1.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.1.9.attn.proj.bias: lr_multiplier: 0.20589113209464907, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.1.9.ls1.gamma: lr_multiplier: 0.20589113209464907, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.1.9.norm2.weight: lr_multiplier: 0.20589113209464907, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.1.9.norm2.bias: lr_multiplier: 0.20589113209464907, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.1.9.mlp.fc1.weight: lr_multiplier: 0.20589113209464907, wd_multiplier: 1.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.1.9.mlp.fc1.bias: lr_multiplier: 0.20589113209464907, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.1.9.mlp.fc2.weight: lr_multiplier: 0.20589113209464907, wd_multiplier: 1.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.1.9.mlp.fc2.bias: lr_multiplier: 0.20589113209464907, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.1.9.ls2.gamma: lr_multiplier: 0.20589113209464907, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.1.10.norm1.weight: lr_multiplier: 0.2287679245496101, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.1.10.norm1.bias: lr_multiplier: 0.2287679245496101, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.1.10.attn.qkv.weight: lr_multiplier: 0.2287679245496101, wd_multiplier: 1.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.1.10.attn.qkv.bias: lr_multiplier: 0.2287679245496101, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.1.10.attn.proj.weight: lr_multiplier: 0.2287679245496101, wd_multiplier: 1.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.1.10.attn.proj.bias: lr_multiplier: 0.2287679245496101, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.1.10.ls1.gamma: lr_multiplier: 0.2287679245496101, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.1.10.norm2.weight: lr_multiplier: 0.2287679245496101, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.1.10.norm2.bias: lr_multiplier: 0.2287679245496101, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.1.10.mlp.fc1.weight: lr_multiplier: 0.2287679245496101, wd_multiplier: 1.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.1.10.mlp.fc1.bias: lr_multiplier: 0.2287679245496101, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.1.10.mlp.fc2.weight: lr_multiplier: 0.2287679245496101, wd_multiplier: 1.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.1.10.mlp.fc2.bias: lr_multiplier: 0.2287679245496101, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.1.10.ls2.gamma: lr_multiplier: 0.2287679245496101, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.1.11.norm1.weight: lr_multiplier: 0.2541865828329001, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.1.11.norm1.bias: lr_multiplier: 0.2541865828329001, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.1.11.attn.qkv.weight: lr_multiplier: 0.2541865828329001, wd_multiplier: 1.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.1.11.attn.qkv.bias: lr_multiplier: 0.2541865828329001, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.1.11.attn.proj.weight: lr_multiplier: 0.2541865828329001, wd_multiplier: 1.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.1.11.attn.proj.bias: lr_multiplier: 0.2541865828329001, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.1.11.ls1.gamma: lr_multiplier: 0.2541865828329001, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.1.11.norm2.weight: lr_multiplier: 0.2541865828329001, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.1.11.norm2.bias: lr_multiplier: 0.2541865828329001, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.1.11.mlp.fc1.weight: lr_multiplier: 0.2541865828329001, wd_multiplier: 1.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.1.11.mlp.fc1.bias: lr_multiplier: 0.2541865828329001, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.1.11.mlp.fc2.weight: lr_multiplier: 0.2541865828329001, wd_multiplier: 1.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.1.11.mlp.fc2.bias: lr_multiplier: 0.2541865828329001, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.1.11.ls2.gamma: lr_multiplier: 0.2541865828329001, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.2.12.norm1.weight: lr_multiplier: 0.2824295364810001, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.2.12.norm1.bias: lr_multiplier: 0.2824295364810001, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.2.12.attn.qkv.weight: lr_multiplier: 0.2824295364810001, wd_multiplier: 1.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.2.12.attn.qkv.bias: lr_multiplier: 0.2824295364810001, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.2.12.attn.proj.weight: lr_multiplier: 0.2824295364810001, wd_multiplier: 1.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.2.12.attn.proj.bias: lr_multiplier: 0.2824295364810001, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.2.12.ls1.gamma: lr_multiplier: 0.2824295364810001, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.2.12.norm2.weight: lr_multiplier: 0.2824295364810001, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.2.12.norm2.bias: lr_multiplier: 0.2824295364810001, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.2.12.mlp.fc1.weight: lr_multiplier: 0.2824295364810001, wd_multiplier: 1.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.2.12.mlp.fc1.bias: lr_multiplier: 0.2824295364810001, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.2.12.mlp.fc2.weight: lr_multiplier: 0.2824295364810001, wd_multiplier: 1.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.2.12.mlp.fc2.bias: lr_multiplier: 0.2824295364810001, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.2.12.ls2.gamma: lr_multiplier: 0.2824295364810001, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.2.13.norm1.weight: lr_multiplier: 0.31381059609000006, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.2.13.norm1.bias: lr_multiplier: 0.31381059609000006, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.2.13.attn.qkv.weight: lr_multiplier: 0.31381059609000006, wd_multiplier: 1.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.2.13.attn.qkv.bias: lr_multiplier: 0.31381059609000006, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.2.13.attn.proj.weight: lr_multiplier: 0.31381059609000006, wd_multiplier: 1.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.2.13.attn.proj.bias: lr_multiplier: 0.31381059609000006, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.2.13.ls1.gamma: lr_multiplier: 0.31381059609000006, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.2.13.norm2.weight: lr_multiplier: 0.31381059609000006, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.2.13.norm2.bias: lr_multiplier: 0.31381059609000006, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.2.13.mlp.fc1.weight: lr_multiplier: 0.31381059609000006, wd_multiplier: 1.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.2.13.mlp.fc1.bias: lr_multiplier: 0.31381059609000006, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.2.13.mlp.fc2.weight: lr_multiplier: 0.31381059609000006, wd_multiplier: 1.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.2.13.mlp.fc2.bias: lr_multiplier: 0.31381059609000006, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.2.13.ls2.gamma: lr_multiplier: 0.31381059609000006, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.2.14.norm1.weight: lr_multiplier: 0.3486784401000001, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.2.14.norm1.bias: lr_multiplier: 0.3486784401000001, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.2.14.attn.qkv.weight: lr_multiplier: 0.3486784401000001, wd_multiplier: 1.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.2.14.attn.qkv.bias: lr_multiplier: 0.3486784401000001, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.2.14.attn.proj.weight: lr_multiplier: 0.3486784401000001, wd_multiplier: 1.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.2.14.attn.proj.bias: lr_multiplier: 0.3486784401000001, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.2.14.ls1.gamma: lr_multiplier: 0.3486784401000001, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.2.14.norm2.weight: lr_multiplier: 0.3486784401000001, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.2.14.norm2.bias: lr_multiplier: 0.3486784401000001, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.2.14.mlp.fc1.weight: lr_multiplier: 0.3486784401000001, wd_multiplier: 1.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.2.14.mlp.fc1.bias: lr_multiplier: 0.3486784401000001, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.2.14.mlp.fc2.weight: lr_multiplier: 0.3486784401000001, wd_multiplier: 1.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.2.14.mlp.fc2.bias: lr_multiplier: 0.3486784401000001, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.2.14.ls2.gamma: lr_multiplier: 0.3486784401000001, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.2.15.norm1.weight: lr_multiplier: 0.3874204890000001, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.2.15.norm1.bias: lr_multiplier: 0.3874204890000001, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.2.15.attn.qkv.weight: lr_multiplier: 0.3874204890000001, wd_multiplier: 1.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.2.15.attn.qkv.bias: lr_multiplier: 0.3874204890000001, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.2.15.attn.proj.weight: lr_multiplier: 0.3874204890000001, wd_multiplier: 1.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.2.15.attn.proj.bias: lr_multiplier: 0.3874204890000001, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.2.15.ls1.gamma: lr_multiplier: 0.3874204890000001, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.2.15.norm2.weight: lr_multiplier: 0.3874204890000001, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.2.15.norm2.bias: lr_multiplier: 0.3874204890000001, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.2.15.mlp.fc1.weight: lr_multiplier: 0.3874204890000001, wd_multiplier: 1.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.2.15.mlp.fc1.bias: lr_multiplier: 0.3874204890000001, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.2.15.mlp.fc2.weight: lr_multiplier: 0.3874204890000001, wd_multiplier: 1.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.2.15.mlp.fc2.bias: lr_multiplier: 0.3874204890000001, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.2.15.ls2.gamma: lr_multiplier: 0.3874204890000001, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.2.16.norm1.weight: lr_multiplier: 0.4304672100000001, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.2.16.norm1.bias: lr_multiplier: 0.4304672100000001, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.2.16.attn.qkv.weight: lr_multiplier: 0.4304672100000001, wd_multiplier: 1.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.2.16.attn.qkv.bias: lr_multiplier: 0.4304672100000001, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.2.16.attn.proj.weight: lr_multiplier: 0.4304672100000001, wd_multiplier: 1.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.2.16.attn.proj.bias: lr_multiplier: 0.4304672100000001, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.2.16.ls1.gamma: lr_multiplier: 0.4304672100000001, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.2.16.norm2.weight: lr_multiplier: 0.4304672100000001, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.2.16.norm2.bias: lr_multiplier: 0.4304672100000001, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.2.16.mlp.fc1.weight: lr_multiplier: 0.4304672100000001, wd_multiplier: 1.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.2.16.mlp.fc1.bias: lr_multiplier: 0.4304672100000001, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.2.16.mlp.fc2.weight: lr_multiplier: 0.4304672100000001, wd_multiplier: 1.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.2.16.mlp.fc2.bias: lr_multiplier: 0.4304672100000001, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.2.16.ls2.gamma: lr_multiplier: 0.4304672100000001, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.2.17.norm1.weight: lr_multiplier: 0.4782969000000001, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.2.17.norm1.bias: lr_multiplier: 0.4782969000000001, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.2.17.attn.qkv.weight: lr_multiplier: 0.4782969000000001, wd_multiplier: 1.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.2.17.attn.qkv.bias: lr_multiplier: 0.4782969000000001, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.2.17.attn.proj.weight: lr_multiplier: 0.4782969000000001, wd_multiplier: 1.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.2.17.attn.proj.bias: lr_multiplier: 0.4782969000000001, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.2.17.ls1.gamma: lr_multiplier: 0.4782969000000001, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.2.17.norm2.weight: lr_multiplier: 0.4782969000000001, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.2.17.norm2.bias: lr_multiplier: 0.4782969000000001, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.2.17.mlp.fc1.weight: lr_multiplier: 0.4782969000000001, wd_multiplier: 1.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.2.17.mlp.fc1.bias: lr_multiplier: 0.4782969000000001, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.2.17.mlp.fc2.weight: lr_multiplier: 0.4782969000000001, wd_multiplier: 1.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.2.17.mlp.fc2.bias: lr_multiplier: 0.4782969000000001, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.2.17.ls2.gamma: lr_multiplier: 0.4782969000000001, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.3.18.norm1.weight: lr_multiplier: 0.531441, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.3.18.norm1.bias: lr_multiplier: 0.531441, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.3.18.attn.qkv.weight: lr_multiplier: 0.531441, wd_multiplier: 1.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.3.18.attn.qkv.bias: lr_multiplier: 0.531441, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.3.18.attn.proj.weight: lr_multiplier: 0.531441, wd_multiplier: 1.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.3.18.attn.proj.bias: lr_multiplier: 0.531441, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.3.18.ls1.gamma: lr_multiplier: 0.531441, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.3.18.norm2.weight: lr_multiplier: 0.531441, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.3.18.norm2.bias: lr_multiplier: 0.531441, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.3.18.mlp.fc1.weight: lr_multiplier: 0.531441, wd_multiplier: 1.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.3.18.mlp.fc1.bias: lr_multiplier: 0.531441, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.3.18.mlp.fc2.weight: lr_multiplier: 0.531441, wd_multiplier: 1.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.3.18.mlp.fc2.bias: lr_multiplier: 0.531441, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.3.18.ls2.gamma: lr_multiplier: 0.531441, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.3.19.norm1.weight: lr_multiplier: 0.5904900000000001, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.3.19.norm1.bias: lr_multiplier: 0.5904900000000001, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.3.19.attn.qkv.weight: lr_multiplier: 0.5904900000000001, wd_multiplier: 1.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.3.19.attn.qkv.bias: lr_multiplier: 0.5904900000000001, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.3.19.attn.proj.weight: lr_multiplier: 0.5904900000000001, wd_multiplier: 1.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.3.19.attn.proj.bias: lr_multiplier: 0.5904900000000001, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.3.19.ls1.gamma: lr_multiplier: 0.5904900000000001, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.3.19.norm2.weight: lr_multiplier: 0.5904900000000001, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.3.19.norm2.bias: lr_multiplier: 0.5904900000000001, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.3.19.mlp.fc1.weight: lr_multiplier: 0.5904900000000001, wd_multiplier: 1.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.3.19.mlp.fc1.bias: lr_multiplier: 0.5904900000000001, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.3.19.mlp.fc2.weight: lr_multiplier: 0.5904900000000001, wd_multiplier: 1.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.3.19.mlp.fc2.bias: lr_multiplier: 0.5904900000000001, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.3.19.ls2.gamma: lr_multiplier: 0.5904900000000001, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.3.20.norm1.weight: lr_multiplier: 0.6561, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.3.20.norm1.bias: lr_multiplier: 0.6561, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.3.20.attn.qkv.weight: lr_multiplier: 0.6561, wd_multiplier: 1.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.3.20.attn.qkv.bias: lr_multiplier: 0.6561, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.3.20.attn.proj.weight: lr_multiplier: 0.6561, wd_multiplier: 1.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.3.20.attn.proj.bias: lr_multiplier: 0.6561, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.3.20.ls1.gamma: lr_multiplier: 0.6561, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.3.20.norm2.weight: lr_multiplier: 0.6561, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.3.20.norm2.bias: lr_multiplier: 0.6561, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.3.20.mlp.fc1.weight: lr_multiplier: 0.6561, wd_multiplier: 1.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.3.20.mlp.fc1.bias: lr_multiplier: 0.6561, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.3.20.mlp.fc2.weight: lr_multiplier: 0.6561, wd_multiplier: 1.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.3.20.mlp.fc2.bias: lr_multiplier: 0.6561, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.3.20.ls2.gamma: lr_multiplier: 0.6561, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.3.21.norm1.weight: lr_multiplier: 0.7290000000000001, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.3.21.norm1.bias: lr_multiplier: 0.7290000000000001, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.3.21.attn.qkv.weight: lr_multiplier: 0.7290000000000001, wd_multiplier: 1.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.3.21.attn.qkv.bias: lr_multiplier: 0.7290000000000001, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.3.21.attn.proj.weight: lr_multiplier: 0.7290000000000001, wd_multiplier: 1.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.3.21.attn.proj.bias: lr_multiplier: 0.7290000000000001, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.3.21.ls1.gamma: lr_multiplier: 0.7290000000000001, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.3.21.norm2.weight: lr_multiplier: 0.7290000000000001, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.3.21.norm2.bias: lr_multiplier: 0.7290000000000001, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.3.21.mlp.fc1.weight: lr_multiplier: 0.7290000000000001, wd_multiplier: 1.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.3.21.mlp.fc1.bias: lr_multiplier: 0.7290000000000001, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.3.21.mlp.fc2.weight: lr_multiplier: 0.7290000000000001, wd_multiplier: 1.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.3.21.mlp.fc2.bias: lr_multiplier: 0.7290000000000001, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.3.21.ls2.gamma: lr_multiplier: 0.7290000000000001, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.3.22.norm1.weight: lr_multiplier: 0.81, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.3.22.norm1.bias: lr_multiplier: 0.81, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.3.22.attn.qkv.weight: lr_multiplier: 0.81, wd_multiplier: 1.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.3.22.attn.qkv.bias: lr_multiplier: 0.81, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.3.22.attn.proj.weight: lr_multiplier: 0.81, wd_multiplier: 1.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.3.22.attn.proj.bias: lr_multiplier: 0.81, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.3.22.ls1.gamma: lr_multiplier: 0.81, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.3.22.norm2.weight: lr_multiplier: 0.81, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.3.22.norm2.bias: lr_multiplier: 0.81, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.3.22.mlp.fc1.weight: lr_multiplier: 0.81, wd_multiplier: 1.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.3.22.mlp.fc1.bias: lr_multiplier: 0.81, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.3.22.mlp.fc2.weight: lr_multiplier: 0.81, wd_multiplier: 1.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.3.22.mlp.fc2.bias: lr_multiplier: 0.81, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.3.22.ls2.gamma: lr_multiplier: 0.81, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.3.23.norm1.weight: lr_multiplier: 0.9, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.3.23.norm1.bias: lr_multiplier: 0.9, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.3.23.attn.qkv.weight: lr_multiplier: 0.9, wd_multiplier: 1.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.3.23.attn.qkv.bias: lr_multiplier: 0.9, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.3.23.attn.proj.weight: lr_multiplier: 0.9, wd_multiplier: 1.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.3.23.attn.proj.bias: lr_multiplier: 0.9, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.3.23.ls1.gamma: lr_multiplier: 0.9, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.3.23.norm2.weight: lr_multiplier: 0.9, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.3.23.norm2.bias: lr_multiplier: 0.9, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.3.23.mlp.fc1.weight: lr_multiplier: 0.9, wd_multiplier: 1.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.3.23.mlp.fc1.bias: lr_multiplier: 0.9, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.3.23.mlp.fc2.weight: lr_multiplier: 0.9, wd_multiplier: 1.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.3.23.mlp.fc2.bias: lr_multiplier: 0.9, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] blocks.3.23.ls2.gamma: lr_multiplier: 0.9, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] norm.weight: lr_multiplier: 1.0, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] norm.bias: lr_multiplier: 1.0, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 ssl_meta_arch.py:378] fusing param groups
I20240512 15:33:33 3637928 dinov2 param_groups.py:64] else code branch
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] mlp.0.weight: lr_multiplier: 1.0, wd_multiplier: 1.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] mlp.0.bias: lr_multiplier: 1.0, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] mlp.2.weight: lr_multiplier: 1.0, wd_multiplier: 1.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] mlp.2.bias: lr_multiplier: 1.0, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] mlp.4.weight: lr_multiplier: 1.0, wd_multiplier: 1.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] mlp.4.bias: lr_multiplier: 1.0, wd_multiplier: 0.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] last_layer.weight_g: lr_multiplier: 1.0, wd_multiplier: 1.0
I20240512 15:33:33 3637928 dinov2 param_groups.py:87] last_layer.weight_v: lr_multiplier: 1.0, wd_multiplier: 1.0
I20240512 15:33:33 3637928 dinov2 ssl_meta_arch.py:378] fusing param groups
I20240512 15:33:33 3637928 dinov2 train.py:102] Schedulers ready.
I20240512 15:33:33 3637928 fvcore.common.checkpoint checkpoint.py:148] No checkpoint found. Initializing model from scratch
I20240512 15:33:33 3637928 dinov2 augmentations.py:34] ###################################
I20240512 15:33:33 3637928 dinov2 augmentations.py:35] Using data augmentation parameters:
I20240512 15:33:33 3637928 dinov2 augmentations.py:36] global_crops_scale: [0.32, 1.0]
I20240512 15:33:33 3637928 dinov2 augmentations.py:37] local_crops_scale: [0.05, 0.32]
I20240512 15:33:33 3637928 dinov2 augmentations.py:38] local_crops_number: 8
I20240512 15:33:33 3637928 dinov2 augmentations.py:39] global_crops_size: 224
I20240512 15:33:33 3637928 dinov2 augmentations.py:40] local_crops_size: 96
I20240512 15:33:33 3637928 dinov2 augmentations.py:41] ###################################
I20240512 15:50:10 3637928 dinov2 loaders.py:122] sampler: sharded infinite
I20240512 15:50:10 3637928 dinov2 loaders.py:206] using PyTorch data loader
I20240512 15:50:10 3637928 dinov2 loaders.py:221] infinite data loader
W20240512 15:50:15 3637928 py.warnings warnings.py:109] /home/guevel/.conda/envs/dinov2/lib/python3.9/site-packages/xformers/ops/fmha/flash.py:339: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  and inp.query.storage().data_ptr() == inp.key.storage().data_ptr()

I20240512 15:50:16 3637928 dinov2 helpers.py:102] Training  [   0/2000]  eta: 3:19:35  memoryused: 10613.0000 (10613.0000)  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 32.0000 (32.0000)  total_loss: 13.7424 (13.7424)  dino_local_crops_loss: 9.1752 (9.1752)  dino_global_crops_loss: 1.1469 (1.1469)  koleo_loss: 0.6377 (0.6377)  ibot_loss: 2.7826 (2.7826)  time: 5.987957  data: 2.250189  max mem: 17491
I20240512 15:50:24 3637928 dinov2 helpers.py:102] Training  [  10/2000]  eta: 0:42:06  memoryused: 18425.0000 (18606.8182)  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 32.0000 (32.0000)  total_loss: 14.1426 (14.0662)  dino_local_crops_loss: 9.5243 (9.4964)  dino_global_crops_loss: 1.1905 (1.1871)  koleo_loss: 0.6294 (0.5914)  ibot_loss: 2.7932 (2.7913)  time: 1.269420  data: 0.204675  max mem: 19999
I20240512 15:50:34 3637928 dinov2 helpers.py:102] Training  [  20/2000]  eta: 0:36:46  memoryused: 14287.0000 (16526.5238)  lr: 0.0000 (0.0000)  wd: 0.0400 (0.0400)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0000 (0.0000)  current_batch_size: 32.0000 (32.0000)  total_loss: 14.2229 (14.1580)  dino_local_crops_loss: 9.7328 (9.6680)  dino_global_crops_loss: 1.2166 (1.2085)  koleo_loss: 0.4617 (0.4898)  ibot_loss: 2.7919 (2.7916)  time: 0.870481  data: 0.000112  max mem: 20005
I20240512 15:50:43 3637928 dinov2 helpers.py:102] Training  [  30/2000]  eta: 0:34:47  memoryused: 14231.0000 (15785.9677)  lr: 0.0001 (0.0001)  wd: 0.0401 (0.0401)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0001 (0.0000)  current_batch_size: 32.0000 (32.0000)  total_loss: 14.2364 (14.1739)  dino_local_crops_loss: 9.9268 (9.7556)  dino_global_crops_loss: 1.2409 (1.2195)  koleo_loss: 0.3081 (0.4059)  ibot_loss: 2.7947 (2.7930)  time: 0.944216  data: 0.000111  max mem: 20006
I20240512 15:50:53 3637928 dinov2 helpers.py:102] Training  [  40/2000]  eta: 0:33:43  memoryused: 14231.0000 (15406.7073)  lr: 0.0001 (0.0001)  wd: 0.0402 (0.0401)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0001 (0.0001)  current_batch_size: 32.0000 (32.0000)  total_loss: 14.0859 (14.1305)  dino_local_crops_loss: 9.9334 (9.7952)  dino_global_crops_loss: 1.2416 (1.2245)  koleo_loss: 0.1285 (0.3237)  ibot_loss: 2.7812 (2.7872)  time: 0.946713  data: 0.000112  max mem: 20010
I20240512 15:51:02 3637928 dinov2 helpers.py:102] Training  [  50/2000]  eta: 0:33:01  memoryused: 14231.0000 (15176.1765)  lr: 0.0001 (0.0001)  wd: 0.0404 (0.0402)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0001 (0.0001)  current_batch_size: 32.0000 (32.0000)  total_loss: 13.9023 (14.0786)  dino_local_crops_loss: 9.8829 (9.8079)  dino_global_crops_loss: 1.2356 (1.2261)  koleo_loss: 0.0333 (0.2642)  ibot_loss: 2.7580 (2.7803)  time: 0.948574  data: 0.000106  max mem: 20010
I20240512 15:51:11 3637928 fvcore.common.checkpoint __init__.py:109] Saving checkpoint to /home/guevel/OT4D/cell_similarity/src/cell_similarity/scripts/model_0000059.rank_0.pth
E20240512 15:51:11 3637928 iopath.common.file_io file_io.py:949] An exception occurred in telemetry logging.Disabling telemetry to prevent further exceptions.
Traceback (most recent call last):
  File "/home/guevel/.conda/envs/dinov2/lib/python3.9/site-packages/iopath/common/file_io.py", line 946, in __log_tmetry_keys
    handler.log_event()
  File "/home/guevel/.conda/envs/dinov2/lib/python3.9/site-packages/iopath/common/event_logger.py", line 97, in log_event
    del self._evt
AttributeError: _evt
I20240512 15:54:37 3637928 dinov2 helpers.py:102] Training  [  60/2000]  eta: 2:21:36  memoryused: 14231.0000 (15021.2295)  lr: 0.0002 (0.0001)  wd: 0.0406 (0.0403)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0002 (0.0001)  current_batch_size: 32.0000 (32.0000)  total_loss: 13.8261 (14.0353)  dino_local_crops_loss: 9.8399 (9.8124)  dino_global_crops_loss: 1.2302 (1.2267)  koleo_loss: 0.0139 (0.2227)  ibot_loss: 2.7468 (2.7734)  time: 11.240587  data: 0.000121  max mem: 20010
I20240512 15:54:47 3637928 dinov2 helpers.py:102] Training  [  70/2000]  eta: 2:05:18  memoryused: 14231.0000 (14909.9296)  lr: 0.0002 (0.0001)  wd: 0.0408 (0.0404)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0002 (0.0001)  current_batch_size: 32.0000 (32.0000)  total_loss: 13.8097 (14.0027)  dino_local_crops_loss: 9.8355 (9.8159)  dino_global_crops_loss: 1.2298 (1.2272)  koleo_loss: 0.0072 (0.1918)  ibot_loss: 2.7362 (2.7678)  time: 11.238776  data: 0.000118  max mem: 20010
I20240512 15:54:57 3637928 dinov2 helpers.py:102] Training  [  80/2000]  eta: 1:53:01  memoryused: 14231.0000 (14826.1111)  lr: 0.0002 (0.0001)  wd: 0.0411 (0.0405)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0002 (0.0001)  current_batch_size: 32.0000 (32.0000)  total_loss: 13.8035 (13.9781)  dino_local_crops_loss: 9.8402 (9.8195)  dino_global_crops_loss: 1.2303 (1.2276)  koleo_loss: 0.0014 (0.1683)  ibot_loss: 2.7306 (2.7627)  time: 0.946754  data: 0.000111  max mem: 20010
I20240512 15:55:08 3637928 dinov2 helpers.py:102] Training  [  90/2000]  eta: 1:43:23  memoryused: 14231.0000 (14761.0000)  lr: 0.0003 (0.0002)  wd: 0.0414 (0.0406)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0003 (0.0002)  current_batch_size: 32.0000 (32.0000)  total_loss: 13.8035 (13.9593)  dino_local_crops_loss: 9.8480 (9.8229)  dino_global_crops_loss: 1.2316 (1.2281)  koleo_loss: 0.0002 (0.1498)  ibot_loss: 2.7253 (2.7585)  time: 0.947597  data: 0.000111  max mem: 20010
I20240512 15:55:18 3637928 dinov2 helpers.py:102] Training  [ 100/2000]  eta: 1:35:37  memoryused: 14231.0000 (14708.5248)  lr: 0.0003 (0.0002)  wd: 0.0418 (0.0407)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0003 (0.0002)  current_batch_size: 32.0000 (32.0000)  total_loss: 13.8062 (13.9437)  dino_local_crops_loss: 9.8525 (9.8259)  dino_global_crops_loss: 1.2319 (1.2285)  koleo_loss: -0.0012 (0.1348)  ibot_loss: 2.7224 (2.7545)  time: 0.945828  data: 0.000108  max mem: 20010
I20240512 15:55:28 3637928 dinov2 helpers.py:102] Training  [ 110/2000]  eta: 1:29:15  memoryused: 14231.0000 (14665.5045)  lr: 0.0004 (0.0002)  wd: 0.0422 (0.0409)  mom: 0.9920 (0.9920)  last_layer_lr: 0.0004 (0.0002)  current_batch_size: 32.0000 (32.0000)  total_loss: 13.8062 (13.9316)  dino_local_crops_loss: 9.8542 (9.8286)  dino_global_crops_loss: 1.2321 (1.2288)  koleo_loss: -0.0026 (0.1224)  ibot_loss: 2.7224 (2.7519)  time: 0.949113  data: 0.000114  max mem: 20010
I20240512 15:55:36 3637928 fvcore.common.checkpoint __init__.py:109] Saving checkpoint to /home/guevel/OT4D/cell_similarity/src/cell_similarity/scripts/model_0000119.rank_0.pth
I20240512 15:58:54 3637928 dinov2 helpers.py:102] Training  [ 120/2000]  eta: 2:14:49  memoryused: 14231.0000 (14629.5950)  lr: 0.0004 (0.0002)  wd: 0.0427 (0.0411)  mom: 0.9921 (0.9920)  last_layer_lr: 0.0004 (0.0002)  current_batch_size: 32.0000 (32.0000)  total_loss: 13.8074 (13.9210)  dino_local_crops_loss: 9.8552 (9.8308)  dino_global_crops_loss: 1.2322 (1.2291)  koleo_loss: -0.0037 (0.1119)  ibot_loss: 2.7246 (2.7492)  time: 10.782509  data: 0.000136  max mem: 20010
I20240512 15:59:03 3637928 dinov2 helpers.py:102] Training  [ 130/2000]  eta: 2:06:06  memoryused: 14231.0000 (14599.1679)  lr: 0.0004 (0.0002)  wd: 0.0432 (0.0413)  mom: 0.9921 (0.9920)  last_layer_lr: 0.0004 (0.0002)  current_batch_size: 32.0000 (32.0000)  total_loss: 13.8036 (13.9114)  dino_local_crops_loss: 9.8558 (9.8327)  dino_global_crops_loss: 1.2323 (1.2294)  koleo_loss: -0.0050 (0.1030)  ibot_loss: 2.7210 (2.7463)  time: 10.777469  data: 0.000148  max mem: 20010
I20240512 15:59:13 3637928 dinov2 helpers.py:102] Training  [ 140/2000]  eta: 1:58:37  memoryused: 14231.0000 (14573.0567)  lr: 0.0005 (0.0002)  wd: 0.0437 (0.0415)  mom: 0.9921 (0.9920)  last_layer_lr: 0.0005 (0.0002)  current_batch_size: 32.0000 (32.0000)  total_loss: 13.8026 (13.9039)  dino_local_crops_loss: 9.8563 (9.8344)  dino_global_crops_loss: 1.2323 (1.2296)  koleo_loss: -0.0058 (0.0953)  ibot_loss: 2.7184 (2.7446)  time: 0.943702  data: 0.000154  max mem: 20010
I20240512 15:59:22 3637928 dinov2 helpers.py:102] Training  [ 150/2000]  eta: 1:52:06  memoryused: 14231.0000 (14550.4040)  lr: 0.0005 (0.0003)  wd: 0.0443 (0.0417)  mom: 0.9921 (0.9920)  last_layer_lr: 0.0005 (0.0003)  current_batch_size: 32.0000 (32.0000)  total_loss: 13.8014 (13.8969)  dino_local_crops_loss: 9.8569 (9.8359)  dino_global_crops_loss: 1.2324 (1.2298)  koleo_loss: -0.0063 (0.0885)  ibot_loss: 2.7184 (2.7427)  time: 0.945789  data: 0.000165  max mem: 20010
I20240512 15:59:31 3637928 dinov2 helpers.py:102] Training  [ 160/2000]  eta: 1:46:22  memoryused: 14231.0000 (14530.5652)  lr: 0.0005 (0.0003)  wd: 0.0450 (0.0419)  mom: 0.9921 (0.9920)  last_layer_lr: 0.0005 (0.0003)  current_batch_size: 32.0000 (32.0000)  total_loss: 13.7989 (13.8907)  dino_local_crops_loss: 9.8573 (9.8373)  dino_global_crops_loss: 1.2325 (1.2299)  koleo_loss: -0.0085 (0.0824)  ibot_loss: 2.7185 (2.7411)  time: 0.945575  data: 0.000133  max mem: 20010
I20240512 15:59:41 3637928 dinov2 helpers.py:102] Training  [ 170/2000]  eta: 1:41:17  memoryused: 14231.0000 (14513.0468)  lr: 0.0006 (0.0003)  wd: 0.0457 (0.0421)  mom: 0.9921 (0.9920)  last_layer_lr: 0.0006 (0.0003)  current_batch_size: 32.0000 (32.0000)  total_loss: 13.8012 (13.8858)  dino_local_crops_loss: 9.8575 (9.8385)  dino_global_crops_loss: 1.2324 (1.2301)  koleo_loss: -0.0090 (0.0771)  ibot_loss: 2.7202 (2.7402)  time: 0.947372  data: 0.000106  max mem: 20010
I20240512 15:59:50 3637928 fvcore.common.checkpoint __init__.py:109] Saving checkpoint to /home/guevel/OT4D/cell_similarity/src/cell_similarity/scripts/model_0000179.rank_0.pth
I20240512 16:00:52 3637928 dinov2 helpers.py:102] Training  [ 180/2000]  eta: 1:47:06  memoryused: 14231.0000 (14497.4641)  lr: 0.0006 (0.0003)  wd: 0.0464 (0.0424)  mom: 0.9921 (0.9921)  last_layer_lr: 0.0006 (0.0003)  current_batch_size: 32.0000 (32.0000)  total_loss: 13.8064 (13.8818)  dino_local_crops_loss: 9.8578 (9.8395)  dino_global_crops_loss: 1.2324 (1.2302)  koleo_loss: -0.0100 (0.0722)  ibot_loss: 2.7265 (2.7398)  time: 4.032062  data: 0.000114  max mem: 20010
I20240512 16:01:02 3637928 dinov2 helpers.py:102] Training  [ 190/2000]  eta: 1:42:25  memoryused: 14231.0000 (14483.6492)  lr: 0.0006 (0.0003)  wd: 0.0471 (0.0427)  mom: 0.9922 (0.9921)  last_layer_lr: 0.0006 (0.0003)  current_batch_size: 32.0000 (32.0000)  total_loss: 13.8118 (13.8782)  dino_local_crops_loss: 9.8580 (9.8405)  dino_global_crops_loss: 1.2324 (1.2303)  koleo_loss: -0.0105 (0.0679)  ibot_loss: 2.7314 (2.7395)  time: 4.029029  data: 0.000128  max mem: 20010
I20240512 16:01:11 3637928 dinov2 helpers.py:102] Training  [ 200/2000]  eta: 1:38:12  memoryused: 14231.0000 (14471.0796)  lr: 0.0007 (0.0004)  wd: 0.0480 (0.0430)  mom: 0.9922 (0.9921)  last_layer_lr: 0.0007 (0.0004)  current_batch_size: 32.0000 (32.0000)  total_loss: 13.8139 (13.8751)  dino_local_crops_loss: 9.8584 (9.8414)  dino_global_crops_loss: 1.2326 (1.2304)  koleo_loss: -0.0116 (0.0639)  ibot_loss: 2.7350 (2.7394)  time: 0.947563  data: 0.000122  max mem: 20010
I20240512 16:01:21 3637928 dinov2 helpers.py:102] Training  [ 210/2000]  eta: 1:34:23  memoryused: 14231.0000 (14459.7014)  lr: 0.0007 (0.0004)  wd: 0.0488 (0.0433)  mom: 0.9922 (0.9921)  last_layer_lr: 0.0007 (0.0004)  current_batch_size: 32.0000 (32.0000)  total_loss: 13.8152 (13.8723)  dino_local_crops_loss: 9.8583 (9.8422)  dino_global_crops_loss: 1.2325 (1.2305)  koleo_loss: -0.0121 (0.0603)  ibot_loss: 2.7352 (2.7393)  time: 0.951305  data: 0.000120  max mem: 20010
I20240512 16:01:30 3637928 dinov2 helpers.py:102] Training  [ 220/2000]  eta: 1:30:53  memoryused: 14231.0000 (14449.3529)  lr: 0.0007 (0.0004)  wd: 0.0497 (0.0436)  mom: 0.9922 (0.9921)  last_layer_lr: 0.0007 (0.0004)  current_batch_size: 32.0000 (32.0000)  total_loss: 13.8152 (13.8697)  dino_local_crops_loss: 9.8581 (9.8429)  dino_global_crops_loss: 1.2324 (1.2306)  koleo_loss: -0.0127 (0.0570)  ibot_loss: 2.7374 (2.7392)  time: 0.953086  data: 0.000120  max mem: 20010
I20240512 16:01:40 3637928 dinov2 helpers.py:102] Training  [ 230/2000]  eta: 1:27:41  memoryused: 14231.0000 (14439.9004)  lr: 0.0007 (0.0004)  wd: 0.0506 (0.0439)  mom: 0.9922 (0.9921)  last_layer_lr: 0.0007 (0.0004)  current_batch_size: 32.0000 (32.0000)  total_loss: 13.8179 (13.8676)  dino_local_crops_loss: 9.8581 (9.8436)  dino_global_crops_loss: 1.2324 (1.2307)  koleo_loss: -0.0134 (0.0540)  ibot_loss: 2.7405 (2.7393)  time: 0.956636  data: 0.000112  max mem: 20010
I20240512 16:01:48 3637928 fvcore.common.checkpoint __init__.py:109] Saving checkpoint to /home/guevel/OT4D/cell_similarity/src/cell_similarity/scripts/model_0000239.rank_0.pth
I20240512 16:02:55 3637928 dinov2 helpers.py:102] Training  [ 240/2000]  eta: 1:32:42  memoryused: 14231.0000 (14431.2324)  lr: 0.0007 (0.0004)  wd: 0.0516 (0.0442)  mom: 0.9923 (0.9921)  last_layer_lr: 0.0007 (0.0004)  current_batch_size: 32.0000 (32.0000)  total_loss: 13.8214 (13.8657)  dino_local_crops_loss: 9.8583 (9.8442)  dino_global_crops_loss: 1.2324 (1.2308)  koleo_loss: -0.0133 (0.0512)  ibot_loss: 2.7441 (2.7396)  time: 4.230395  data: 0.000121  max mem: 20010
I20240512 16:03:04 3637928 dinov2 helpers.py:102] Training  [ 250/2000]  eta: 1:29:37  memoryused: 14231.0000 (14423.2550)  lr: 0.0007 (0.0004)  wd: 0.0526 (0.0446)  mom: 0.9923 (0.9921)  last_layer_lr: 0.0007 (0.0004)  current_batch_size: 32.0000 (32.0000)  total_loss: 13.8216 (13.8640)  dino_local_crops_loss: 9.8584 (9.8448)  dino_global_crops_loss: 1.2324 (1.2308)  koleo_loss: -0.0139 (0.0485)  ibot_loss: 2.7455 (2.7398)  time: 4.227023  data: 0.000120  max mem: 20010
I20240512 16:03:14 3637928 dinov2 helpers.py:102] Training  [ 260/2000]  eta: 1:26:45  memoryused: 14231.0000 (14415.8889)  lr: 0.0007 (0.0004)  wd: 0.0537 (0.0450)  mom: 0.9923 (0.9921)  last_layer_lr: 0.0007 (0.0004)  current_batch_size: 32.0000 (32.0000)  total_loss: 13.8221 (13.8624)  dino_local_crops_loss: 9.8584 (9.8453)  dino_global_crops_loss: 1.2324 (1.2309)  koleo_loss: -0.0151 (0.0461)  ibot_loss: 2.7465 (2.7401)  time: 0.953387  data: 0.000111  max mem: 20010
I20240512 16:03:23 3637928 dinov2 helpers.py:102] Training  [ 270/2000]  eta: 1:24:05  memoryused: 14231.0000 (14409.0590)  lr: 0.0007 (0.0004)  wd: 0.0548 (0.0454)  mom: 0.9923 (0.9921)  last_layer_lr: 0.0007 (0.0004)  current_batch_size: 32.0000 (32.0000)  total_loss: 13.8256 (13.8611)  dino_local_crops_loss: 9.8583 (9.8458)  dino_global_crops_loss: 1.2324 (1.2310)  koleo_loss: -0.0151 (0.0439)  ibot_loss: 2.7503 (2.7405)  time: 0.954567  data: 0.000133  max mem: 20010
I20240512 16:03:33 3637928 dinov2 helpers.py:102] Training  [ 280/2000]  eta: 1:21:35  memoryused: 14231.0000 (14402.7224)  lr: 0.0007 (0.0005)  wd: 0.0559 (0.0458)  mom: 0.9924 (0.9921)  last_layer_lr: 0.0007 (0.0005)  current_batch_size: 32.0000 (32.0000)  total_loss: 13.8263 (13.8599)  dino_local_crops_loss: 9.8582 (9.8462)  dino_global_crops_loss: 1.2324 (1.2310)  koleo_loss: -0.0155 (0.0417)  ibot_loss: 2.7512 (2.7409)  time: 0.953642  data: 0.000133  max mem: 20010
I20240512 16:03:43 3637928 dinov2 helpers.py:102] Training  [ 290/2000]  eta: 1:19:16  memoryused: 14231.0000 (14396.8213)  lr: 0.0007 (0.0005)  wd: 0.0571 (0.0462)  mom: 0.9924 (0.9921)  last_layer_lr: 0.0007 (0.0005)  current_batch_size: 32.0000 (32.0000)  total_loss: 13.8266 (13.8587)  dino_local_crops_loss: 9.8583 (9.8466)  dino_global_crops_loss: 1.2324 (1.2311)  koleo_loss: -0.0159 (0.0398)  ibot_loss: 2.7522 (2.7413)  time: 0.957821  data: 0.000107  max mem: 20010
I20240512 16:03:51 3637928 fvcore.common.checkpoint __init__.py:109] Saving checkpoint to /home/guevel/OT4D/cell_similarity/src/cell_similarity/scripts/model_0000299.rank_0.pth
I20240512 16:04:54 3637928 dinov2 helpers.py:102] Training  [ 300/2000]  eta: 1:22:55  memoryused: 14231.0000 (14391.3987)  lr: 0.0007 (0.0005)  wd: 0.0584 (0.0466)  mom: 0.9924 (0.9921)  last_layer_lr: 0.0007 (0.0005)  current_batch_size: 32.0000 (32.0000)  total_loss: 13.8272 (13.8578)  dino_local_crops_loss: 9.8584 (9.8470)  dino_global_crops_loss: 1.2324 (1.2311)  koleo_loss: -0.0153 (0.0379)  ibot_loss: 2.7513 (2.7417)  time: 4.060180  data: 0.000115  max mem: 20010
I20240512 16:05:04 3637928 dinov2 helpers.py:102] Training  [ 310/2000]  eta: 1:20:39  memoryused: 14231.0000 (14386.2412)  lr: 0.0007 (0.0005)  wd: 0.0596 (0.0470)  mom: 0.9924 (0.9922)  last_layer_lr: 0.0007 (0.0005)  current_batch_size: 32.0000 (32.0000)  total_loss: 13.8300 (13.8569)  dino_local_crops_loss: 9.8584 (9.8474)  dino_global_crops_loss: 1.2324 (1.2311)  koleo_loss: -0.0153 (0.0362)  ibot_loss: 2.7548 (2.7421)  time: 4.053375  data: 0.000122  max mem: 20010
I20240512 16:05:13 3637928 dinov2 helpers.py:102] Training  [ 320/2000]  eta: 1:18:30  memoryused: 14231.0000 (14381.4050)  lr: 0.0007 (0.0005)  wd: 0.0609 (0.0475)  mom: 0.9925 (0.9922)  last_layer_lr: 0.0007 (0.0005)  current_batch_size: 32.0000 (32.0000)  total_loss: 13.8304 (13.8560)  dino_local_crops_loss: 9.8585 (9.8478)  dino_global_crops_loss: 1.2324 (1.2312)  koleo_loss: -0.0161 (0.0346)  ibot_loss: 2.7557 (2.7425)  time: 0.950607  data: 0.000117  max mem: 20010
I20240512 16:05:23 3637928 dinov2 helpers.py:102] Training  [ 330/2000]  eta: 1:16:29  memoryused: 14231.0000 (14376.9396)  lr: 0.0007 (0.0005)  wd: 0.0623 (0.0480)  mom: 0.9925 (0.9922)  last_layer_lr: 0.0007 (0.0005)  current_batch_size: 32.0000 (32.0000)  total_loss: 13.8319 (13.8553)  dino_local_crops_loss: 9.8584 (9.8481)  dino_global_crops_loss: 1.2324 (1.2312)  koleo_loss: -0.0157 (0.0331)  ibot_loss: 2.7574 (2.7430)  time: 0.954862  data: 0.000110  max mem: 20010
I20240512 16:05:32 3637928 dinov2 helpers.py:102] Training  [ 340/2000]  eta: 1:14:34  memoryused: 14231.0000 (14372.6598)  lr: 0.0007 (0.0005)  wd: 0.0636 (0.0484)  mom: 0.9925 (0.9922)  last_layer_lr: 0.0007 (0.0005)  current_batch_size: 32.0000 (32.0000)  total_loss: 13.8340 (13.8547)  dino_local_crops_loss: 9.8583 (9.8484)  dino_global_crops_loss: 1.2323 (1.2313)  koleo_loss: -0.0157 (0.0316)  ibot_loss: 2.7581 (2.7434)  time: 0.959334  data: 0.000107  max mem: 20010
I20240512 16:05:42 3637928 dinov2 helpers.py:102] Training  [ 350/2000]  eta: 1:12:46  memoryused: 14231.0000 (14368.6239)  lr: 0.0007 (0.0005)  wd: 0.0651 (0.0489)  mom: 0.9926 (0.9922)  last_layer_lr: 0.0007 (0.0005)  current_batch_size: 32.0000 (32.0000)  total_loss: 13.8340 (13.8541)  dino_local_crops_loss: 9.8582 (9.8487)  dino_global_crops_loss: 1.2323 (1.2313)  koleo_loss: -0.0154 (0.0303)  ibot_loss: 2.7576 (2.7438)  time: 0.959719  data: 0.000111  max mem: 20010
I20240512 16:05:51 3637928 fvcore.common.checkpoint __init__.py:109] Saving checkpoint to /home/guevel/OT4D/cell_similarity/src/cell_similarity/scripts/model_0000359.rank_0.pth
I20240512 16:06:55 3637928 dinov2 helpers.py:102] Training  [ 360/2000]  eta: 1:15:49  memoryused: 14231.0000 (14364.8116)  lr: 0.0007 (0.0005)  wd: 0.0665 (0.0495)  mom: 0.9926 (0.9922)  last_layer_lr: 0.0007 (0.0005)  current_batch_size: 32.0000 (32.0000)  total_loss: 13.8328 (13.8535)  dino_local_crops_loss: 9.8582 (9.8489)  dino_global_crops_loss: 1.2323 (1.2313)  koleo_loss: -0.0156 (0.0290)  ibot_loss: 2.7579 (2.7443)  time: 4.110301  data: 0.000135  max mem: 20010
I20240512 16:07:04 3637928 dinov2 helpers.py:102] Training  [ 370/2000]  eta: 1:14:01  memoryused: 14231.0000 (14361.2049)  lr: 0.0007 (0.0005)  wd: 0.0680 (0.0500)  mom: 0.9926 (0.9922)  last_layer_lr: 0.0007 (0.0005)  current_batch_size: 32.0000 (32.0000)  total_loss: 13.8333 (13.8530)  dino_local_crops_loss: 9.8582 (9.8492)  dino_global_crops_loss: 1.2323 (1.2313)  koleo_loss: -0.0166 (0.0278)  ibot_loss: 2.7592 (2.7447)  time: 4.108421  data: 0.000142  max mem: 20010
I20240512 16:07:14 3637928 dinov2 helpers.py:102] Training  [ 380/2000]  eta: 1:12:19  memoryused: 14231.0000 (14357.7874)  lr: 0.0007 (0.0005)  wd: 0.0696 (0.0505)  mom: 0.9927 (0.9922)  last_layer_lr: 0.0007 (0.0005)  current_batch_size: 32.0000 (32.0000)  total_loss: 13.8354 (13.8525)  dino_local_crops_loss: 9.8583 (9.8494)  dino_global_crops_loss: 1.2323 (1.2314)  koleo_loss: -0.0168 (0.0266)  ibot_loss: 2.7614 (2.7451)  time: 0.955498  data: 0.000119  max mem: 20010
I20240512 16:07:23 3637928 dinov2 helpers.py:102] Training  [ 390/2000]  eta: 1:10:41  memoryused: 14231.0000 (14354.5448)  lr: 0.0007 (0.0005)  wd: 0.0711 (0.0511)  mom: 0.9927 (0.9922)  last_layer_lr: 0.0007 (0.0005)  current_batch_size: 32.0000 (32.0000)  total_loss: 13.8354 (13.8521)  dino_local_crops_loss: 9.8583 (9.8496)  dino_global_crops_loss: 1.2323 (1.2314)  koleo_loss: -0.0166 (0.0255)  ibot_loss: 2.7621 (2.7455)  time: 0.956482  data: 0.000124  max mem: 20010
I20240512 16:07:33 3637928 dinov2 helpers.py:102] Training  [ 400/2000]  eta: 1:09:08  memoryused: 14231.0000 (14351.4638)  lr: 0.0007 (0.0005)  wd: 0.0727 (0.0516)  mom: 0.9927 (0.9923)  last_layer_lr: 0.0007 (0.0005)  current_batch_size: 32.0000 (32.0000)  total_loss: 13.8358 (13.8517)  dino_local_crops_loss: 9.8583 (9.8499)  dino_global_crops_loss: 1.2323 (1.2314)  koleo_loss: -0.0164 (0.0245)  ibot_loss: 2.7620 (2.7459)  time: 0.956386  data: 0.000125  max mem: 20010
I20240512 16:07:42 3637928 dinov2 helpers.py:102] Training  [ 410/2000]  eta: 1:07:39  memoryused: 14231.0000 (14348.5328)  lr: 0.0007 (0.0005)  wd: 0.0744 (0.0522)  mom: 0.9928 (0.9923)  last_layer_lr: 0.0007 (0.0005)  current_batch_size: 32.0000 (32.0000)  total_loss: 13.8373 (13.8513)  dino_local_crops_loss: 9.8583 (9.8501)  dino_global_crops_loss: 1.2323 (1.2314)  koleo_loss: -0.0157 (0.0235)  ibot_loss: 2.7621 (2.7463)  time: 0.958857  data: 0.000119  max mem: 20010
I20240512 16:07:51 3637928 fvcore.common.checkpoint __init__.py:109] Saving checkpoint to /home/guevel/OT4D/cell_similarity/src/cell_similarity/scripts/model_0000419.rank_0.pth
I20240512 16:08:54 3637928 dinov2 helpers.py:102] Training  [ 420/2000]  eta: 1:10:05  memoryused: 14231.0000 (14345.7411)  lr: 0.0007 (0.0005)  wd: 0.0761 (0.0528)  mom: 0.9928 (0.9923)  last_layer_lr: 0.0007 (0.0005)  current_batch_size: 32.0000 (32.0000)  total_loss: 13.8362 (13.8510)  dino_local_crops_loss: 9.8583 (9.8503)  dino_global_crops_loss: 1.2323 (1.2315)  koleo_loss: -0.0159 (0.0226)  ibot_loss: 2.7619 (2.7467)  time: 4.047517  data: 0.000143  max mem: 20010
I20240512 16:09:03 3637928 dinov2 helpers.py:102] Training  [ 430/2000]  eta: 1:08:36  memoryused: 14231.0000 (14343.0789)  lr: 0.0007 (0.0005)  wd: 0.0778 (0.0534)  mom: 0.9928 (0.9923)  last_layer_lr: 0.0007 (0.0005)  current_batch_size: 32.0000 (32.0000)  total_loss: 13.8374 (13.8507)  dino_local_crops_loss: 9.8582 (9.8504)  dino_global_crops_loss: 1.2323 (1.2315)  koleo_loss: -0.0164 (0.0217)  ibot_loss: 2.7625 (2.7471)  time: 4.039699  data: 0.000146  max mem: 20010
I20240512 16:09:13 3637928 dinov2 helpers.py:102] Training  [ 440/2000]  eta: 1:07:11  memoryused: 14231.0000 (14340.5329)  lr: 0.0007 (0.0005)  wd: 0.0795 (0.0540)  mom: 0.9929 (0.9923)  last_layer_lr: 0.0007 (0.0005)  current_batch_size: 32.0000 (32.0000)  total_loss: 13.8391 (13.8504)  dino_local_crops_loss: 9.8582 (9.8506)  dino_global_crops_loss: 1.2323 (1.2315)  koleo_loss: -0.0166 (0.0208)  ibot_loss: 2.7649 (2.7475)  time: 0.947929  data: 0.000123  max mem: 20010
I20240512 16:09:22 3637928 dinov2 helpers.py:102] Training  [ 450/2000]  eta: 1:05:49  memoryused: 14231.0000 (14338.1042)  lr: 0.0007 (0.0005)  wd: 0.0813 (0.0546)  mom: 0.9929 (0.9923)  last_layer_lr: 0.0007 (0.0005)  current_batch_size: 32.0000 (32.0000)  total_loss: 13.8401 (13.8502)  dino_local_crops_loss: 9.8582 (9.8508)  dino_global_crops_loss: 1.2323 (1.2315)  koleo_loss: -0.0162 (0.0200)  ibot_loss: 2.7642 (2.7479)  time: 0.952789  data: 0.000109  max mem: 20010
I20240512 16:09:32 3637928 dinov2 helpers.py:102] Training  [ 460/2000]  eta: 1:04:31  memoryused: 14231.0000 (14335.7809)  lr: 0.0007 (0.0005)  wd: 0.0831 (0.0553)  mom: 0.9930 (0.9923)  last_layer_lr: 0.0007 (0.0005)  current_batch_size: 32.0000 (32.0000)  total_loss: 13.8413 (13.8500)  dino_local_crops_loss: 9.8582 (9.8509)  dino_global_crops_loss: 1.2323 (1.2315)  koleo_loss: -0.0151 (0.0193)  ibot_loss: 2.7655 (2.7483)  time: 0.961582  data: 0.000108  max mem: 20010
I20240512 16:09:42 3637928 dinov2 helpers.py:102] Training  [ 470/2000]  eta: 1:03:15  memoryused: 14231.0000 (14333.5563)  lr: 0.0007 (0.0005)  wd: 0.0850 (0.0559)  mom: 0.9930 (0.9924)  last_layer_lr: 0.0007 (0.0005)  current_batch_size: 32.0000 (32.0000)  total_loss: 13.8392 (13.8497)  dino_local_crops_loss: 9.8582 (9.8511)  dino_global_crops_loss: 1.2323 (1.2315)  koleo_loss: -0.0155 (0.0185)  ibot_loss: 2.7644 (2.7486)  time: 0.964526  data: 0.000110  max mem: 20010
I20240512 16:09:50 3637928 fvcore.common.checkpoint __init__.py:109] Saving checkpoint to /home/guevel/OT4D/cell_similarity/src/cell_similarity/scripts/model_0000479.rank_0.pth
I20240512 16:11:46 3637928 dinov2 helpers.py:102] Training  [ 480/2000]  eta: 1:08:06  memoryused: 14231.0000 (14331.4241)  lr: 0.0007 (0.0006)  wd: 0.0869 (0.0566)  mom: 0.9930 (0.9924)  last_layer_lr: 0.0007 (0.0006)  current_batch_size: 32.0000 (32.0000)  total_loss: 13.8391 (13.8495)  dino_local_crops_loss: 9.8582 (9.8512)  dino_global_crops_loss: 1.2323 (1.2316)  koleo_loss: -0.0164 (0.0178)  ibot_loss: 2.7650 (2.7490)  time: 6.711057  data: 0.000126  max mem: 20010
I20240512 16:11:56 3637928 dinov2 helpers.py:102] Training  [ 490/2000]  eta: 1:06:46  memoryused: 14231.0000 (14329.3788)  lr: 0.0007 (0.0006)  wd: 0.0888 (0.0573)  mom: 0.9931 (0.9924)  last_layer_lr: 0.0007 (0.0006)  current_batch_size: 32.0000 (32.0000)  total_loss: 13.8408 (13.8494)  dino_local_crops_loss: 9.8582 (9.8514)  dino_global_crops_loss: 1.2323 (1.2316)  koleo_loss: -0.0158 (0.0171)  ibot_loss: 2.7656 (2.7493)  time: 6.712770  data: 0.000132  max mem: 20010
I20240512 16:12:06 3637928 dinov2 helpers.py:102] Training  [ 500/2000]  eta: 1:05:28  memoryused: 14231.0000 (14327.4152)  lr: 0.0007 (0.0006)  wd: 0.0907 (0.0580)  mom: 0.9931 (0.9924)  last_layer_lr: 0.0007 (0.0006)  current_batch_size: 32.0000 (32.0000)  total_loss: 13.8413 (13.8492)  dino_local_crops_loss: 9.8582 (9.8515)  dino_global_crops_loss: 1.2323 (1.2316)  koleo_loss: -0.0157 (0.0165)  ibot_loss: 2.7661 (2.7497)  time: 0.962176  data: 0.000123  max mem: 20010
I20240512 16:12:15 3637928 dinov2 helpers.py:102] Training  [ 510/2000]  eta: 1:04:14  memoryused: 14231.0000 (14325.5284)  lr: 0.0007 (0.0006)  wd: 0.0927 (0.0587)  mom: 0.9932 (0.9924)  last_layer_lr: 0.0007 (0.0006)  current_batch_size: 32.0000 (32.0000)  total_loss: 13.8413 (13.8491)  dino_local_crops_loss: 9.8582 (9.8517)  dino_global_crops_loss: 1.2323 (1.2316)  koleo_loss: -0.0157 (0.0158)  ibot_loss: 2.7667 (2.7500)  time: 0.962847  data: 0.000119  max mem: 20010
I20240512 16:12:25 3637928 dinov2 helpers.py:102] Training  [ 520/2000]  eta: 1:03:02  memoryused: 14231.0000 (14323.7140)  lr: 0.0007 (0.0006)  wd: 0.0947 (0.0594)  mom: 0.9932 (0.9924)  last_layer_lr: 0.0007 (0.0006)  current_batch_size: 32.0000 (32.0000)  total_loss: 13.8429 (13.8490)  dino_local_crops_loss: 9.8582 (9.8518)  dino_global_crops_loss: 1.2323 (1.2316)  koleo_loss: -0.0146 (0.0153)  ibot_loss: 2.7672 (2.7503)  time: 0.969506  data: 0.000113  max mem: 20010
I20240512 16:12:35 3637928 dinov2 helpers.py:102] Training  [ 530/2000]  eta: 1:01:53  memoryused: 14231.0000 (14321.9680)  lr: 0.0007 (0.0006)  wd: 0.0968 (0.0601)  mom: 0.9933 (0.9924)  last_layer_lr: 0.0007 (0.0006)  current_batch_size: 32.0000 (32.0000)  total_loss: 13.8436 (13.8489)  dino_local_crops_loss: 9.8582 (9.8519)  dino_global_crops_loss: 1.2323 (1.2316)  koleo_loss: -0.0145 (0.0147)  ibot_loss: 2.7675 (2.7506)  time: 0.971494  data: 0.000122  max mem: 20010
I20240512 16:12:43 3637928 fvcore.common.checkpoint __init__.py:109] Saving checkpoint to /home/guevel/OT4D/cell_similarity/src/cell_similarity/scripts/model_0000539.rank_0.pth
I20240512 16:16:15 3637928 dinov2 helpers.py:102] Training  [ 540/2000]  eta: 1:10:13  memoryused: 14231.0000 (14320.2865)  lr: 0.0006 (0.0006)  wd: 0.0989 (0.0608)  mom: 0.9933 (0.9925)  last_layer_lr: 0.0006 (0.0006)  current_batch_size: 32.0000 (32.0000)  total_loss: 13.8432 (13.8488)  dino_local_crops_loss: 9.8582 (9.8520)  dino_global_crops_loss: 1.2323 (1.2316)  koleo_loss: -0.0155 (0.0141)  ibot_loss: 2.7687 (2.7510)  time: 11.488682  data: 0.000144  max mem: 20010
I20240512 16:16:24 3637928 dinov2 helpers.py:102] Training  [ 550/2000]  eta: 1:08:54  memoryused: 14231.0000 (14318.6661)  lr: 0.0006 (0.0006)  wd: 0.1010 (0.0616)  mom: 0.9934 (0.9925)  last_layer_lr: 0.0006 (0.0006)  current_batch_size: 32.0000 (32.0000)  total_loss: 13.8442 (13.8487)  dino_local_crops_loss: 9.8582 (9.8521)  dino_global_crops_loss: 1.2323 (1.2317)  koleo_loss: -0.0147 (0.0136)  ibot_loss: 2.7683 (2.7513)  time: 11.478155  data: 0.000148  max mem: 20010
I20240512 16:16:34 3637928 dinov2 helpers.py:102] Training  [ 560/2000]  eta: 1:07:37  memoryused: 14231.0000 (14317.1034)  lr: 0.0006 (0.0006)  wd: 0.1031 (0.0623)  mom: 0.9934 (0.9925)  last_layer_lr: 0.0006 (0.0006)  current_batch_size: 32.0000 (32.0000)  total_loss: 13.8438 (13.8486)  dino_local_crops_loss: 9.8583 (9.8522)  dino_global_crops_loss: 1.2323 (1.2317)  koleo_loss: -0.0145 (0.0131)  ibot_loss: 2.7678 (2.7516)  time: 0.955894  data: 0.000142  max mem: 20010
I20240512 16:16:44 3637928 dinov2 helpers.py:102] Training  [ 570/2000]  eta: 1:06:22  memoryused: 14231.0000 (14315.5954)  lr: 0.0006 (0.0006)  wd: 0.1053 (0.0631)  mom: 0.9935 (0.9925)  last_layer_lr: 0.0006 (0.0006)  current_batch_size: 32.0000 (32.0000)  total_loss: 13.8431 (13.8485)  dino_local_crops_loss: 9.8583 (9.8524)  dino_global_crops_loss: 1.2323 (1.2317)  koleo_loss: -0.0163 (0.0126)  ibot_loss: 2.7677 (2.7519)  time: 0.962038  data: 0.000150  max mem: 20010
I20240512 16:16:53 3637928 dinov2 helpers.py:102] Training  [ 580/2000]  eta: 1:05:09  memoryused: 14231.0000 (14314.1842)  lr: 0.0006 (0.0006)  wd: 0.1075 (0.0639)  mom: 0.9935 (0.9925)  last_layer_lr: 0.0006 (0.0006)  current_batch_size: 32.0000 (32.0000)  total_loss: 13.8424 (13.8484)  dino_local_crops_loss: 9.8583 (9.8525)  dino_global_crops_loss: 1.2323 (1.2317)  koleo_loss: -0.0167 (0.0121)  ibot_loss: 2.7683 (2.7522)  time: 0.960246  data: 0.000161  max mem: 20010
I20240512 16:17:03 3637928 dinov2 helpers.py:102] Training  [ 590/2000]  eta: 1:03:59  memoryused: 14231.0000 (14312.7766)  lr: 0.0006 (0.0006)  wd: 0.1097 (0.0647)  mom: 0.9935 (0.9925)  last_layer_lr: 0.0006 (0.0006)  current_batch_size: 32.0000 (32.0000)  total_loss: 13.8426 (13.8483)  dino_local_crops_loss: 9.8582 (9.8526)  dino_global_crops_loss: 1.2323 (1.2317)  koleo_loss: -0.0166 (0.0116)  ibot_loss: 2.7685 (2.7524)  time: 0.961043  data: 0.000140  max mem: 20010
I20240512 16:17:12 3637928 fvcore.common.checkpoint __init__.py:109] Saving checkpoint to /home/guevel/OT4D/cell_similarity/src/cell_similarity/scripts/model_0000599.rank_0.pth
I20240512 16:20:33 3637928 dinov2 helpers.py:102] Training  [ 600/2000]  eta: 1:10:35  memoryused: 14231.0000 (14311.4160)  lr: 0.0006 (0.0006)  wd: 0.1119 (0.0655)  mom: 0.9936 (0.9926)  last_layer_lr: 0.0006 (0.0006)  current_batch_size: 32.0000 (32.0000)  total_loss: 13.8439 (13.8482)  dino_local_crops_loss: 9.8582 (9.8526)  dino_global_crops_loss: 1.2323 (1.2317)  koleo_loss: -0.0154 (0.0112)  ibot_loss: 2.7693 (2.7527)  time: 10.918516  data: 0.000124  max mem: 20010
I20240512 16:20:42 3637928 dinov2 helpers.py:102] Training  [ 610/2000]  eta: 1:09:17  memoryused: 14231.0000 (14310.0998)  lr: 0.0006 (0.0006)  wd: 0.1142 (0.0663)  mom: 0.9936 (0.9926)  last_layer_lr: 0.0006 (0.0006)  current_batch_size: 32.0000 (32.0000)  total_loss: 13.8436 (13.8481)  dino_local_crops_loss: 9.8582 (9.8527)  dino_global_crops_loss: 1.2323 (1.2317)  koleo_loss: -0.0162 (0.0107)  ibot_loss: 2.7694 (2.7530)  time: 10.911785  data: 0.000131  max mem: 20010
I20240512 16:20:52 3637928 dinov2 helpers.py:102] Training  [ 620/2000]  eta: 1:08:02  memoryused: 14231.0000 (14308.8229)  lr: 0.0006 (0.0006)  wd: 0.1165 (0.0672)  mom: 0.9937 (0.9926)  last_layer_lr: 0.0006 (0.0006)  current_batch_size: 32.0000 (32.0000)  total_loss: 13.8424 (13.8480)  dino_local_crops_loss: 9.8582 (9.8528)  dino_global_crops_loss: 1.2323 (1.2317)  koleo_loss: -0.0168 (0.0103)  ibot_loss: 2.7692 (2.7532)  time: 0.956523  data: 0.000129  max mem: 20010
I20240512 16:21:01 3637928 dinov2 helpers.py:102] Training  [ 630/2000]  eta: 1:06:49  memoryused: 14231.0000 (14307.6307)  lr: 0.0006 (0.0006)  wd: 0.1188 (0.0680)  mom: 0.9938 (0.9926)  last_layer_lr: 0.0006 (0.0006)  current_batch_size: 32.0000 (32.0000)  total_loss: 13.8420 (13.8480)  dino_local_crops_loss: 9.8582 (9.8529)  dino_global_crops_loss: 1.2323 (1.2317)  koleo_loss: -0.0169 (0.0098)  ibot_loss: 2.7694 (2.7535)  time: 0.962174  data: 0.000133  max mem: 20010
I20240512 16:21:11 3637928 dinov2 helpers.py:102] Training  [ 640/2000]  eta: 1:05:39  memoryused: 14231.0000 (14306.4353)  lr: 0.0006 (0.0006)  wd: 0.1212 (0.0688)  mom: 0.9938 (0.9926)  last_layer_lr: 0.0006 (0.0006)  current_batch_size: 32.0000 (32.0000)  total_loss: 13.8429 (13.8479)  dino_local_crops_loss: 9.8583 (9.8530)  dino_global_crops_loss: 1.2323 (1.2317)  koleo_loss: -0.0169 (0.0094)  ibot_loss: 2.7688 (2.7537)  time: 0.964812  data: 0.000130  max mem: 20010
I20240512 16:21:21 3637928 dinov2 helpers.py:102] Training  [ 650/2000]  eta: 1:04:30  memoryused: 14231.0000 (14305.2765)  lr: 0.0006 (0.0006)  wd: 0.1236 (0.0697)  mom: 0.9939 (0.9927)  last_layer_lr: 0.0006 (0.0006)  current_batch_size: 32.0000 (32.0000)  total_loss: 13.8435 (13.8478)  dino_local_crops_loss: 9.8583 (9.8531)  dino_global_crops_loss: 1.2323 (1.2318)  koleo_loss: -0.0156 (0.0091)  ibot_loss: 2.7686 (2.7539)  time: 0.967319  data: 0.000126  max mem: 20010
I20240512 16:21:30 3637928 fvcore.common.checkpoint __init__.py:109] Saving checkpoint to /home/guevel/OT4D/cell_similarity/src/cell_similarity/scripts/model_0000659.rank_0.pth
I20240512 16:24:50 3637928 dinov2 helpers.py:102] Training  [ 660/2000]  eta: 1:10:07  memoryused: 14231.0000 (14304.1528)  lr: 0.0006 (0.0006)  wd: 0.1260 (0.0706)  mom: 0.9939 (0.9927)  last_layer_lr: 0.0006 (0.0006)  current_batch_size: 32.0000 (32.0000)  total_loss: 13.8430 (13.8477)  dino_local_crops_loss: 9.8583 (9.8532)  dino_global_crops_loss: 1.2323 (1.2318)  koleo_loss: -0.0162 (0.0087)  ibot_loss: 2.7679 (2.7542)  time: 10.943478  data: 0.000141  max mem: 20010
I20240512 16:25:00 3637928 dinov2 helpers.py:102] Training  [ 670/2000]  eta: 1:08:52  memoryused: 14231.0000 (14303.0626)  lr: 0.0006 (0.0006)  wd: 0.1284 (0.0715)  mom: 0.9940 (0.9927)  last_layer_lr: 0.0006 (0.0006)  current_batch_size: 32.0000 (32.0000)  total_loss: 13.8427 (13.8477)  dino_local_crops_loss: 9.8582 (9.8532)  dino_global_crops_loss: 1.2323 (1.2318)  koleo_loss: -0.0164 (0.0083)  ibot_loss: 2.7681 (2.7544)  time: 10.937364  data: 0.000140  max mem: 20010
I20240512 16:25:09 3637928 dinov2 helpers.py:102] Training  [ 680/2000]  eta: 1:07:40  memoryused: 14231.0000 (14302.0426)  lr: 0.0006 (0.0006)  wd: 0.1308 (0.0723)  mom: 0.9940 (0.9927)  last_layer_lr: 0.0006 (0.0006)  current_batch_size: 32.0000 (32.0000)  total_loss: 13.8439 (13.8476)  dino_local_crops_loss: 9.8582 (9.8533)  dino_global_crops_loss: 1.2323 (1.2318)  koleo_loss: -0.0158 (0.0080)  ibot_loss: 2.7692 (2.7546)  time: 0.958389  data: 0.000125  max mem: 20010
I20240512 16:25:19 3637928 dinov2 helpers.py:102] Training  [ 690/2000]  eta: 1:06:29  memoryused: 14231.0000 (14301.0145)  lr: 0.0006 (0.0006)  wd: 0.1333 (0.0733)  mom: 0.9941 (0.9927)  last_layer_lr: 0.0006 (0.0006)  current_batch_size: 32.0000 (32.0000)  total_loss: 13.8438 (13.8476)  dino_local_crops_loss: 9.8582 (9.8534)  dino_global_crops_loss: 1.2323 (1.2318)  koleo_loss: -0.0154 (0.0076)  ibot_loss: 2.7692 (2.7548)  time: 0.966417  data: 0.000123  max mem: 20010
I20240512 16:25:29 3637928 dinov2 helpers.py:102] Training  [ 700/2000]  eta: 1:05:20  memoryused: 14231.0000 (14300.0157)  lr: 0.0006 (0.0006)  wd: 0.1358 (0.0742)  mom: 0.9941 (0.9928)  last_layer_lr: 0.0006 (0.0006)  current_batch_size: 32.0000 (32.0000)  total_loss: 13.8435 (13.8475)  dino_local_crops_loss: 9.8582 (9.8534)  dino_global_crops_loss: 1.2323 (1.2318)  koleo_loss: -0.0153 (0.0073)  ibot_loss: 2.7681 (2.7550)  time: 0.969974  data: 0.000119  max mem: 20010
I20240512 16:25:38 3637928 dinov2 helpers.py:102] Training  [ 710/2000]  eta: 1:04:13  memoryused: 14231.0000 (14299.0816)  lr: 0.0006 (0.0006)  wd: 0.1383 (0.0751)  mom: 0.9942 (0.9928)  last_layer_lr: 0.0006 (0.0006)  current_batch_size: 32.0000 (32.0000)  total_loss: 13.8428 (13.8474)  dino_local_crops_loss: 9.8582 (9.8535)  dino_global_crops_loss: 1.2323 (1.2318)  koleo_loss: -0.0159 (0.0070)  ibot_loss: 2.7678 (2.7552)  time: 0.969487  data: 0.000124  max mem: 20010
I20240512 16:25:47 3637928 fvcore.common.checkpoint __init__.py:109] Saving checkpoint to /home/guevel/OT4D/cell_similarity/src/cell_similarity/scripts/model_0000719.rank_0.pth
I20240512 16:28:22 3637928 dinov2 helpers.py:102] Training  [ 720/2000]  eta: 1:07:41  memoryused: 14231.0000 (14298.1373)  lr: 0.0006 (0.0006)  wd: 0.1408 (0.0760)  mom: 0.9942 (0.9928)  last_layer_lr: 0.0006 (0.0006)  current_batch_size: 32.0000 (32.0000)  total_loss: 13.8433 (13.8474)  dino_local_crops_loss: 9.8582 (9.8536)  dino_global_crops_loss: 1.2323 (1.2318)  koleo_loss: -0.0156 (0.0067)  ibot_loss: 2.7679 (2.7553)  time: 8.681721  data: 0.000137  max mem: 20010
I20240512 16:28:32 3637928 dinov2 helpers.py:102] Training  [ 730/2000]  eta: 1:06:30  memoryused: 14231.0000 (14297.2189)  lr: 0.0006 (0.0006)  wd: 0.1434 (0.0770)  mom: 0.9943 (0.9928)  last_layer_lr: 0.0006 (0.0006)  current_batch_size: 32.0000 (32.0000)  total_loss: 13.8433 (13.8473)  dino_local_crops_loss: 9.8582 (9.8536)  dino_global_crops_loss: 1.2323 (1.2318)  koleo_loss: -0.0161 (0.0063)  ibot_loss: 2.7689 (2.7555)  time: 8.673716  data: 0.000139  max mem: 20010
I20240512 16:28:41 3637928 dinov2 helpers.py:102] Training  [ 740/2000]  eta: 1:05:22  memoryused: 14231.0000 (14296.3603)  lr: 0.0006 (0.0006)  wd: 0.1459 (0.0779)  mom: 0.9944 (0.9928)  last_layer_lr: 0.0006 (0.0006)  current_batch_size: 32.0000 (32.0000)  total_loss: 13.8422 (13.8472)  dino_local_crops_loss: 9.8582 (9.8537)  dino_global_crops_loss: 1.2323 (1.2318)  koleo_loss: -0.0167 (0.0060)  ibot_loss: 2.7691 (2.7557)  time: 0.954406  data: 0.000128  max mem: 20010
I20240512 16:28:51 3637928 dinov2 helpers.py:102] Training  [ 750/2000]  eta: 1:04:15  memoryused: 14231.0000 (14295.4900)  lr: 0.0006 (0.0006)  wd: 0.1485 (0.0789)  mom: 0.9944 (0.9929)  last_layer_lr: 0.0006 (0.0006)  current_batch_size: 32.0000 (32.0000)  total_loss: 13.8413 (13.8471)  dino_local_crops_loss: 9.8582 (9.8538)  dino_global_crops_loss: 1.2323 (1.2318)  koleo_loss: -0.0172 (0.0057)  ibot_loss: 2.7678 (2.7558)  time: 0.959140  data: 0.000122  max mem: 20010
I20240512 16:29:01 3637928 dinov2 helpers.py:102] Training  [ 760/2000]  eta: 1:03:09  memoryused: 14231.0000 (14294.6426)  lr: 0.0006 (0.0006)  wd: 0.1511 (0.0798)  mom: 0.9945 (0.9929)  last_layer_lr: 0.0006 (0.0006)  current_batch_size: 32.0000 (32.0000)  total_loss: 13.8412 (13.8471)  dino_local_crops_loss: 9.8582 (9.8538)  dino_global_crops_loss: 1.2323 (1.2318)  koleo_loss: -0.0174 (0.0054)  ibot_loss: 2.7685 (2.7560)  time: 0.961062  data: 0.000126  max mem: 20010
I20240512 16:29:10 3637928 dinov2 helpers.py:102] Training  [ 770/2000]  eta: 1:02:06  memoryused: 14231.0000 (14293.8171)  lr: 0.0006 (0.0006)  wd: 0.1537 (0.0808)  mom: 0.9945 (0.9929)  last_layer_lr: 0.0006 (0.0006)  current_batch_size: 32.0000 (32.0000)  total_loss: 13.8415 (13.8470)  dino_local_crops_loss: 9.8583 (9.8539)  dino_global_crops_loss: 1.2323 (1.2318)  koleo_loss: -0.0175 (0.0051)  ibot_loss: 2.7685 (2.7562)  time: 0.963883  data: 0.000127  max mem: 20010
I20240512 16:29:19 3637928 fvcore.common.checkpoint __init__.py:109] Saving checkpoint to /home/guevel/OT4D/cell_similarity/src/cell_similarity/scripts/model_0000779.rank_0.pth
I20240512 16:30:42 3637928 dinov2 helpers.py:102] Training  [ 780/2000]  eta: 1:03:12  memoryused: 14231.0000 (14293.0128)  lr: 0.0005 (0.0006)  wd: 0.1564 (0.0818)  mom: 0.9946 (0.9929)  last_layer_lr: 0.0005 (0.0006)  current_batch_size: 32.0000 (32.0000)  total_loss: 13.8407 (13.8469)  dino_local_crops_loss: 9.8583 (9.8539)  dino_global_crops_loss: 1.2323 (1.2318)  koleo_loss: -0.0180 (0.0048)  ibot_loss: 2.7683 (2.7563)  time: 5.090439  data: 0.000135  max mem: 20010
I20240512 16:30:52 3637928 dinov2 helpers.py:102] Training  [ 790/2000]  eta: 1:02:08  memoryused: 14231.0000 (14292.2238)  lr: 0.0005 (0.0006)  wd: 0.1590 (0.0828)  mom: 0.9946 (0.9930)  last_layer_lr: 0.0005 (0.0006)  current_batch_size: 32.0000 (32.0000)  total_loss: 13.8402 (13.8468)  dino_local_crops_loss: 9.8582 (9.8540)  dino_global_crops_loss: 1.2323 (1.2319)  koleo_loss: -0.0182 (0.0045)  ibot_loss: 2.7677 (2.7564)  time: 5.087755  data: 0.000140  max mem: 20010
I20240512 16:31:02 3637928 dinov2 helpers.py:102] Training  [ 800/2000]  eta: 1:01:05  memoryused: 14231.0000 (14291.4594)  lr: 0.0005 (0.0006)  wd: 0.1617 (0.0838)  mom: 0.9947 (0.9930)  last_layer_lr: 0.0005 (0.0006)  current_batch_size: 32.0000 (32.0000)  total_loss: 13.8394 (13.8467)  dino_local_crops_loss: 9.8582 (9.8540)  dino_global_crops_loss: 1.2323 (1.2319)  koleo_loss: -0.0183 (0.0042)  ibot_loss: 2.7672 (2.7566)  time: 0.960294  data: 0.000130  max mem: 20010
I20240512 16:31:11 3637928 dinov2 helpers.py:102] Training  [ 810/2000]  eta: 1:00:04  memoryused: 14231.0000 (14290.7139)  lr: 0.0005 (0.0006)  wd: 0.1644 (0.0848)  mom: 0.9948 (0.9930)  last_layer_lr: 0.0005 (0.0006)  current_batch_size: 32.0000 (32.0000)  total_loss: 13.8397 (13.8466)  dino_local_crops_loss: 9.8582 (9.8541)  dino_global_crops_loss: 1.2323 (1.2319)  koleo_loss: -0.0179 (0.0040)  ibot_loss: 2.7676 (2.7567)  time: 0.959970  data: 0.000120  max mem: 20010
I20240512 16:31:21 3637928 dinov2 helpers.py:102] Training  [ 820/2000]  eta: 0:59:04  memoryused: 14231.0000 (14289.9866)  lr: 0.0005 (0.0006)  wd: 0.1671 (0.0858)  mom: 0.9948 (0.9930)  last_layer_lr: 0.0005 (0.0006)  current_batch_size: 32.0000 (32.0000)  total_loss: 13.8400 (13.8466)  dino_local_crops_loss: 9.8582 (9.8541)  dino_global_crops_loss: 1.2323 (1.2319)  koleo_loss: -0.0181 (0.0037)  ibot_loss: 2.7680 (2.7568)  time: 0.966372  data: 0.000140  max mem: 20010
I20240512 16:31:31 3637928 dinov2 helpers.py:102] Training  [ 830/2000]  eta: 0:58:06  memoryused: 14231.0000 (14289.2768)  lr: 0.0005 (0.0006)  wd: 0.1698 (0.0869)  mom: 0.9949 (0.9930)  last_layer_lr: 0.0005 (0.0006)  current_batch_size: 32.0000 (32.0000)  total_loss: 13.8394 (13.8465)  dino_local_crops_loss: 9.8582 (9.8542)  dino_global_crops_loss: 1.2323 (1.2319)  koleo_loss: -0.0191 (0.0034)  ibot_loss: 2.7680 (2.7570)  time: 0.968682  data: 0.000142  max mem: 20010
I20240512 16:31:40 3637928 fvcore.common.checkpoint __init__.py:109] Saving checkpoint to /home/guevel/OT4D/cell_similarity/src/cell_similarity/scripts/model_0000839.rank_0.pth
I20240512 16:34:17 3637928 dinov2 helpers.py:102] Training  [ 840/2000]  eta: 1:00:44  memoryused: 14231.0000 (14288.6147)  lr: 0.0005 (0.0006)  wd: 0.1725 (0.0879)  mom: 0.9949 (0.9931)  last_layer_lr: 0.0005 (0.0006)  current_batch_size: 32.0000 (32.0000)  total_loss: 13.8399 (13.8464)  dino_local_crops_loss: 9.8582 (9.8542)  dino_global_crops_loss: 1.2323 (1.2319)  koleo_loss: -0.0182 (0.0032)  ibot_loss: 2.7675 (2.7571)  time: 8.794879  data: 0.000144  max mem: 20010
I20240512 16:34:27 3637928 dinov2 helpers.py:102] Training  [ 850/2000]  eta: 0:59:43  memoryused: 14231.0000 (14287.9377)  lr: 0.0005 (0.0006)  wd: 0.1752 (0.0889)  mom: 0.9950 (0.9931)  last_layer_lr: 0.0005 (0.0006)  current_batch_size: 32.0000 (32.0000)  total_loss: 13.8398 (13.8463)  dino_local_crops_loss: 9.8582 (9.8543)  dino_global_crops_loss: 1.2323 (1.2319)  koleo_loss: -0.0180 (0.0029)  ibot_loss: 2.7667 (2.7572)  time: 8.790728  data: 0.000163  max mem: 20010
I20240512 16:34:36 3637928 dinov2 helpers.py:102] Training  [ 860/2000]  eta: 0:58:43  memoryused: 14231.0000 (14287.2764)  lr: 0.0005 (0.0006)  wd: 0.1780 (0.0900)  mom: 0.9951 (0.9931)  last_layer_lr: 0.0005 (0.0006)  current_batch_size: 32.0000 (32.0000)  total_loss: 13.8380 (13.8462)  dino_local_crops_loss: 9.8582 (9.8543)  dino_global_crops_loss: 1.2323 (1.2319)  koleo_loss: -0.0181 (0.0027)  ibot_loss: 2.7653 (2.7573)  time: 0.960904  data: 0.000142  max mem: 20010
I20240512 16:34:46 3637928 dinov2 helpers.py:102] Training  [ 870/2000]  eta: 0:57:45  memoryused: 14231.0000 (14286.6303)  lr: 0.0005 (0.0006)  wd: 0.1807 (0.0910)  mom: 0.9951 (0.9931)  last_layer_lr: 0.0005 (0.0006)  current_batch_size: 32.0000 (32.0000)  total_loss: 13.8392 (13.8461)  dino_local_crops_loss: 9.8582 (9.8544)  dino_global_crops_loss: 1.2323 (1.2319)  koleo_loss: -0.0179 (0.0024)  ibot_loss: 2.7670 (2.7574)  time: 0.961962  data: 0.000168  max mem: 20010
I20240512 16:34:56 3637928 dinov2 helpers.py:102] Training  [ 880/2000]  eta: 0:56:47  memoryused: 14231.0000 (14285.9989)  lr: 0.0005 (0.0006)  wd: 0.1835 (0.0921)  mom: 0.9952 (0.9932)  last_layer_lr: 0.0005 (0.0006)  current_batch_size: 32.0000 (32.0000)  total_loss: 13.8396 (13.8461)  dino_local_crops_loss: 9.8582 (9.8544)  dino_global_crops_loss: 1.2323 (1.2319)  koleo_loss: -0.0176 (0.0022)  ibot_loss: 2.7670 (2.7575)  time: 0.961539  data: 0.000174  max mem: 20010
I20240512 16:35:05 3637928 dinov2 helpers.py:102] Training  [ 890/2000]  eta: 0:55:51  memoryused: 14231.0000 (14285.3816)  lr: 0.0005 (0.0006)  wd: 0.1863 (0.0932)  mom: 0.9953 (0.9932)  last_layer_lr: 0.0005 (0.0006)  current_batch_size: 32.0000 (32.0000)  total_loss: 13.8399 (13.8460)  dino_local_crops_loss: 9.8582 (9.8545)  dino_global_crops_loss: 1.2323 (1.2319)  koleo_loss: -0.0176 (0.0020)  ibot_loss: 2.7674 (2.7576)  time: 0.963916  data: 0.000126  max mem: 20010
I20240512 16:35:14 3637928 fvcore.common.checkpoint __init__.py:109] Saving checkpoint to /home/guevel/OT4D/cell_similarity/src/cell_similarity/scripts/model_0000899.rank_0.pth
I20240512 16:40:18 3637928 dinov2 helpers.py:102] Training  [ 900/2000]  eta: 1:01:05  memoryused: 14231.0000 (14284.7780)  lr: 0.0005 (0.0006)  wd: 0.1891 (0.0943)  mom: 0.9953 (0.9932)  last_layer_lr: 0.0005 (0.0006)  current_batch_size: 32.0000 (32.0000)  total_loss: 13.8399 (13.8459)  dino_local_crops_loss: 9.8583 (9.8545)  dino_global_crops_loss: 1.2323 (1.2319)  koleo_loss: -0.0176 (0.0018)  ibot_loss: 2.7676 (2.7577)  time: 16.075624  data: 0.000151  max mem: 20013
I20240512 16:40:28 3637928 dinov2 helpers.py:102] Training  [ 910/2000]  eta: 1:00:03  memoryused: 14231.0000 (14284.1877)  lr: 0.0005 (0.0006)  wd: 0.1918 (0.0954)  mom: 0.9954 (0.9932)  last_layer_lr: 0.0005 (0.0006)  current_batch_size: 32.0000 (32.0000)  total_loss: 13.8405 (13.8459)  dino_local_crops_loss: 9.8584 (9.8546)  dino_global_crops_loss: 1.2323 (1.2319)  koleo_loss: -0.0175 (0.0016)  ibot_loss: 2.7678 (2.7578)  time: 16.069820  data: 0.000167  max mem: 20013
I20240512 16:40:40 3637928 dinov2 helpers.py:102] Training  [ 920/2000]  eta: 0:59:05  memoryused: 14231.0000 (14283.6384)  lr: 0.0005 (0.0006)  wd: 0.1946 (0.0965)  mom: 0.9954 (0.9933)  last_layer_lr: 0.0005 (0.0006)  current_batch_size: 32.0000 (32.0000)  total_loss: 13.8416 (13.8458)  dino_local_crops_loss: 9.8583 (9.8546)  dino_global_crops_loss: 1.2323 (1.2319)  koleo_loss: -0.0172 (0.0014)  ibot_loss: 2.7683 (2.7579)  time: 1.060997  data: 0.102811  max mem: 20013
I20240512 16:40:50 3637928 dinov2 helpers.py:102] Training  [ 930/2000]  eta: 0:58:05  memoryused: 14231.0000 (14283.0967)  lr: 0.0005 (0.0006)  wd: 0.1974 (0.0976)  mom: 0.9955 (0.9933)  last_layer_lr: 0.0005 (0.0006)  current_batch_size: 32.0000 (32.0000)  total_loss: 13.8403 (13.8458)  dino_local_crops_loss: 9.8583 (9.8546)  dino_global_crops_loss: 1.2323 (1.2319)  koleo_loss: -0.0166 (0.0012)  ibot_loss: 2.7673 (2.7580)  time: 1.064390  data: 0.102800  max mem: 20013
I20240512 16:41:00 3637928 dinov2 helpers.py:102] Training  [ 940/2000]  eta: 0:57:07  memoryused: 14231.0000 (14282.5707)  lr: 0.0005 (0.0006)  wd: 0.2002 (0.0987)  mom: 0.9956 (0.9933)  last_layer_lr: 0.0005 (0.0006)  current_batch_size: 32.0000 (32.0000)  total_loss: 13.8393 (13.8457)  dino_local_crops_loss: 9.8583 (9.8547)  dino_global_crops_loss: 1.2323 (1.2319)  koleo_loss: -0.0169 (0.0010)  ibot_loss: 2.7662 (2.7581)  time: 0.958008  data: 0.000148  max mem: 20013
I20240512 16:41:15 3637928 dinov2 helpers.py:102] Training  [ 950/2000]  eta: 0:56:15  memoryused: 14231.0000 (14282.0284)  lr: 0.0005 (0.0006)  wd: 0.2031 (0.0998)  mom: 0.9956 (0.9933)  last_layer_lr: 0.0005 (0.0006)  current_batch_size: 32.0000 (32.0000)  total_loss: 13.8401 (13.8456)  dino_local_crops_loss: 9.8582 (9.8547)  dino_global_crops_loss: 1.2323 (1.2319)  koleo_loss: -0.0172 (0.0008)  ibot_loss: 2.7667 (2.7582)  time: 1.200216  data: 0.241382  max mem: 20013
I20240512 16:41:23 3637928 fvcore.common.checkpoint __init__.py:109] Saving checkpoint to /home/guevel/OT4D/cell_similarity/src/cell_similarity/scripts/model_0000959.rank_0.pth
I20240512 16:45:49 3637928 dinov2 helpers.py:102] Training  [ 960/2000]  eta: 1:00:05  memoryused: 14231.0000 (14281.4974)  lr: 0.0004 (0.0006)  wd: 0.2059 (0.1009)  mom: 0.9957 (0.9934)  last_layer_lr: 0.0004 (0.0006)  current_batch_size: 32.0000 (32.0000)  total_loss: 13.8413 (13.8456)  dino_local_crops_loss: 9.8582 (9.8547)  dino_global_crops_loss: 1.2323 (1.2319)  koleo_loss: -0.0177 (0.0006)  ibot_loss: 2.7687 (2.7583)  time: 14.437990  data: 0.241366  max mem: 20013
I20240512 16:45:59 3637928 dinov2 helpers.py:102] Training  [ 970/2000]  eta: 0:59:03  memoryused: 14231.0000 (14280.9773)  lr: 0.0004 (0.0006)  wd: 0.2087 (0.1020)  mom: 0.9957 (0.9934)  last_layer_lr: 0.0004 (0.0006)  current_batch_size: 32.0000 (32.0000)  total_loss: 13.8413 (13.8455)  dino_local_crops_loss: 9.8582 (9.8548)  dino_global_crops_loss: 1.2323 (1.2319)  koleo_loss: -0.0177 (0.0004)  ibot_loss: 2.7691 (2.7584)  time: 14.192282  data: 0.000125  max mem: 20013
I20240512 16:46:10 3637928 dinov2 helpers.py:102] Training  [ 980/2000]  eta: 0:58:03  memoryused: 14231.0000 (14280.4679)  lr: 0.0004 (0.0006)  wd: 0.2115 (0.1032)  mom: 0.9958 (0.9934)  last_layer_lr: 0.0004 (0.0006)  current_batch_size: 32.0000 (32.0000)  total_loss: 13.8382 (13.8454)  dino_local_crops_loss: 9.8582 (9.8548)  dino_global_crops_loss: 1.2323 (1.2319)  koleo_loss: -0.0190 (0.0002)  ibot_loss: 2.7673 (2.7585)  time: 0.957343  data: 0.000117  max mem: 20013
I20240512 16:46:27 3637928 dinov2 helpers.py:102] Training  [ 990/2000]  eta: 0:57:11  memoryused: 14231.0000 (14279.9687)  lr: 0.0004 (0.0006)  wd: 0.2143 (0.1043)  mom: 0.9959 (0.9934)  last_layer_lr: 0.0004 (0.0006)  current_batch_size: 32.0000 (32.0000)  total_loss: 13.8386 (13.8454)  dino_local_crops_loss: 9.8582 (9.8548)  dino_global_crops_loss: 1.2323 (1.2319)  koleo_loss: -0.0195 (0.0000)  ibot_loss: 2.7673 (2.7586)  time: 1.316290  data: 0.356042  max mem: 20013
I20240512 16:46:37 3637928 dinov2 helpers.py:102] Training  [1000/2000]  eta: 0:56:13  memoryused: 14231.0000 (14279.4795)  lr: 0.0004 (0.0006)  wd: 0.2172 (0.1054)  mom: 0.9959 (0.9935)  last_layer_lr: 0.0004 (0.0006)  current_batch_size: 32.0000 (32.0000)  total_loss: 13.8395 (13.8453)  dino_local_crops_loss: 9.8582 (9.8549)  dino_global_crops_loss: 1.2323 (1.2319)  koleo_loss: -0.0195 (-0.0002)  ibot_loss: 2.7682 (2.7587)  time: 1.316697  data: 0.356050  max mem: 20013
I20240512 16:46:53 3637928 dinov2 helpers.py:102] Training  [1010/2000]  eta: 0:55:20  memoryused: 14231.0000 (14279.0000)  lr: 0.0004 (0.0006)  wd: 0.2200 (0.1066)  mom: 0.9960 (0.9935)  last_layer_lr: 0.0004 (0.0006)  current_batch_size: 32.0000 (32.0000)  total_loss: 13.8393 (13.8453)  dino_local_crops_loss: 9.8582 (9.8549)  dino_global_crops_loss: 1.2323 (1.2320)  koleo_loss: -0.0185 (-0.0004)  ibot_loss: 2.7678 (2.7588)  time: 1.199422  data: 0.236067  max mem: 20013
I20240512 16:47:13 3637928 fvcore.common.checkpoint __init__.py:109] Saving checkpoint to /home/guevel/OT4D/cell_similarity/src/cell_similarity/scripts/model_0001019.rank_0.pth
I20240512 16:51:14 3637928 dinov2 helpers.py:102] Training  [1020/2000]  eta: 0:58:25  memoryused: 14231.0000 (14278.5299)  lr: 0.0004 (0.0006)  wd: 0.2228 (0.1077)  mom: 0.9961 (0.9935)  last_layer_lr: 0.0004 (0.0005)  current_batch_size: 32.0000 (32.0000)  total_loss: 13.8393 (13.8452)  dino_local_crops_loss: 9.8582 (9.8549)  dino_global_crops_loss: 1.2323 (1.2320)  koleo_loss: -0.0191 (-0.0005)  ibot_loss: 2.7674 (2.7588)  time: 13.769369  data: 0.785812  max mem: 20013
I20240512 16:51:24 3637928 dinov2 helpers.py:102] Training  [1030/2000]  eta: 0:57:25  memoryused: 14231.0000 (14278.0689)  lr: 0.0004 (0.0005)  wd: 0.2257 (0.1089)  mom: 0.9961 (0.9935)  last_layer_lr: 0.0004 (0.0005)  current_batch_size: 32.0000 (32.0000)  total_loss: 13.8399 (13.8451)  dino_local_crops_loss: 9.8582 (9.8550)  dino_global_crops_loss: 1.2323 (1.2320)  koleo_loss: -0.0194 (-0.0007)  ibot_loss: 2.7678 (2.7589)  time: 13.527270  data: 0.549884  max mem: 20013
I20240512 17:19:13 1283354 dinov2 config.py:59] git:
  sha: e1277af2ba9496fbadf7aec6eba56e8d882d1e35, status: has uncommitted changes, branch: main

I20240512 17:19:13 1283354 dinov2 config.py:60] config_file: config_test2.yaml
eval: 
eval_only: False
no_resume: False
opts: ['train.output_dir=/home/guevel/OT4D/cell_similarity/src/cell_similarity/scripts']
output_dir: /home/guevel/OT4D/cell_similarity/src/cell_similarity/scripts
I20240512 17:19:13 1283354 dinov2 config.py:26] sqrt scaling learning rate; base: 0.004, new: 0.0007071067811865476
I20240512 17:19:13 1283354 dinov2 config.py:33] MODEL:
  WEIGHTS: ''
compute_precision:
  grad_scaler: true
  teacher:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
  student:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
dino:
  loss_weight: 1.0
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
  koleo_loss_weight: 0.1
ibot:
  loss_weight: 1.0
  mask_sample_probability: 0.5
  mask_ratio_min_max:
  - 0.1
  - 0.5
  separate_head: false
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
train:
  batch_size_per_gpu: 32
  dataset_path: /home/manon/classification/data/Single_cells/medhi
  output_dir: /home/guevel/OT4D/cell_similarity/src/cell_similarity/scripts
  saveckp_freq: 20
  seed: 0
  num_workers: 10
  OFFICIAL_EPOCH_LENGTH: 20
  cache_dataset: true
  centering: centering
student:
  arch: vit_large
  patch_size: 16
  drop_path_rate: 0.3
  layerscale: 1.0e-05
  drop_path_uniform: true
  pretrained_weights: ''
  ffn_layer: mlp
  block_chunks: 4
  qkv_bias: true
  proj_bias: true
  ffn_bias: true
  num_register_tokens: 0
  interpolate_antialias: false
  interpolate_offset: 0.1
teacher:
  momentum_teacher: 0.992
  final_momentum_teacher: 1
  warmup_teacher_temp: 0.04
  teacher_temp: 0.07
  warmup_teacher_temp_epochs: 30
optim:
  epochs: 100
  weight_decay: 0.04
  weight_decay_end: 0.4
  base_lr: 0.004
  lr: 0.0007071067811865476
  warmup_epochs: 10
  min_lr: 1.0e-06
  clip_grad: 3.0
  freeze_last_layer_epochs: 1
  scaling_rule: sqrt_wrt_1024
  patch_embed_lr_mult: 0.2
  layerwise_decay: 0.9
  adamw_beta1: 0.9
  adamw_beta2: 0.999
crops:
  global_crops_scale:
  - 0.32
  - 1.0
  local_crops_number: 8
  local_crops_scale:
  - 0.05
  - 0.32
  global_crops_size: 224
  local_crops_size: 96
evaluation:
  eval_period_iterations: 12500

I20240512 17:19:13 1283354 dinov2 vision_transformer.py:122] using MLP layer as FFN
I20240512 17:19:17 1283354 dinov2 vision_transformer.py:122] using MLP layer as FFN
I20240512 17:19:20 1283354 dinov2 ssl_meta_arch.py:43] OPTIONS -- architecture : embed_dim: 1024
I20240512 17:19:20 1283354 dinov2 ssl_meta_arch.py:58] OPTIONS -- DINO
I20240512 17:19:20 1283354 dinov2 ssl_meta_arch.py:60] OPTIONS -- DINO -- loss_weight: 1.0
I20240512 17:19:20 1283354 dinov2 ssl_meta_arch.py:61] OPTIONS -- DINO -- head_n_prototypes: 65536
I20240512 17:19:20 1283354 dinov2 ssl_meta_arch.py:62] OPTIONS -- DINO -- head_bottleneck_dim: 256
I20240512 17:19:20 1283354 dinov2 ssl_meta_arch.py:63] OPTIONS -- DINO -- head_hidden_dim: 2048
I20240512 17:19:20 1283354 dinov2 ssl_meta_arch.py:75] OPTIONS -- DINO -- applying KOLEO regularization
I20240512 17:19:20 1283354 dinov2 ssl_meta_arch.py:85] OPTIONS -- IBOT
I20240512 17:19:20 1283354 dinov2 ssl_meta_arch.py:86] OPTIONS -- IBOT -- loss_weight: 1.0
I20240512 17:19:20 1283354 dinov2 ssl_meta_arch.py:87] OPTIONS -- IBOT masking -- ibot_mask_ratio_tuple: [0.1, 0.5]
I20240512 17:19:20 1283354 dinov2 ssl_meta_arch.py:88] OPTIONS -- IBOT masking -- ibot_mask_sample_probability: 0.5
I20240512 17:19:20 1283354 dinov2 ssl_meta_arch.py:111] OPTIONS -- IBOT -- head shared with DINO
I20240512 17:19:20 1283354 dinov2 ssl_meta_arch.py:121] Student and Teacher are built: they are both vit_large network.
I20240512 17:19:21 1283354 dinov2 ssl_meta_arch.py:391] DISTRIBUTED FSDP -- preparing model for distributed training
W20240512 17:19:21 1283354 py.warnings warnings.py:109] /home/guevel/.conda/envs/dinov2/lib/python3.9/site-packages/torch/distributed/fsdp/_init_utils.py:295: UserWarning: FSDP is switching to use `NO_SHARD` instead of ShardingStrategy.SHARD_GRAD_OP since the world size is 1.
  warnings.warn(

I20240512 17:19:21 1283354 dinov2 memory_test2.py:17] Model:
SSLMetaArch(
  (dino_loss): DINOLoss()
  (koleo_loss): KoLeoLoss(
    (pdist): PairwiseDistance()
  )
  (ibot_patch_loss): iBOTPatchLoss()
  (student): ModuleDict(
    (backbone): FullyShardedDataParallel(
      (_fsdp_wrapped_module): DinoVisionTransformer(
        (patch_embed): PatchEmbed(
          (proj): Conv2d(3, 1024, kernel_size=(16, 16), stride=(16, 16))
          (norm): Identity()
        )
        (blocks): ModuleList(
          (0): FullyShardedDataParallel(
            (_fsdp_wrapped_module): BlockChunk(
              (0-5): 6 x NestedTensorBlock(
                (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
                (attn): MemEffAttention(
                  (qkv): Linear(in_features=1024, out_features=3072, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=1024, out_features=1024, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                )
                (ls1): LayerScale()
                (drop_path1): DropPath()
                (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=1024, out_features=4096, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=4096, out_features=1024, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
                (ls2): LayerScale()
                (drop_path2): DropPath()
              )
            )
          )
          (1): FullyShardedDataParallel(
            (_fsdp_wrapped_module): BlockChunk(
              (0-5): 6 x Identity()
              (6-11): 6 x NestedTensorBlock(
                (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
                (attn): MemEffAttention(
                  (qkv): Linear(in_features=1024, out_features=3072, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=1024, out_features=1024, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                )
                (ls1): LayerScale()
                (drop_path1): DropPath()
                (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=1024, out_features=4096, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=4096, out_features=1024, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
                (ls2): LayerScale()
                (drop_path2): DropPath()
              )
            )
          )
          (2): FullyShardedDataParallel(
            (_fsdp_wrapped_module): BlockChunk(
              (0-11): 12 x Identity()
              (12-17): 6 x NestedTensorBlock(
                (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
                (attn): MemEffAttention(
                  (qkv): Linear(in_features=1024, out_features=3072, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=1024, out_features=1024, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                )
                (ls1): LayerScale()
                (drop_path1): DropPath()
                (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=1024, out_features=4096, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=4096, out_features=1024, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
                (ls2): LayerScale()
                (drop_path2): DropPath()
              )
            )
          )
          (3): FullyShardedDataParallel(
            (_fsdp_wrapped_module): BlockChunk(
              (0-17): 18 x Identity()
              (18-23): 6 x NestedTensorBlock(
                (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
                (attn): MemEffAttention(
                  (qkv): Linear(in_features=1024, out_features=3072, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=1024, out_features=1024, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                )
                (ls1): LayerScale()
                (drop_path1): DropPath()
                (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=1024, out_features=4096, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=4096, out_features=1024, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
                (ls2): LayerScale()
                (drop_path2): DropPath()
              )
            )
          )
        )
        (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (head): Identity()
      )
    )
    (dino_head): FullyShardedDataParallel(
      (_fsdp_wrapped_module): DINOHead(
        (mlp): Sequential(
          (0): Linear(in_features=1024, out_features=2048, bias=True)
          (1): GELU(approximate='none')
          (2): Linear(in_features=2048, out_features=2048, bias=True)
          (3): GELU(approximate='none')
          (4): Linear(in_features=2048, out_features=256, bias=True)
        )
        (last_layer): Linear(in_features=256, out_features=65536, bias=False)
      )
    )
  )
  (teacher): ModuleDict(
    (backbone): FullyShardedDataParallel(
      (_fsdp_wrapped_module): DinoVisionTransformer(
        (patch_embed): PatchEmbed(
          (proj): Conv2d(3, 1024, kernel_size=(16, 16), stride=(16, 16))
          (norm): Identity()
        )
        (blocks): ModuleList(
          (0): FullyShardedDataParallel(
            (_fsdp_wrapped_module): BlockChunk(
              (0-5): 6 x NestedTensorBlock(
                (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
                (attn): MemEffAttention(
                  (qkv): Linear(in_features=1024, out_features=3072, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=1024, out_features=1024, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                )
                (ls1): LayerScale()
                (drop_path1): Identity()
                (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=1024, out_features=4096, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=4096, out_features=1024, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
                (ls2): LayerScale()
                (drop_path2): Identity()
              )
            )
          )
          (1): FullyShardedDataParallel(
            (_fsdp_wrapped_module): BlockChunk(
              (0-5): 6 x Identity()
              (6-11): 6 x NestedTensorBlock(
                (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
                (attn): MemEffAttention(
                  (qkv): Linear(in_features=1024, out_features=3072, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=1024, out_features=1024, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                )
                (ls1): LayerScale()
                (drop_path1): Identity()
                (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=1024, out_features=4096, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=4096, out_features=1024, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
                (ls2): LayerScale()
                (drop_path2): Identity()
              )
            )
          )
          (2): FullyShardedDataParallel(
            (_fsdp_wrapped_module): BlockChunk(
              (0-11): 12 x Identity()
              (12-17): 6 x NestedTensorBlock(
                (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
                (attn): MemEffAttention(
                  (qkv): Linear(in_features=1024, out_features=3072, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=1024, out_features=1024, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                )
                (ls1): LayerScale()
                (drop_path1): Identity()
                (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=1024, out_features=4096, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=4096, out_features=1024, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
                (ls2): LayerScale()
                (drop_path2): Identity()
              )
            )
          )
          (3): FullyShardedDataParallel(
            (_fsdp_wrapped_module): BlockChunk(
              (0-17): 18 x Identity()
              (18-23): 6 x NestedTensorBlock(
                (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
                (attn): MemEffAttention(
                  (qkv): Linear(in_features=1024, out_features=3072, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=1024, out_features=1024, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                )
                (ls1): LayerScale()
                (drop_path1): Identity()
                (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=1024, out_features=4096, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=4096, out_features=1024, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
                (ls2): LayerScale()
                (drop_path2): Identity()
              )
            )
          )
        )
        (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (head): Identity()
      )
    )
    (dino_head): FullyShardedDataParallel(
      (_fsdp_wrapped_module): DINOHead(
        (mlp): Sequential(
          (0): Linear(in_features=1024, out_features=2048, bias=True)
          (1): GELU(approximate='none')
          (2): Linear(in_features=2048, out_features=2048, bias=True)
          (3): GELU(approximate='none')
          (4): Linear(in_features=2048, out_features=256, bias=True)
        )
        (last_layer): Linear(in_features=256, out_features=65536, bias=False)
      )
    )
  )
)
I20240512 17:19:21 1283354 dinov2 param_groups.py:54] chunked fsdp
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] cls_token: lr_multiplier: 0.0717897987691853, wd_multiplier: 1.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] pos_embed: lr_multiplier: 0.0717897987691853, wd_multiplier: 1.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] mask_token: lr_multiplier: 0.0717897987691853, wd_multiplier: 1.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] patch_embed.proj.weight: lr_multiplier: 0.01435795975383706, wd_multiplier: 1.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] patch_embed.proj.bias: lr_multiplier: 0.01435795975383706, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.0.0.norm1.weight: lr_multiplier: 0.07976644307687256, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.0.0.norm1.bias: lr_multiplier: 0.07976644307687256, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.0.0.attn.qkv.weight: lr_multiplier: 0.07976644307687256, wd_multiplier: 1.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.0.0.attn.qkv.bias: lr_multiplier: 0.07976644307687256, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.0.0.attn.proj.weight: lr_multiplier: 0.07976644307687256, wd_multiplier: 1.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.0.0.attn.proj.bias: lr_multiplier: 0.07976644307687256, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.0.0.ls1.gamma: lr_multiplier: 0.07976644307687256, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.0.0.norm2.weight: lr_multiplier: 0.07976644307687256, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.0.0.norm2.bias: lr_multiplier: 0.07976644307687256, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.0.0.mlp.fc1.weight: lr_multiplier: 0.07976644307687256, wd_multiplier: 1.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.0.0.mlp.fc1.bias: lr_multiplier: 0.07976644307687256, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.0.0.mlp.fc2.weight: lr_multiplier: 0.07976644307687256, wd_multiplier: 1.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.0.0.mlp.fc2.bias: lr_multiplier: 0.07976644307687256, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.0.0.ls2.gamma: lr_multiplier: 0.07976644307687256, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.0.1.norm1.weight: lr_multiplier: 0.08862938119652507, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.0.1.norm1.bias: lr_multiplier: 0.08862938119652507, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.0.1.attn.qkv.weight: lr_multiplier: 0.08862938119652507, wd_multiplier: 1.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.0.1.attn.qkv.bias: lr_multiplier: 0.08862938119652507, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.0.1.attn.proj.weight: lr_multiplier: 0.08862938119652507, wd_multiplier: 1.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.0.1.attn.proj.bias: lr_multiplier: 0.08862938119652507, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.0.1.ls1.gamma: lr_multiplier: 0.08862938119652507, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.0.1.norm2.weight: lr_multiplier: 0.08862938119652507, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.0.1.norm2.bias: lr_multiplier: 0.08862938119652507, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.0.1.mlp.fc1.weight: lr_multiplier: 0.08862938119652507, wd_multiplier: 1.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.0.1.mlp.fc1.bias: lr_multiplier: 0.08862938119652507, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.0.1.mlp.fc2.weight: lr_multiplier: 0.08862938119652507, wd_multiplier: 1.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.0.1.mlp.fc2.bias: lr_multiplier: 0.08862938119652507, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.0.1.ls2.gamma: lr_multiplier: 0.08862938119652507, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.0.2.norm1.weight: lr_multiplier: 0.09847709021836118, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.0.2.norm1.bias: lr_multiplier: 0.09847709021836118, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.0.2.attn.qkv.weight: lr_multiplier: 0.09847709021836118, wd_multiplier: 1.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.0.2.attn.qkv.bias: lr_multiplier: 0.09847709021836118, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.0.2.attn.proj.weight: lr_multiplier: 0.09847709021836118, wd_multiplier: 1.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.0.2.attn.proj.bias: lr_multiplier: 0.09847709021836118, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.0.2.ls1.gamma: lr_multiplier: 0.09847709021836118, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.0.2.norm2.weight: lr_multiplier: 0.09847709021836118, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.0.2.norm2.bias: lr_multiplier: 0.09847709021836118, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.0.2.mlp.fc1.weight: lr_multiplier: 0.09847709021836118, wd_multiplier: 1.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.0.2.mlp.fc1.bias: lr_multiplier: 0.09847709021836118, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.0.2.mlp.fc2.weight: lr_multiplier: 0.09847709021836118, wd_multiplier: 1.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.0.2.mlp.fc2.bias: lr_multiplier: 0.09847709021836118, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.0.2.ls2.gamma: lr_multiplier: 0.09847709021836118, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.0.3.norm1.weight: lr_multiplier: 0.10941898913151242, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.0.3.norm1.bias: lr_multiplier: 0.10941898913151242, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.0.3.attn.qkv.weight: lr_multiplier: 0.10941898913151242, wd_multiplier: 1.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.0.3.attn.qkv.bias: lr_multiplier: 0.10941898913151242, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.0.3.attn.proj.weight: lr_multiplier: 0.10941898913151242, wd_multiplier: 1.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.0.3.attn.proj.bias: lr_multiplier: 0.10941898913151242, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.0.3.ls1.gamma: lr_multiplier: 0.10941898913151242, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.0.3.norm2.weight: lr_multiplier: 0.10941898913151242, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.0.3.norm2.bias: lr_multiplier: 0.10941898913151242, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.0.3.mlp.fc1.weight: lr_multiplier: 0.10941898913151242, wd_multiplier: 1.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.0.3.mlp.fc1.bias: lr_multiplier: 0.10941898913151242, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.0.3.mlp.fc2.weight: lr_multiplier: 0.10941898913151242, wd_multiplier: 1.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.0.3.mlp.fc2.bias: lr_multiplier: 0.10941898913151242, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.0.3.ls2.gamma: lr_multiplier: 0.10941898913151242, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.0.4.norm1.weight: lr_multiplier: 0.12157665459056935, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.0.4.norm1.bias: lr_multiplier: 0.12157665459056935, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.0.4.attn.qkv.weight: lr_multiplier: 0.12157665459056935, wd_multiplier: 1.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.0.4.attn.qkv.bias: lr_multiplier: 0.12157665459056935, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.0.4.attn.proj.weight: lr_multiplier: 0.12157665459056935, wd_multiplier: 1.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.0.4.attn.proj.bias: lr_multiplier: 0.12157665459056935, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.0.4.ls1.gamma: lr_multiplier: 0.12157665459056935, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.0.4.norm2.weight: lr_multiplier: 0.12157665459056935, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.0.4.norm2.bias: lr_multiplier: 0.12157665459056935, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.0.4.mlp.fc1.weight: lr_multiplier: 0.12157665459056935, wd_multiplier: 1.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.0.4.mlp.fc1.bias: lr_multiplier: 0.12157665459056935, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.0.4.mlp.fc2.weight: lr_multiplier: 0.12157665459056935, wd_multiplier: 1.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.0.4.mlp.fc2.bias: lr_multiplier: 0.12157665459056935, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.0.4.ls2.gamma: lr_multiplier: 0.12157665459056935, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.0.5.norm1.weight: lr_multiplier: 0.13508517176729928, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.0.5.norm1.bias: lr_multiplier: 0.13508517176729928, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.0.5.attn.qkv.weight: lr_multiplier: 0.13508517176729928, wd_multiplier: 1.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.0.5.attn.qkv.bias: lr_multiplier: 0.13508517176729928, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.0.5.attn.proj.weight: lr_multiplier: 0.13508517176729928, wd_multiplier: 1.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.0.5.attn.proj.bias: lr_multiplier: 0.13508517176729928, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.0.5.ls1.gamma: lr_multiplier: 0.13508517176729928, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.0.5.norm2.weight: lr_multiplier: 0.13508517176729928, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.0.5.norm2.bias: lr_multiplier: 0.13508517176729928, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.0.5.mlp.fc1.weight: lr_multiplier: 0.13508517176729928, wd_multiplier: 1.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.0.5.mlp.fc1.bias: lr_multiplier: 0.13508517176729928, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.0.5.mlp.fc2.weight: lr_multiplier: 0.13508517176729928, wd_multiplier: 1.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.0.5.mlp.fc2.bias: lr_multiplier: 0.13508517176729928, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.0.5.ls2.gamma: lr_multiplier: 0.13508517176729928, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.1.6.norm1.weight: lr_multiplier: 0.15009463529699918, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.1.6.norm1.bias: lr_multiplier: 0.15009463529699918, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.1.6.attn.qkv.weight: lr_multiplier: 0.15009463529699918, wd_multiplier: 1.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.1.6.attn.qkv.bias: lr_multiplier: 0.15009463529699918, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.1.6.attn.proj.weight: lr_multiplier: 0.15009463529699918, wd_multiplier: 1.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.1.6.attn.proj.bias: lr_multiplier: 0.15009463529699918, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.1.6.ls1.gamma: lr_multiplier: 0.15009463529699918, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.1.6.norm2.weight: lr_multiplier: 0.15009463529699918, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.1.6.norm2.bias: lr_multiplier: 0.15009463529699918, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.1.6.mlp.fc1.weight: lr_multiplier: 0.15009463529699918, wd_multiplier: 1.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.1.6.mlp.fc1.bias: lr_multiplier: 0.15009463529699918, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.1.6.mlp.fc2.weight: lr_multiplier: 0.15009463529699918, wd_multiplier: 1.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.1.6.mlp.fc2.bias: lr_multiplier: 0.15009463529699918, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.1.6.ls2.gamma: lr_multiplier: 0.15009463529699918, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.1.7.norm1.weight: lr_multiplier: 0.16677181699666577, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.1.7.norm1.bias: lr_multiplier: 0.16677181699666577, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.1.7.attn.qkv.weight: lr_multiplier: 0.16677181699666577, wd_multiplier: 1.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.1.7.attn.qkv.bias: lr_multiplier: 0.16677181699666577, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.1.7.attn.proj.weight: lr_multiplier: 0.16677181699666577, wd_multiplier: 1.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.1.7.attn.proj.bias: lr_multiplier: 0.16677181699666577, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.1.7.ls1.gamma: lr_multiplier: 0.16677181699666577, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.1.7.norm2.weight: lr_multiplier: 0.16677181699666577, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.1.7.norm2.bias: lr_multiplier: 0.16677181699666577, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.1.7.mlp.fc1.weight: lr_multiplier: 0.16677181699666577, wd_multiplier: 1.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.1.7.mlp.fc1.bias: lr_multiplier: 0.16677181699666577, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.1.7.mlp.fc2.weight: lr_multiplier: 0.16677181699666577, wd_multiplier: 1.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.1.7.mlp.fc2.bias: lr_multiplier: 0.16677181699666577, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.1.7.ls2.gamma: lr_multiplier: 0.16677181699666577, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.1.8.norm1.weight: lr_multiplier: 0.18530201888518416, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.1.8.norm1.bias: lr_multiplier: 0.18530201888518416, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.1.8.attn.qkv.weight: lr_multiplier: 0.18530201888518416, wd_multiplier: 1.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.1.8.attn.qkv.bias: lr_multiplier: 0.18530201888518416, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.1.8.attn.proj.weight: lr_multiplier: 0.18530201888518416, wd_multiplier: 1.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.1.8.attn.proj.bias: lr_multiplier: 0.18530201888518416, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.1.8.ls1.gamma: lr_multiplier: 0.18530201888518416, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.1.8.norm2.weight: lr_multiplier: 0.18530201888518416, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.1.8.norm2.bias: lr_multiplier: 0.18530201888518416, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.1.8.mlp.fc1.weight: lr_multiplier: 0.18530201888518416, wd_multiplier: 1.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.1.8.mlp.fc1.bias: lr_multiplier: 0.18530201888518416, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.1.8.mlp.fc2.weight: lr_multiplier: 0.18530201888518416, wd_multiplier: 1.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.1.8.mlp.fc2.bias: lr_multiplier: 0.18530201888518416, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.1.8.ls2.gamma: lr_multiplier: 0.18530201888518416, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.1.9.norm1.weight: lr_multiplier: 0.20589113209464907, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.1.9.norm1.bias: lr_multiplier: 0.20589113209464907, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.1.9.attn.qkv.weight: lr_multiplier: 0.20589113209464907, wd_multiplier: 1.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.1.9.attn.qkv.bias: lr_multiplier: 0.20589113209464907, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.1.9.attn.proj.weight: lr_multiplier: 0.20589113209464907, wd_multiplier: 1.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.1.9.attn.proj.bias: lr_multiplier: 0.20589113209464907, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.1.9.ls1.gamma: lr_multiplier: 0.20589113209464907, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.1.9.norm2.weight: lr_multiplier: 0.20589113209464907, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.1.9.norm2.bias: lr_multiplier: 0.20589113209464907, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.1.9.mlp.fc1.weight: lr_multiplier: 0.20589113209464907, wd_multiplier: 1.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.1.9.mlp.fc1.bias: lr_multiplier: 0.20589113209464907, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.1.9.mlp.fc2.weight: lr_multiplier: 0.20589113209464907, wd_multiplier: 1.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.1.9.mlp.fc2.bias: lr_multiplier: 0.20589113209464907, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.1.9.ls2.gamma: lr_multiplier: 0.20589113209464907, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.1.10.norm1.weight: lr_multiplier: 0.2287679245496101, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.1.10.norm1.bias: lr_multiplier: 0.2287679245496101, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.1.10.attn.qkv.weight: lr_multiplier: 0.2287679245496101, wd_multiplier: 1.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.1.10.attn.qkv.bias: lr_multiplier: 0.2287679245496101, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.1.10.attn.proj.weight: lr_multiplier: 0.2287679245496101, wd_multiplier: 1.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.1.10.attn.proj.bias: lr_multiplier: 0.2287679245496101, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.1.10.ls1.gamma: lr_multiplier: 0.2287679245496101, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.1.10.norm2.weight: lr_multiplier: 0.2287679245496101, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.1.10.norm2.bias: lr_multiplier: 0.2287679245496101, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.1.10.mlp.fc1.weight: lr_multiplier: 0.2287679245496101, wd_multiplier: 1.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.1.10.mlp.fc1.bias: lr_multiplier: 0.2287679245496101, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.1.10.mlp.fc2.weight: lr_multiplier: 0.2287679245496101, wd_multiplier: 1.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.1.10.mlp.fc2.bias: lr_multiplier: 0.2287679245496101, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.1.10.ls2.gamma: lr_multiplier: 0.2287679245496101, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.1.11.norm1.weight: lr_multiplier: 0.2541865828329001, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.1.11.norm1.bias: lr_multiplier: 0.2541865828329001, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.1.11.attn.qkv.weight: lr_multiplier: 0.2541865828329001, wd_multiplier: 1.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.1.11.attn.qkv.bias: lr_multiplier: 0.2541865828329001, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.1.11.attn.proj.weight: lr_multiplier: 0.2541865828329001, wd_multiplier: 1.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.1.11.attn.proj.bias: lr_multiplier: 0.2541865828329001, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.1.11.ls1.gamma: lr_multiplier: 0.2541865828329001, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.1.11.norm2.weight: lr_multiplier: 0.2541865828329001, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.1.11.norm2.bias: lr_multiplier: 0.2541865828329001, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.1.11.mlp.fc1.weight: lr_multiplier: 0.2541865828329001, wd_multiplier: 1.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.1.11.mlp.fc1.bias: lr_multiplier: 0.2541865828329001, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.1.11.mlp.fc2.weight: lr_multiplier: 0.2541865828329001, wd_multiplier: 1.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.1.11.mlp.fc2.bias: lr_multiplier: 0.2541865828329001, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.1.11.ls2.gamma: lr_multiplier: 0.2541865828329001, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.2.12.norm1.weight: lr_multiplier: 0.2824295364810001, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.2.12.norm1.bias: lr_multiplier: 0.2824295364810001, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.2.12.attn.qkv.weight: lr_multiplier: 0.2824295364810001, wd_multiplier: 1.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.2.12.attn.qkv.bias: lr_multiplier: 0.2824295364810001, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.2.12.attn.proj.weight: lr_multiplier: 0.2824295364810001, wd_multiplier: 1.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.2.12.attn.proj.bias: lr_multiplier: 0.2824295364810001, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.2.12.ls1.gamma: lr_multiplier: 0.2824295364810001, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.2.12.norm2.weight: lr_multiplier: 0.2824295364810001, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.2.12.norm2.bias: lr_multiplier: 0.2824295364810001, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.2.12.mlp.fc1.weight: lr_multiplier: 0.2824295364810001, wd_multiplier: 1.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.2.12.mlp.fc1.bias: lr_multiplier: 0.2824295364810001, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.2.12.mlp.fc2.weight: lr_multiplier: 0.2824295364810001, wd_multiplier: 1.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.2.12.mlp.fc2.bias: lr_multiplier: 0.2824295364810001, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.2.12.ls2.gamma: lr_multiplier: 0.2824295364810001, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.2.13.norm1.weight: lr_multiplier: 0.31381059609000006, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.2.13.norm1.bias: lr_multiplier: 0.31381059609000006, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.2.13.attn.qkv.weight: lr_multiplier: 0.31381059609000006, wd_multiplier: 1.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.2.13.attn.qkv.bias: lr_multiplier: 0.31381059609000006, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.2.13.attn.proj.weight: lr_multiplier: 0.31381059609000006, wd_multiplier: 1.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.2.13.attn.proj.bias: lr_multiplier: 0.31381059609000006, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.2.13.ls1.gamma: lr_multiplier: 0.31381059609000006, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.2.13.norm2.weight: lr_multiplier: 0.31381059609000006, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.2.13.norm2.bias: lr_multiplier: 0.31381059609000006, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.2.13.mlp.fc1.weight: lr_multiplier: 0.31381059609000006, wd_multiplier: 1.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.2.13.mlp.fc1.bias: lr_multiplier: 0.31381059609000006, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.2.13.mlp.fc2.weight: lr_multiplier: 0.31381059609000006, wd_multiplier: 1.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.2.13.mlp.fc2.bias: lr_multiplier: 0.31381059609000006, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.2.13.ls2.gamma: lr_multiplier: 0.31381059609000006, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.2.14.norm1.weight: lr_multiplier: 0.3486784401000001, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.2.14.norm1.bias: lr_multiplier: 0.3486784401000001, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.2.14.attn.qkv.weight: lr_multiplier: 0.3486784401000001, wd_multiplier: 1.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.2.14.attn.qkv.bias: lr_multiplier: 0.3486784401000001, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.2.14.attn.proj.weight: lr_multiplier: 0.3486784401000001, wd_multiplier: 1.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.2.14.attn.proj.bias: lr_multiplier: 0.3486784401000001, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.2.14.ls1.gamma: lr_multiplier: 0.3486784401000001, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.2.14.norm2.weight: lr_multiplier: 0.3486784401000001, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.2.14.norm2.bias: lr_multiplier: 0.3486784401000001, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.2.14.mlp.fc1.weight: lr_multiplier: 0.3486784401000001, wd_multiplier: 1.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.2.14.mlp.fc1.bias: lr_multiplier: 0.3486784401000001, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.2.14.mlp.fc2.weight: lr_multiplier: 0.3486784401000001, wd_multiplier: 1.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.2.14.mlp.fc2.bias: lr_multiplier: 0.3486784401000001, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.2.14.ls2.gamma: lr_multiplier: 0.3486784401000001, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.2.15.norm1.weight: lr_multiplier: 0.3874204890000001, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.2.15.norm1.bias: lr_multiplier: 0.3874204890000001, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.2.15.attn.qkv.weight: lr_multiplier: 0.3874204890000001, wd_multiplier: 1.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.2.15.attn.qkv.bias: lr_multiplier: 0.3874204890000001, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.2.15.attn.proj.weight: lr_multiplier: 0.3874204890000001, wd_multiplier: 1.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.2.15.attn.proj.bias: lr_multiplier: 0.3874204890000001, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.2.15.ls1.gamma: lr_multiplier: 0.3874204890000001, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.2.15.norm2.weight: lr_multiplier: 0.3874204890000001, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.2.15.norm2.bias: lr_multiplier: 0.3874204890000001, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.2.15.mlp.fc1.weight: lr_multiplier: 0.3874204890000001, wd_multiplier: 1.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.2.15.mlp.fc1.bias: lr_multiplier: 0.3874204890000001, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.2.15.mlp.fc2.weight: lr_multiplier: 0.3874204890000001, wd_multiplier: 1.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.2.15.mlp.fc2.bias: lr_multiplier: 0.3874204890000001, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.2.15.ls2.gamma: lr_multiplier: 0.3874204890000001, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.2.16.norm1.weight: lr_multiplier: 0.4304672100000001, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.2.16.norm1.bias: lr_multiplier: 0.4304672100000001, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.2.16.attn.qkv.weight: lr_multiplier: 0.4304672100000001, wd_multiplier: 1.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.2.16.attn.qkv.bias: lr_multiplier: 0.4304672100000001, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.2.16.attn.proj.weight: lr_multiplier: 0.4304672100000001, wd_multiplier: 1.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.2.16.attn.proj.bias: lr_multiplier: 0.4304672100000001, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.2.16.ls1.gamma: lr_multiplier: 0.4304672100000001, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.2.16.norm2.weight: lr_multiplier: 0.4304672100000001, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.2.16.norm2.bias: lr_multiplier: 0.4304672100000001, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.2.16.mlp.fc1.weight: lr_multiplier: 0.4304672100000001, wd_multiplier: 1.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.2.16.mlp.fc1.bias: lr_multiplier: 0.4304672100000001, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.2.16.mlp.fc2.weight: lr_multiplier: 0.4304672100000001, wd_multiplier: 1.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.2.16.mlp.fc2.bias: lr_multiplier: 0.4304672100000001, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.2.16.ls2.gamma: lr_multiplier: 0.4304672100000001, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.2.17.norm1.weight: lr_multiplier: 0.4782969000000001, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.2.17.norm1.bias: lr_multiplier: 0.4782969000000001, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.2.17.attn.qkv.weight: lr_multiplier: 0.4782969000000001, wd_multiplier: 1.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.2.17.attn.qkv.bias: lr_multiplier: 0.4782969000000001, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.2.17.attn.proj.weight: lr_multiplier: 0.4782969000000001, wd_multiplier: 1.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.2.17.attn.proj.bias: lr_multiplier: 0.4782969000000001, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.2.17.ls1.gamma: lr_multiplier: 0.4782969000000001, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.2.17.norm2.weight: lr_multiplier: 0.4782969000000001, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.2.17.norm2.bias: lr_multiplier: 0.4782969000000001, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.2.17.mlp.fc1.weight: lr_multiplier: 0.4782969000000001, wd_multiplier: 1.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.2.17.mlp.fc1.bias: lr_multiplier: 0.4782969000000001, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.2.17.mlp.fc2.weight: lr_multiplier: 0.4782969000000001, wd_multiplier: 1.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.2.17.mlp.fc2.bias: lr_multiplier: 0.4782969000000001, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.2.17.ls2.gamma: lr_multiplier: 0.4782969000000001, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.3.18.norm1.weight: lr_multiplier: 0.531441, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.3.18.norm1.bias: lr_multiplier: 0.531441, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.3.18.attn.qkv.weight: lr_multiplier: 0.531441, wd_multiplier: 1.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.3.18.attn.qkv.bias: lr_multiplier: 0.531441, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.3.18.attn.proj.weight: lr_multiplier: 0.531441, wd_multiplier: 1.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.3.18.attn.proj.bias: lr_multiplier: 0.531441, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.3.18.ls1.gamma: lr_multiplier: 0.531441, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.3.18.norm2.weight: lr_multiplier: 0.531441, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.3.18.norm2.bias: lr_multiplier: 0.531441, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.3.18.mlp.fc1.weight: lr_multiplier: 0.531441, wd_multiplier: 1.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.3.18.mlp.fc1.bias: lr_multiplier: 0.531441, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.3.18.mlp.fc2.weight: lr_multiplier: 0.531441, wd_multiplier: 1.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.3.18.mlp.fc2.bias: lr_multiplier: 0.531441, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.3.18.ls2.gamma: lr_multiplier: 0.531441, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.3.19.norm1.weight: lr_multiplier: 0.5904900000000001, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.3.19.norm1.bias: lr_multiplier: 0.5904900000000001, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.3.19.attn.qkv.weight: lr_multiplier: 0.5904900000000001, wd_multiplier: 1.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.3.19.attn.qkv.bias: lr_multiplier: 0.5904900000000001, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.3.19.attn.proj.weight: lr_multiplier: 0.5904900000000001, wd_multiplier: 1.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.3.19.attn.proj.bias: lr_multiplier: 0.5904900000000001, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.3.19.ls1.gamma: lr_multiplier: 0.5904900000000001, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.3.19.norm2.weight: lr_multiplier: 0.5904900000000001, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.3.19.norm2.bias: lr_multiplier: 0.5904900000000001, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.3.19.mlp.fc1.weight: lr_multiplier: 0.5904900000000001, wd_multiplier: 1.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.3.19.mlp.fc1.bias: lr_multiplier: 0.5904900000000001, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.3.19.mlp.fc2.weight: lr_multiplier: 0.5904900000000001, wd_multiplier: 1.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.3.19.mlp.fc2.bias: lr_multiplier: 0.5904900000000001, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.3.19.ls2.gamma: lr_multiplier: 0.5904900000000001, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.3.20.norm1.weight: lr_multiplier: 0.6561, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.3.20.norm1.bias: lr_multiplier: 0.6561, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.3.20.attn.qkv.weight: lr_multiplier: 0.6561, wd_multiplier: 1.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.3.20.attn.qkv.bias: lr_multiplier: 0.6561, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.3.20.attn.proj.weight: lr_multiplier: 0.6561, wd_multiplier: 1.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.3.20.attn.proj.bias: lr_multiplier: 0.6561, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.3.20.ls1.gamma: lr_multiplier: 0.6561, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.3.20.norm2.weight: lr_multiplier: 0.6561, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.3.20.norm2.bias: lr_multiplier: 0.6561, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.3.20.mlp.fc1.weight: lr_multiplier: 0.6561, wd_multiplier: 1.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.3.20.mlp.fc1.bias: lr_multiplier: 0.6561, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.3.20.mlp.fc2.weight: lr_multiplier: 0.6561, wd_multiplier: 1.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.3.20.mlp.fc2.bias: lr_multiplier: 0.6561, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.3.20.ls2.gamma: lr_multiplier: 0.6561, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.3.21.norm1.weight: lr_multiplier: 0.7290000000000001, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.3.21.norm1.bias: lr_multiplier: 0.7290000000000001, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.3.21.attn.qkv.weight: lr_multiplier: 0.7290000000000001, wd_multiplier: 1.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.3.21.attn.qkv.bias: lr_multiplier: 0.7290000000000001, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.3.21.attn.proj.weight: lr_multiplier: 0.7290000000000001, wd_multiplier: 1.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.3.21.attn.proj.bias: lr_multiplier: 0.7290000000000001, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.3.21.ls1.gamma: lr_multiplier: 0.7290000000000001, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.3.21.norm2.weight: lr_multiplier: 0.7290000000000001, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.3.21.norm2.bias: lr_multiplier: 0.7290000000000001, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.3.21.mlp.fc1.weight: lr_multiplier: 0.7290000000000001, wd_multiplier: 1.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.3.21.mlp.fc1.bias: lr_multiplier: 0.7290000000000001, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.3.21.mlp.fc2.weight: lr_multiplier: 0.7290000000000001, wd_multiplier: 1.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.3.21.mlp.fc2.bias: lr_multiplier: 0.7290000000000001, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.3.21.ls2.gamma: lr_multiplier: 0.7290000000000001, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.3.22.norm1.weight: lr_multiplier: 0.81, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.3.22.norm1.bias: lr_multiplier: 0.81, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.3.22.attn.qkv.weight: lr_multiplier: 0.81, wd_multiplier: 1.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.3.22.attn.qkv.bias: lr_multiplier: 0.81, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.3.22.attn.proj.weight: lr_multiplier: 0.81, wd_multiplier: 1.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.3.22.attn.proj.bias: lr_multiplier: 0.81, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.3.22.ls1.gamma: lr_multiplier: 0.81, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.3.22.norm2.weight: lr_multiplier: 0.81, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.3.22.norm2.bias: lr_multiplier: 0.81, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.3.22.mlp.fc1.weight: lr_multiplier: 0.81, wd_multiplier: 1.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.3.22.mlp.fc1.bias: lr_multiplier: 0.81, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.3.22.mlp.fc2.weight: lr_multiplier: 0.81, wd_multiplier: 1.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.3.22.mlp.fc2.bias: lr_multiplier: 0.81, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.3.22.ls2.gamma: lr_multiplier: 0.81, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.3.23.norm1.weight: lr_multiplier: 0.9, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.3.23.norm1.bias: lr_multiplier: 0.9, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.3.23.attn.qkv.weight: lr_multiplier: 0.9, wd_multiplier: 1.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.3.23.attn.qkv.bias: lr_multiplier: 0.9, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.3.23.attn.proj.weight: lr_multiplier: 0.9, wd_multiplier: 1.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.3.23.attn.proj.bias: lr_multiplier: 0.9, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.3.23.ls1.gamma: lr_multiplier: 0.9, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.3.23.norm2.weight: lr_multiplier: 0.9, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.3.23.norm2.bias: lr_multiplier: 0.9, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.3.23.mlp.fc1.weight: lr_multiplier: 0.9, wd_multiplier: 1.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.3.23.mlp.fc1.bias: lr_multiplier: 0.9, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.3.23.mlp.fc2.weight: lr_multiplier: 0.9, wd_multiplier: 1.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.3.23.mlp.fc2.bias: lr_multiplier: 0.9, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] blocks.3.23.ls2.gamma: lr_multiplier: 0.9, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] norm.weight: lr_multiplier: 1.0, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] norm.bias: lr_multiplier: 1.0, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 ssl_meta_arch.py:378] fusing param groups
I20240512 17:19:21 1283354 dinov2 param_groups.py:64] else code branch
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] mlp.0.weight: lr_multiplier: 1.0, wd_multiplier: 1.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] mlp.0.bias: lr_multiplier: 1.0, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] mlp.2.weight: lr_multiplier: 1.0, wd_multiplier: 1.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] mlp.2.bias: lr_multiplier: 1.0, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] mlp.4.weight: lr_multiplier: 1.0, wd_multiplier: 1.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] mlp.4.bias: lr_multiplier: 1.0, wd_multiplier: 0.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] last_layer.weight_g: lr_multiplier: 1.0, wd_multiplier: 1.0
I20240512 17:19:21 1283354 dinov2 param_groups.py:87] last_layer.weight_v: lr_multiplier: 1.0, wd_multiplier: 1.0
I20240512 17:19:21 1283354 dinov2 ssl_meta_arch.py:378] fusing param groups
I20240512 17:19:21 1283354 dinov2 train.py:102] Schedulers ready.
I20240512 17:19:21 1283354 fvcore.common.checkpoint checkpoint.py:148] No checkpoint found. Initializing model from scratch
I20240512 17:19:21 1283354 dinov2 augmentations.py:34] ###################################
I20240512 17:19:21 1283354 dinov2 augmentations.py:35] Using data augmentation parameters:
I20240512 17:19:21 1283354 dinov2 augmentations.py:36] global_crops_scale: [0.32, 1.0]
I20240512 17:19:21 1283354 dinov2 augmentations.py:37] local_crops_scale: [0.05, 0.32]
I20240512 17:19:21 1283354 dinov2 augmentations.py:38] local_crops_number: 8
I20240512 17:19:21 1283354 dinov2 augmentations.py:39] global_crops_size: 224
I20240512 17:19:21 1283354 dinov2 augmentations.py:40] local_crops_size: 96
I20240512 17:19:21 1283354 dinov2 augmentations.py:41] ###################################
I20240512 17:22:17 1283805 dinov2 config.py:59] git:
  sha: e1277af2ba9496fbadf7aec6eba56e8d882d1e35, status: has uncommitted changes, branch: main

I20240512 17:22:17 1283805 dinov2 config.py:60] config_file: config_test2.yaml
eval: 
eval_only: False
no_resume: False
opts: ['train.output_dir=/home/guevel/OT4D/cell_similarity/src/cell_similarity/scripts']
output_dir: /home/guevel/OT4D/cell_similarity/src/cell_similarity/scripts
I20240512 17:22:17 1283805 dinov2 config.py:26] sqrt scaling learning rate; base: 0.004, new: 0.0007071067811865476
I20240512 17:22:17 1283805 dinov2 config.py:33] MODEL:
  WEIGHTS: ''
compute_precision:
  grad_scaler: true
  teacher:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
  student:
    backbone:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp16
        buffer_dtype: fp32
    dino_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
    ibot_head:
      sharding_strategy: SHARD_GRAD_OP
      mixed_precision:
        param_dtype: fp16
        reduce_dtype: fp32
        buffer_dtype: fp32
dino:
  loss_weight: 1.0
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
  koleo_loss_weight: 0.1
ibot:
  loss_weight: 1.0
  mask_sample_probability: 0.5
  mask_ratio_min_max:
  - 0.1
  - 0.5
  separate_head: false
  head_n_prototypes: 65536
  head_bottleneck_dim: 256
  head_nlayers: 3
  head_hidden_dim: 2048
train:
  batch_size_per_gpu: 32
  dataset_path: /home/manon/classification/data/Single_cells/medhi
  output_dir: /home/guevel/OT4D/cell_similarity/src/cell_similarity/scripts
  saveckp_freq: 20
  seed: 0
  num_workers: 10
  OFFICIAL_EPOCH_LENGTH: 20
  cache_dataset: true
  centering: centering
student:
  arch: vit_large
  patch_size: 16
  drop_path_rate: 0.3
  layerscale: 1.0e-05
  drop_path_uniform: true
  pretrained_weights: ''
  ffn_layer: mlp
  block_chunks: 4
  qkv_bias: true
  proj_bias: true
  ffn_bias: true
  num_register_tokens: 0
  interpolate_antialias: false
  interpolate_offset: 0.1
teacher:
  momentum_teacher: 0.992
  final_momentum_teacher: 1
  warmup_teacher_temp: 0.04
  teacher_temp: 0.07
  warmup_teacher_temp_epochs: 30
optim:
  epochs: 100
  weight_decay: 0.04
  weight_decay_end: 0.4
  base_lr: 0.004
  lr: 0.0007071067811865476
  warmup_epochs: 10
  min_lr: 1.0e-06
  clip_grad: 3.0
  freeze_last_layer_epochs: 1
  scaling_rule: sqrt_wrt_1024
  patch_embed_lr_mult: 0.2
  layerwise_decay: 0.9
  adamw_beta1: 0.9
  adamw_beta2: 0.999
crops:
  global_crops_scale:
  - 0.32
  - 1.0
  local_crops_number: 8
  local_crops_scale:
  - 0.05
  - 0.32
  global_crops_size: 224
  local_crops_size: 96
evaluation:
  eval_period_iterations: 12500

I20240512 17:22:17 1283805 dinov2 vision_transformer.py:122] using MLP layer as FFN
I20240512 17:22:21 1283805 dinov2 vision_transformer.py:122] using MLP layer as FFN
I20240512 17:22:24 1283805 dinov2 ssl_meta_arch.py:43] OPTIONS -- architecture : embed_dim: 1024
I20240512 17:22:24 1283805 dinov2 ssl_meta_arch.py:58] OPTIONS -- DINO
I20240512 17:22:24 1283805 dinov2 ssl_meta_arch.py:60] OPTIONS -- DINO -- loss_weight: 1.0
I20240512 17:22:24 1283805 dinov2 ssl_meta_arch.py:61] OPTIONS -- DINO -- head_n_prototypes: 65536
I20240512 17:22:24 1283805 dinov2 ssl_meta_arch.py:62] OPTIONS -- DINO -- head_bottleneck_dim: 256
I20240512 17:22:24 1283805 dinov2 ssl_meta_arch.py:63] OPTIONS -- DINO -- head_hidden_dim: 2048
I20240512 17:22:24 1283805 dinov2 ssl_meta_arch.py:75] OPTIONS -- DINO -- applying KOLEO regularization
I20240512 17:22:24 1283805 dinov2 ssl_meta_arch.py:85] OPTIONS -- IBOT
I20240512 17:22:24 1283805 dinov2 ssl_meta_arch.py:86] OPTIONS -- IBOT -- loss_weight: 1.0
I20240512 17:22:24 1283805 dinov2 ssl_meta_arch.py:87] OPTIONS -- IBOT masking -- ibot_mask_ratio_tuple: [0.1, 0.5]
I20240512 17:22:24 1283805 dinov2 ssl_meta_arch.py:88] OPTIONS -- IBOT masking -- ibot_mask_sample_probability: 0.5
I20240512 17:22:24 1283805 dinov2 ssl_meta_arch.py:111] OPTIONS -- IBOT -- head shared with DINO
I20240512 17:22:24 1283805 dinov2 ssl_meta_arch.py:121] Student and Teacher are built: they are both vit_large network.
I20240512 17:22:25 1283805 dinov2 ssl_meta_arch.py:391] DISTRIBUTED FSDP -- preparing model for distributed training
W20240512 17:22:25 1283805 py.warnings warnings.py:109] /home/guevel/.conda/envs/dinov2/lib/python3.9/site-packages/torch/distributed/fsdp/_init_utils.py:295: UserWarning: FSDP is switching to use `NO_SHARD` instead of ShardingStrategy.SHARD_GRAD_OP since the world size is 1.
  warnings.warn(

I20240512 17:22:25 1283805 dinov2 memory_test2.py:17] Model:
SSLMetaArch(
  (dino_loss): DINOLoss()
  (koleo_loss): KoLeoLoss(
    (pdist): PairwiseDistance()
  )
  (ibot_patch_loss): iBOTPatchLoss()
  (student): ModuleDict(
    (backbone): FullyShardedDataParallel(
      (_fsdp_wrapped_module): DinoVisionTransformer(
        (patch_embed): PatchEmbed(
          (proj): Conv2d(3, 1024, kernel_size=(16, 16), stride=(16, 16))
          (norm): Identity()
        )
        (blocks): ModuleList(
          (0): FullyShardedDataParallel(
            (_fsdp_wrapped_module): BlockChunk(
              (0-5): 6 x NestedTensorBlock(
                (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
                (attn): MemEffAttention(
                  (qkv): Linear(in_features=1024, out_features=3072, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=1024, out_features=1024, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                )
                (ls1): LayerScale()
                (drop_path1): DropPath()
                (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=1024, out_features=4096, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=4096, out_features=1024, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
                (ls2): LayerScale()
                (drop_path2): DropPath()
              )
            )
          )
          (1): FullyShardedDataParallel(
            (_fsdp_wrapped_module): BlockChunk(
              (0-5): 6 x Identity()
              (6-11): 6 x NestedTensorBlock(
                (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
                (attn): MemEffAttention(
                  (qkv): Linear(in_features=1024, out_features=3072, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=1024, out_features=1024, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                )
                (ls1): LayerScale()
                (drop_path1): DropPath()
                (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=1024, out_features=4096, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=4096, out_features=1024, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
                (ls2): LayerScale()
                (drop_path2): DropPath()
              )
            )
          )
          (2): FullyShardedDataParallel(
            (_fsdp_wrapped_module): BlockChunk(
              (0-11): 12 x Identity()
              (12-17): 6 x NestedTensorBlock(
                (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
                (attn): MemEffAttention(
                  (qkv): Linear(in_features=1024, out_features=3072, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=1024, out_features=1024, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                )
                (ls1): LayerScale()
                (drop_path1): DropPath()
                (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=1024, out_features=4096, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=4096, out_features=1024, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
                (ls2): LayerScale()
                (drop_path2): DropPath()
              )
            )
          )
          (3): FullyShardedDataParallel(
            (_fsdp_wrapped_module): BlockChunk(
              (0-17): 18 x Identity()
              (18-23): 6 x NestedTensorBlock(
                (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
                (attn): MemEffAttention(
                  (qkv): Linear(in_features=1024, out_features=3072, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=1024, out_features=1024, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                )
                (ls1): LayerScale()
                (drop_path1): DropPath()
                (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=1024, out_features=4096, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=4096, out_features=1024, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
                (ls2): LayerScale()
                (drop_path2): DropPath()
              )
            )
          )
        )
        (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (head): Identity()
      )
    )
    (dino_head): FullyShardedDataParallel(
      (_fsdp_wrapped_module): DINOHead(
        (mlp): Sequential(
          (0): Linear(in_features=1024, out_features=2048, bias=True)
          (1): GELU(approximate='none')
          (2): Linear(in_features=2048, out_features=2048, bias=True)
          (3): GELU(approximate='none')
          (4): Linear(in_features=2048, out_features=256, bias=True)
        )
        (last_layer): Linear(in_features=256, out_features=65536, bias=False)
      )
    )
  )
  (teacher): ModuleDict(
    (backbone): FullyShardedDataParallel(
      (_fsdp_wrapped_module): DinoVisionTransformer(
        (patch_embed): PatchEmbed(
          (proj): Conv2d(3, 1024, kernel_size=(16, 16), stride=(16, 16))
          (norm): Identity()
        )
        (blocks): ModuleList(
          (0): FullyShardedDataParallel(
            (_fsdp_wrapped_module): BlockChunk(
              (0-5): 6 x NestedTensorBlock(
                (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
                (attn): MemEffAttention(
                  (qkv): Linear(in_features=1024, out_features=3072, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=1024, out_features=1024, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                )
                (ls1): LayerScale()
                (drop_path1): Identity()
                (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=1024, out_features=4096, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=4096, out_features=1024, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
                (ls2): LayerScale()
                (drop_path2): Identity()
              )
            )
          )
          (1): FullyShardedDataParallel(
            (_fsdp_wrapped_module): BlockChunk(
              (0-5): 6 x Identity()
              (6-11): 6 x NestedTensorBlock(
                (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
                (attn): MemEffAttention(
                  (qkv): Linear(in_features=1024, out_features=3072, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=1024, out_features=1024, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                )
                (ls1): LayerScale()
                (drop_path1): Identity()
                (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=1024, out_features=4096, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=4096, out_features=1024, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
                (ls2): LayerScale()
                (drop_path2): Identity()
              )
            )
          )
          (2): FullyShardedDataParallel(
            (_fsdp_wrapped_module): BlockChunk(
              (0-11): 12 x Identity()
              (12-17): 6 x NestedTensorBlock(
                (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
                (attn): MemEffAttention(
                  (qkv): Linear(in_features=1024, out_features=3072, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=1024, out_features=1024, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                )
                (ls1): LayerScale()
                (drop_path1): Identity()
                (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=1024, out_features=4096, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=4096, out_features=1024, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
                (ls2): LayerScale()
                (drop_path2): Identity()
              )
            )
          )
          (3): FullyShardedDataParallel(
            (_fsdp_wrapped_module): BlockChunk(
              (0-17): 18 x Identity()
              (18-23): 6 x NestedTensorBlock(
                (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
                (attn): MemEffAttention(
                  (qkv): Linear(in_features=1024, out_features=3072, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=1024, out_features=1024, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                )
                (ls1): LayerScale()
                (drop_path1): Identity()
                (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=1024, out_features=4096, bias=True)
                  (act): GELU(approximate='none')
                  (fc2): Linear(in_features=4096, out_features=1024, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
                (ls2): LayerScale()
                (drop_path2): Identity()
              )
            )
          )
        )
        (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (head): Identity()
      )
    )
    (dino_head): FullyShardedDataParallel(
      (_fsdp_wrapped_module): DINOHead(
        (mlp): Sequential(
          (0): Linear(in_features=1024, out_features=2048, bias=True)
          (1): GELU(approximate='none')
          (2): Linear(in_features=2048, out_features=2048, bias=True)
          (3): GELU(approximate='none')
          (4): Linear(in_features=2048, out_features=256, bias=True)
        )
        (last_layer): Linear(in_features=256, out_features=65536, bias=False)
      )
    )
  )
)
I20240512 17:22:25 1283805 dinov2 param_groups.py:54] chunked fsdp
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] cls_token: lr_multiplier: 0.0717897987691853, wd_multiplier: 1.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] pos_embed: lr_multiplier: 0.0717897987691853, wd_multiplier: 1.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] mask_token: lr_multiplier: 0.0717897987691853, wd_multiplier: 1.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] patch_embed.proj.weight: lr_multiplier: 0.01435795975383706, wd_multiplier: 1.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] patch_embed.proj.bias: lr_multiplier: 0.01435795975383706, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.0.0.norm1.weight: lr_multiplier: 0.07976644307687256, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.0.0.norm1.bias: lr_multiplier: 0.07976644307687256, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.0.0.attn.qkv.weight: lr_multiplier: 0.07976644307687256, wd_multiplier: 1.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.0.0.attn.qkv.bias: lr_multiplier: 0.07976644307687256, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.0.0.attn.proj.weight: lr_multiplier: 0.07976644307687256, wd_multiplier: 1.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.0.0.attn.proj.bias: lr_multiplier: 0.07976644307687256, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.0.0.ls1.gamma: lr_multiplier: 0.07976644307687256, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.0.0.norm2.weight: lr_multiplier: 0.07976644307687256, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.0.0.norm2.bias: lr_multiplier: 0.07976644307687256, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.0.0.mlp.fc1.weight: lr_multiplier: 0.07976644307687256, wd_multiplier: 1.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.0.0.mlp.fc1.bias: lr_multiplier: 0.07976644307687256, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.0.0.mlp.fc2.weight: lr_multiplier: 0.07976644307687256, wd_multiplier: 1.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.0.0.mlp.fc2.bias: lr_multiplier: 0.07976644307687256, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.0.0.ls2.gamma: lr_multiplier: 0.07976644307687256, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.0.1.norm1.weight: lr_multiplier: 0.08862938119652507, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.0.1.norm1.bias: lr_multiplier: 0.08862938119652507, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.0.1.attn.qkv.weight: lr_multiplier: 0.08862938119652507, wd_multiplier: 1.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.0.1.attn.qkv.bias: lr_multiplier: 0.08862938119652507, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.0.1.attn.proj.weight: lr_multiplier: 0.08862938119652507, wd_multiplier: 1.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.0.1.attn.proj.bias: lr_multiplier: 0.08862938119652507, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.0.1.ls1.gamma: lr_multiplier: 0.08862938119652507, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.0.1.norm2.weight: lr_multiplier: 0.08862938119652507, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.0.1.norm2.bias: lr_multiplier: 0.08862938119652507, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.0.1.mlp.fc1.weight: lr_multiplier: 0.08862938119652507, wd_multiplier: 1.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.0.1.mlp.fc1.bias: lr_multiplier: 0.08862938119652507, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.0.1.mlp.fc2.weight: lr_multiplier: 0.08862938119652507, wd_multiplier: 1.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.0.1.mlp.fc2.bias: lr_multiplier: 0.08862938119652507, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.0.1.ls2.gamma: lr_multiplier: 0.08862938119652507, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.0.2.norm1.weight: lr_multiplier: 0.09847709021836118, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.0.2.norm1.bias: lr_multiplier: 0.09847709021836118, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.0.2.attn.qkv.weight: lr_multiplier: 0.09847709021836118, wd_multiplier: 1.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.0.2.attn.qkv.bias: lr_multiplier: 0.09847709021836118, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.0.2.attn.proj.weight: lr_multiplier: 0.09847709021836118, wd_multiplier: 1.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.0.2.attn.proj.bias: lr_multiplier: 0.09847709021836118, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.0.2.ls1.gamma: lr_multiplier: 0.09847709021836118, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.0.2.norm2.weight: lr_multiplier: 0.09847709021836118, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.0.2.norm2.bias: lr_multiplier: 0.09847709021836118, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.0.2.mlp.fc1.weight: lr_multiplier: 0.09847709021836118, wd_multiplier: 1.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.0.2.mlp.fc1.bias: lr_multiplier: 0.09847709021836118, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.0.2.mlp.fc2.weight: lr_multiplier: 0.09847709021836118, wd_multiplier: 1.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.0.2.mlp.fc2.bias: lr_multiplier: 0.09847709021836118, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.0.2.ls2.gamma: lr_multiplier: 0.09847709021836118, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.0.3.norm1.weight: lr_multiplier: 0.10941898913151242, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.0.3.norm1.bias: lr_multiplier: 0.10941898913151242, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.0.3.attn.qkv.weight: lr_multiplier: 0.10941898913151242, wd_multiplier: 1.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.0.3.attn.qkv.bias: lr_multiplier: 0.10941898913151242, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.0.3.attn.proj.weight: lr_multiplier: 0.10941898913151242, wd_multiplier: 1.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.0.3.attn.proj.bias: lr_multiplier: 0.10941898913151242, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.0.3.ls1.gamma: lr_multiplier: 0.10941898913151242, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.0.3.norm2.weight: lr_multiplier: 0.10941898913151242, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.0.3.norm2.bias: lr_multiplier: 0.10941898913151242, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.0.3.mlp.fc1.weight: lr_multiplier: 0.10941898913151242, wd_multiplier: 1.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.0.3.mlp.fc1.bias: lr_multiplier: 0.10941898913151242, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.0.3.mlp.fc2.weight: lr_multiplier: 0.10941898913151242, wd_multiplier: 1.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.0.3.mlp.fc2.bias: lr_multiplier: 0.10941898913151242, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.0.3.ls2.gamma: lr_multiplier: 0.10941898913151242, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.0.4.norm1.weight: lr_multiplier: 0.12157665459056935, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.0.4.norm1.bias: lr_multiplier: 0.12157665459056935, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.0.4.attn.qkv.weight: lr_multiplier: 0.12157665459056935, wd_multiplier: 1.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.0.4.attn.qkv.bias: lr_multiplier: 0.12157665459056935, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.0.4.attn.proj.weight: lr_multiplier: 0.12157665459056935, wd_multiplier: 1.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.0.4.attn.proj.bias: lr_multiplier: 0.12157665459056935, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.0.4.ls1.gamma: lr_multiplier: 0.12157665459056935, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.0.4.norm2.weight: lr_multiplier: 0.12157665459056935, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.0.4.norm2.bias: lr_multiplier: 0.12157665459056935, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.0.4.mlp.fc1.weight: lr_multiplier: 0.12157665459056935, wd_multiplier: 1.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.0.4.mlp.fc1.bias: lr_multiplier: 0.12157665459056935, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.0.4.mlp.fc2.weight: lr_multiplier: 0.12157665459056935, wd_multiplier: 1.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.0.4.mlp.fc2.bias: lr_multiplier: 0.12157665459056935, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.0.4.ls2.gamma: lr_multiplier: 0.12157665459056935, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.0.5.norm1.weight: lr_multiplier: 0.13508517176729928, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.0.5.norm1.bias: lr_multiplier: 0.13508517176729928, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.0.5.attn.qkv.weight: lr_multiplier: 0.13508517176729928, wd_multiplier: 1.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.0.5.attn.qkv.bias: lr_multiplier: 0.13508517176729928, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.0.5.attn.proj.weight: lr_multiplier: 0.13508517176729928, wd_multiplier: 1.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.0.5.attn.proj.bias: lr_multiplier: 0.13508517176729928, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.0.5.ls1.gamma: lr_multiplier: 0.13508517176729928, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.0.5.norm2.weight: lr_multiplier: 0.13508517176729928, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.0.5.norm2.bias: lr_multiplier: 0.13508517176729928, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.0.5.mlp.fc1.weight: lr_multiplier: 0.13508517176729928, wd_multiplier: 1.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.0.5.mlp.fc1.bias: lr_multiplier: 0.13508517176729928, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.0.5.mlp.fc2.weight: lr_multiplier: 0.13508517176729928, wd_multiplier: 1.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.0.5.mlp.fc2.bias: lr_multiplier: 0.13508517176729928, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.0.5.ls2.gamma: lr_multiplier: 0.13508517176729928, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.1.6.norm1.weight: lr_multiplier: 0.15009463529699918, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.1.6.norm1.bias: lr_multiplier: 0.15009463529699918, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.1.6.attn.qkv.weight: lr_multiplier: 0.15009463529699918, wd_multiplier: 1.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.1.6.attn.qkv.bias: lr_multiplier: 0.15009463529699918, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.1.6.attn.proj.weight: lr_multiplier: 0.15009463529699918, wd_multiplier: 1.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.1.6.attn.proj.bias: lr_multiplier: 0.15009463529699918, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.1.6.ls1.gamma: lr_multiplier: 0.15009463529699918, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.1.6.norm2.weight: lr_multiplier: 0.15009463529699918, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.1.6.norm2.bias: lr_multiplier: 0.15009463529699918, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.1.6.mlp.fc1.weight: lr_multiplier: 0.15009463529699918, wd_multiplier: 1.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.1.6.mlp.fc1.bias: lr_multiplier: 0.15009463529699918, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.1.6.mlp.fc2.weight: lr_multiplier: 0.15009463529699918, wd_multiplier: 1.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.1.6.mlp.fc2.bias: lr_multiplier: 0.15009463529699918, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.1.6.ls2.gamma: lr_multiplier: 0.15009463529699918, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.1.7.norm1.weight: lr_multiplier: 0.16677181699666577, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.1.7.norm1.bias: lr_multiplier: 0.16677181699666577, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.1.7.attn.qkv.weight: lr_multiplier: 0.16677181699666577, wd_multiplier: 1.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.1.7.attn.qkv.bias: lr_multiplier: 0.16677181699666577, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.1.7.attn.proj.weight: lr_multiplier: 0.16677181699666577, wd_multiplier: 1.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.1.7.attn.proj.bias: lr_multiplier: 0.16677181699666577, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.1.7.ls1.gamma: lr_multiplier: 0.16677181699666577, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.1.7.norm2.weight: lr_multiplier: 0.16677181699666577, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.1.7.norm2.bias: lr_multiplier: 0.16677181699666577, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.1.7.mlp.fc1.weight: lr_multiplier: 0.16677181699666577, wd_multiplier: 1.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.1.7.mlp.fc1.bias: lr_multiplier: 0.16677181699666577, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.1.7.mlp.fc2.weight: lr_multiplier: 0.16677181699666577, wd_multiplier: 1.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.1.7.mlp.fc2.bias: lr_multiplier: 0.16677181699666577, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.1.7.ls2.gamma: lr_multiplier: 0.16677181699666577, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.1.8.norm1.weight: lr_multiplier: 0.18530201888518416, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.1.8.norm1.bias: lr_multiplier: 0.18530201888518416, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.1.8.attn.qkv.weight: lr_multiplier: 0.18530201888518416, wd_multiplier: 1.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.1.8.attn.qkv.bias: lr_multiplier: 0.18530201888518416, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.1.8.attn.proj.weight: lr_multiplier: 0.18530201888518416, wd_multiplier: 1.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.1.8.attn.proj.bias: lr_multiplier: 0.18530201888518416, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.1.8.ls1.gamma: lr_multiplier: 0.18530201888518416, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.1.8.norm2.weight: lr_multiplier: 0.18530201888518416, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.1.8.norm2.bias: lr_multiplier: 0.18530201888518416, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.1.8.mlp.fc1.weight: lr_multiplier: 0.18530201888518416, wd_multiplier: 1.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.1.8.mlp.fc1.bias: lr_multiplier: 0.18530201888518416, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.1.8.mlp.fc2.weight: lr_multiplier: 0.18530201888518416, wd_multiplier: 1.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.1.8.mlp.fc2.bias: lr_multiplier: 0.18530201888518416, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.1.8.ls2.gamma: lr_multiplier: 0.18530201888518416, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.1.9.norm1.weight: lr_multiplier: 0.20589113209464907, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.1.9.norm1.bias: lr_multiplier: 0.20589113209464907, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.1.9.attn.qkv.weight: lr_multiplier: 0.20589113209464907, wd_multiplier: 1.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.1.9.attn.qkv.bias: lr_multiplier: 0.20589113209464907, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.1.9.attn.proj.weight: lr_multiplier: 0.20589113209464907, wd_multiplier: 1.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.1.9.attn.proj.bias: lr_multiplier: 0.20589113209464907, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.1.9.ls1.gamma: lr_multiplier: 0.20589113209464907, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.1.9.norm2.weight: lr_multiplier: 0.20589113209464907, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.1.9.norm2.bias: lr_multiplier: 0.20589113209464907, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.1.9.mlp.fc1.weight: lr_multiplier: 0.20589113209464907, wd_multiplier: 1.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.1.9.mlp.fc1.bias: lr_multiplier: 0.20589113209464907, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.1.9.mlp.fc2.weight: lr_multiplier: 0.20589113209464907, wd_multiplier: 1.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.1.9.mlp.fc2.bias: lr_multiplier: 0.20589113209464907, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.1.9.ls2.gamma: lr_multiplier: 0.20589113209464907, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.1.10.norm1.weight: lr_multiplier: 0.2287679245496101, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.1.10.norm1.bias: lr_multiplier: 0.2287679245496101, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.1.10.attn.qkv.weight: lr_multiplier: 0.2287679245496101, wd_multiplier: 1.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.1.10.attn.qkv.bias: lr_multiplier: 0.2287679245496101, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.1.10.attn.proj.weight: lr_multiplier: 0.2287679245496101, wd_multiplier: 1.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.1.10.attn.proj.bias: lr_multiplier: 0.2287679245496101, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.1.10.ls1.gamma: lr_multiplier: 0.2287679245496101, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.1.10.norm2.weight: lr_multiplier: 0.2287679245496101, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.1.10.norm2.bias: lr_multiplier: 0.2287679245496101, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.1.10.mlp.fc1.weight: lr_multiplier: 0.2287679245496101, wd_multiplier: 1.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.1.10.mlp.fc1.bias: lr_multiplier: 0.2287679245496101, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.1.10.mlp.fc2.weight: lr_multiplier: 0.2287679245496101, wd_multiplier: 1.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.1.10.mlp.fc2.bias: lr_multiplier: 0.2287679245496101, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.1.10.ls2.gamma: lr_multiplier: 0.2287679245496101, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.1.11.norm1.weight: lr_multiplier: 0.2541865828329001, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.1.11.norm1.bias: lr_multiplier: 0.2541865828329001, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.1.11.attn.qkv.weight: lr_multiplier: 0.2541865828329001, wd_multiplier: 1.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.1.11.attn.qkv.bias: lr_multiplier: 0.2541865828329001, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.1.11.attn.proj.weight: lr_multiplier: 0.2541865828329001, wd_multiplier: 1.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.1.11.attn.proj.bias: lr_multiplier: 0.2541865828329001, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.1.11.ls1.gamma: lr_multiplier: 0.2541865828329001, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.1.11.norm2.weight: lr_multiplier: 0.2541865828329001, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.1.11.norm2.bias: lr_multiplier: 0.2541865828329001, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.1.11.mlp.fc1.weight: lr_multiplier: 0.2541865828329001, wd_multiplier: 1.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.1.11.mlp.fc1.bias: lr_multiplier: 0.2541865828329001, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.1.11.mlp.fc2.weight: lr_multiplier: 0.2541865828329001, wd_multiplier: 1.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.1.11.mlp.fc2.bias: lr_multiplier: 0.2541865828329001, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.1.11.ls2.gamma: lr_multiplier: 0.2541865828329001, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.2.12.norm1.weight: lr_multiplier: 0.2824295364810001, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.2.12.norm1.bias: lr_multiplier: 0.2824295364810001, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.2.12.attn.qkv.weight: lr_multiplier: 0.2824295364810001, wd_multiplier: 1.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.2.12.attn.qkv.bias: lr_multiplier: 0.2824295364810001, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.2.12.attn.proj.weight: lr_multiplier: 0.2824295364810001, wd_multiplier: 1.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.2.12.attn.proj.bias: lr_multiplier: 0.2824295364810001, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.2.12.ls1.gamma: lr_multiplier: 0.2824295364810001, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.2.12.norm2.weight: lr_multiplier: 0.2824295364810001, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.2.12.norm2.bias: lr_multiplier: 0.2824295364810001, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.2.12.mlp.fc1.weight: lr_multiplier: 0.2824295364810001, wd_multiplier: 1.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.2.12.mlp.fc1.bias: lr_multiplier: 0.2824295364810001, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.2.12.mlp.fc2.weight: lr_multiplier: 0.2824295364810001, wd_multiplier: 1.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.2.12.mlp.fc2.bias: lr_multiplier: 0.2824295364810001, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.2.12.ls2.gamma: lr_multiplier: 0.2824295364810001, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.2.13.norm1.weight: lr_multiplier: 0.31381059609000006, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.2.13.norm1.bias: lr_multiplier: 0.31381059609000006, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.2.13.attn.qkv.weight: lr_multiplier: 0.31381059609000006, wd_multiplier: 1.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.2.13.attn.qkv.bias: lr_multiplier: 0.31381059609000006, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.2.13.attn.proj.weight: lr_multiplier: 0.31381059609000006, wd_multiplier: 1.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.2.13.attn.proj.bias: lr_multiplier: 0.31381059609000006, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.2.13.ls1.gamma: lr_multiplier: 0.31381059609000006, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.2.13.norm2.weight: lr_multiplier: 0.31381059609000006, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.2.13.norm2.bias: lr_multiplier: 0.31381059609000006, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.2.13.mlp.fc1.weight: lr_multiplier: 0.31381059609000006, wd_multiplier: 1.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.2.13.mlp.fc1.bias: lr_multiplier: 0.31381059609000006, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.2.13.mlp.fc2.weight: lr_multiplier: 0.31381059609000006, wd_multiplier: 1.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.2.13.mlp.fc2.bias: lr_multiplier: 0.31381059609000006, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.2.13.ls2.gamma: lr_multiplier: 0.31381059609000006, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.2.14.norm1.weight: lr_multiplier: 0.3486784401000001, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.2.14.norm1.bias: lr_multiplier: 0.3486784401000001, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.2.14.attn.qkv.weight: lr_multiplier: 0.3486784401000001, wd_multiplier: 1.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.2.14.attn.qkv.bias: lr_multiplier: 0.3486784401000001, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.2.14.attn.proj.weight: lr_multiplier: 0.3486784401000001, wd_multiplier: 1.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.2.14.attn.proj.bias: lr_multiplier: 0.3486784401000001, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.2.14.ls1.gamma: lr_multiplier: 0.3486784401000001, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.2.14.norm2.weight: lr_multiplier: 0.3486784401000001, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.2.14.norm2.bias: lr_multiplier: 0.3486784401000001, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.2.14.mlp.fc1.weight: lr_multiplier: 0.3486784401000001, wd_multiplier: 1.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.2.14.mlp.fc1.bias: lr_multiplier: 0.3486784401000001, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.2.14.mlp.fc2.weight: lr_multiplier: 0.3486784401000001, wd_multiplier: 1.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.2.14.mlp.fc2.bias: lr_multiplier: 0.3486784401000001, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.2.14.ls2.gamma: lr_multiplier: 0.3486784401000001, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.2.15.norm1.weight: lr_multiplier: 0.3874204890000001, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.2.15.norm1.bias: lr_multiplier: 0.3874204890000001, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.2.15.attn.qkv.weight: lr_multiplier: 0.3874204890000001, wd_multiplier: 1.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.2.15.attn.qkv.bias: lr_multiplier: 0.3874204890000001, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.2.15.attn.proj.weight: lr_multiplier: 0.3874204890000001, wd_multiplier: 1.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.2.15.attn.proj.bias: lr_multiplier: 0.3874204890000001, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.2.15.ls1.gamma: lr_multiplier: 0.3874204890000001, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.2.15.norm2.weight: lr_multiplier: 0.3874204890000001, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.2.15.norm2.bias: lr_multiplier: 0.3874204890000001, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.2.15.mlp.fc1.weight: lr_multiplier: 0.3874204890000001, wd_multiplier: 1.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.2.15.mlp.fc1.bias: lr_multiplier: 0.3874204890000001, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.2.15.mlp.fc2.weight: lr_multiplier: 0.3874204890000001, wd_multiplier: 1.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.2.15.mlp.fc2.bias: lr_multiplier: 0.3874204890000001, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.2.15.ls2.gamma: lr_multiplier: 0.3874204890000001, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.2.16.norm1.weight: lr_multiplier: 0.4304672100000001, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.2.16.norm1.bias: lr_multiplier: 0.4304672100000001, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.2.16.attn.qkv.weight: lr_multiplier: 0.4304672100000001, wd_multiplier: 1.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.2.16.attn.qkv.bias: lr_multiplier: 0.4304672100000001, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.2.16.attn.proj.weight: lr_multiplier: 0.4304672100000001, wd_multiplier: 1.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.2.16.attn.proj.bias: lr_multiplier: 0.4304672100000001, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.2.16.ls1.gamma: lr_multiplier: 0.4304672100000001, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.2.16.norm2.weight: lr_multiplier: 0.4304672100000001, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.2.16.norm2.bias: lr_multiplier: 0.4304672100000001, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.2.16.mlp.fc1.weight: lr_multiplier: 0.4304672100000001, wd_multiplier: 1.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.2.16.mlp.fc1.bias: lr_multiplier: 0.4304672100000001, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.2.16.mlp.fc2.weight: lr_multiplier: 0.4304672100000001, wd_multiplier: 1.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.2.16.mlp.fc2.bias: lr_multiplier: 0.4304672100000001, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.2.16.ls2.gamma: lr_multiplier: 0.4304672100000001, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.2.17.norm1.weight: lr_multiplier: 0.4782969000000001, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.2.17.norm1.bias: lr_multiplier: 0.4782969000000001, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.2.17.attn.qkv.weight: lr_multiplier: 0.4782969000000001, wd_multiplier: 1.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.2.17.attn.qkv.bias: lr_multiplier: 0.4782969000000001, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.2.17.attn.proj.weight: lr_multiplier: 0.4782969000000001, wd_multiplier: 1.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.2.17.attn.proj.bias: lr_multiplier: 0.4782969000000001, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.2.17.ls1.gamma: lr_multiplier: 0.4782969000000001, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.2.17.norm2.weight: lr_multiplier: 0.4782969000000001, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.2.17.norm2.bias: lr_multiplier: 0.4782969000000001, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.2.17.mlp.fc1.weight: lr_multiplier: 0.4782969000000001, wd_multiplier: 1.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.2.17.mlp.fc1.bias: lr_multiplier: 0.4782969000000001, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.2.17.mlp.fc2.weight: lr_multiplier: 0.4782969000000001, wd_multiplier: 1.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.2.17.mlp.fc2.bias: lr_multiplier: 0.4782969000000001, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.2.17.ls2.gamma: lr_multiplier: 0.4782969000000001, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.3.18.norm1.weight: lr_multiplier: 0.531441, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.3.18.norm1.bias: lr_multiplier: 0.531441, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.3.18.attn.qkv.weight: lr_multiplier: 0.531441, wd_multiplier: 1.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.3.18.attn.qkv.bias: lr_multiplier: 0.531441, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.3.18.attn.proj.weight: lr_multiplier: 0.531441, wd_multiplier: 1.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.3.18.attn.proj.bias: lr_multiplier: 0.531441, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.3.18.ls1.gamma: lr_multiplier: 0.531441, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.3.18.norm2.weight: lr_multiplier: 0.531441, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.3.18.norm2.bias: lr_multiplier: 0.531441, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.3.18.mlp.fc1.weight: lr_multiplier: 0.531441, wd_multiplier: 1.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.3.18.mlp.fc1.bias: lr_multiplier: 0.531441, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.3.18.mlp.fc2.weight: lr_multiplier: 0.531441, wd_multiplier: 1.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.3.18.mlp.fc2.bias: lr_multiplier: 0.531441, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.3.18.ls2.gamma: lr_multiplier: 0.531441, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.3.19.norm1.weight: lr_multiplier: 0.5904900000000001, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.3.19.norm1.bias: lr_multiplier: 0.5904900000000001, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.3.19.attn.qkv.weight: lr_multiplier: 0.5904900000000001, wd_multiplier: 1.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.3.19.attn.qkv.bias: lr_multiplier: 0.5904900000000001, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.3.19.attn.proj.weight: lr_multiplier: 0.5904900000000001, wd_multiplier: 1.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.3.19.attn.proj.bias: lr_multiplier: 0.5904900000000001, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.3.19.ls1.gamma: lr_multiplier: 0.5904900000000001, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.3.19.norm2.weight: lr_multiplier: 0.5904900000000001, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.3.19.norm2.bias: lr_multiplier: 0.5904900000000001, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.3.19.mlp.fc1.weight: lr_multiplier: 0.5904900000000001, wd_multiplier: 1.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.3.19.mlp.fc1.bias: lr_multiplier: 0.5904900000000001, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.3.19.mlp.fc2.weight: lr_multiplier: 0.5904900000000001, wd_multiplier: 1.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.3.19.mlp.fc2.bias: lr_multiplier: 0.5904900000000001, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.3.19.ls2.gamma: lr_multiplier: 0.5904900000000001, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.3.20.norm1.weight: lr_multiplier: 0.6561, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.3.20.norm1.bias: lr_multiplier: 0.6561, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.3.20.attn.qkv.weight: lr_multiplier: 0.6561, wd_multiplier: 1.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.3.20.attn.qkv.bias: lr_multiplier: 0.6561, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.3.20.attn.proj.weight: lr_multiplier: 0.6561, wd_multiplier: 1.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.3.20.attn.proj.bias: lr_multiplier: 0.6561, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.3.20.ls1.gamma: lr_multiplier: 0.6561, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.3.20.norm2.weight: lr_multiplier: 0.6561, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.3.20.norm2.bias: lr_multiplier: 0.6561, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.3.20.mlp.fc1.weight: lr_multiplier: 0.6561, wd_multiplier: 1.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.3.20.mlp.fc1.bias: lr_multiplier: 0.6561, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.3.20.mlp.fc2.weight: lr_multiplier: 0.6561, wd_multiplier: 1.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.3.20.mlp.fc2.bias: lr_multiplier: 0.6561, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.3.20.ls2.gamma: lr_multiplier: 0.6561, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.3.21.norm1.weight: lr_multiplier: 0.7290000000000001, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.3.21.norm1.bias: lr_multiplier: 0.7290000000000001, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.3.21.attn.qkv.weight: lr_multiplier: 0.7290000000000001, wd_multiplier: 1.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.3.21.attn.qkv.bias: lr_multiplier: 0.7290000000000001, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.3.21.attn.proj.weight: lr_multiplier: 0.7290000000000001, wd_multiplier: 1.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.3.21.attn.proj.bias: lr_multiplier: 0.7290000000000001, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.3.21.ls1.gamma: lr_multiplier: 0.7290000000000001, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.3.21.norm2.weight: lr_multiplier: 0.7290000000000001, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.3.21.norm2.bias: lr_multiplier: 0.7290000000000001, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.3.21.mlp.fc1.weight: lr_multiplier: 0.7290000000000001, wd_multiplier: 1.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.3.21.mlp.fc1.bias: lr_multiplier: 0.7290000000000001, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.3.21.mlp.fc2.weight: lr_multiplier: 0.7290000000000001, wd_multiplier: 1.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.3.21.mlp.fc2.bias: lr_multiplier: 0.7290000000000001, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.3.21.ls2.gamma: lr_multiplier: 0.7290000000000001, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.3.22.norm1.weight: lr_multiplier: 0.81, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.3.22.norm1.bias: lr_multiplier: 0.81, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.3.22.attn.qkv.weight: lr_multiplier: 0.81, wd_multiplier: 1.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.3.22.attn.qkv.bias: lr_multiplier: 0.81, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.3.22.attn.proj.weight: lr_multiplier: 0.81, wd_multiplier: 1.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.3.22.attn.proj.bias: lr_multiplier: 0.81, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.3.22.ls1.gamma: lr_multiplier: 0.81, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.3.22.norm2.weight: lr_multiplier: 0.81, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.3.22.norm2.bias: lr_multiplier: 0.81, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.3.22.mlp.fc1.weight: lr_multiplier: 0.81, wd_multiplier: 1.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.3.22.mlp.fc1.bias: lr_multiplier: 0.81, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.3.22.mlp.fc2.weight: lr_multiplier: 0.81, wd_multiplier: 1.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.3.22.mlp.fc2.bias: lr_multiplier: 0.81, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.3.22.ls2.gamma: lr_multiplier: 0.81, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.3.23.norm1.weight: lr_multiplier: 0.9, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.3.23.norm1.bias: lr_multiplier: 0.9, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.3.23.attn.qkv.weight: lr_multiplier: 0.9, wd_multiplier: 1.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.3.23.attn.qkv.bias: lr_multiplier: 0.9, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.3.23.attn.proj.weight: lr_multiplier: 0.9, wd_multiplier: 1.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.3.23.attn.proj.bias: lr_multiplier: 0.9, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.3.23.ls1.gamma: lr_multiplier: 0.9, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.3.23.norm2.weight: lr_multiplier: 0.9, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.3.23.norm2.bias: lr_multiplier: 0.9, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.3.23.mlp.fc1.weight: lr_multiplier: 0.9, wd_multiplier: 1.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.3.23.mlp.fc1.bias: lr_multiplier: 0.9, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.3.23.mlp.fc2.weight: lr_multiplier: 0.9, wd_multiplier: 1.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.3.23.mlp.fc2.bias: lr_multiplier: 0.9, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] blocks.3.23.ls2.gamma: lr_multiplier: 0.9, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] norm.weight: lr_multiplier: 1.0, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] norm.bias: lr_multiplier: 1.0, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 ssl_meta_arch.py:378] fusing param groups
I20240512 17:22:25 1283805 dinov2 param_groups.py:64] else code branch
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] mlp.0.weight: lr_multiplier: 1.0, wd_multiplier: 1.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] mlp.0.bias: lr_multiplier: 1.0, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] mlp.2.weight: lr_multiplier: 1.0, wd_multiplier: 1.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] mlp.2.bias: lr_multiplier: 1.0, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] mlp.4.weight: lr_multiplier: 1.0, wd_multiplier: 1.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] mlp.4.bias: lr_multiplier: 1.0, wd_multiplier: 0.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] last_layer.weight_g: lr_multiplier: 1.0, wd_multiplier: 1.0
I20240512 17:22:25 1283805 dinov2 param_groups.py:87] last_layer.weight_v: lr_multiplier: 1.0, wd_multiplier: 1.0
I20240512 17:22:25 1283805 dinov2 ssl_meta_arch.py:378] fusing param groups
I20240512 17:22:25 1283805 dinov2 train.py:102] Schedulers ready.
I20240512 17:22:25 1283805 fvcore.common.checkpoint checkpoint.py:148] No checkpoint found. Initializing model from scratch
I20240512 17:22:25 1283805 dinov2 augmentations.py:34] ###################################
I20240512 17:22:25 1283805 dinov2 augmentations.py:35] Using data augmentation parameters:
I20240512 17:22:25 1283805 dinov2 augmentations.py:36] global_crops_scale: [0.32, 1.0]
I20240512 17:22:25 1283805 dinov2 augmentations.py:37] local_crops_scale: [0.05, 0.32]
I20240512 17:22:25 1283805 dinov2 augmentations.py:38] local_crops_number: 8
I20240512 17:22:25 1283805 dinov2 augmentations.py:39] global_crops_size: 224
I20240512 17:22:25 1283805 dinov2 augmentations.py:40] local_crops_size: 96
I20240512 17:22:25 1283805 dinov2 augmentations.py:41] ###################################
